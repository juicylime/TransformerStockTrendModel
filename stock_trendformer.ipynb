{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FvvwF8Ukax-H",
        "outputId": "76435fee-4e5e-4478-985f-7d532d2f5f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.20)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.41.3)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed gast-0.4.0 keras-2.12.0 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtdkALXHeBbb",
        "outputId": "39c5dc7d-9bbc-4d9f-bfd7-7a6454d59502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  y\n",
            "\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform&state=cZgk8S2Z4wv9bNawBirNPFQ79pYUyu&prompt=consent&access_type=offline&code_challenge=34CZ3q5syc60PmwpBxTW1IXsdDcFNqULHb6uALkUJTQ&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: 4/0AfJohXkOKYE9WgctLVMpp2xr45Gby0n97JgYrDMmbnRm2QdDiJHEdakoE7mzO_DBspAUPg\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login --scopes=https://www.googleapis.com/auth/cloud-platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diVY--fAyf99"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLGkQnNvWUPY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout,Dense, Input, Masking, GlobalAveragePooling1D, Embedding, Lambda, LSTM, RepeatVector, TimeDistributed, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import Huber, BinaryCrossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF5l6yBaZNhw",
        "outputId": "b01b5750-8eb2-4fd4-8e3c-5fa77aee305c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.12.0\n",
            "Running on TPU  ['10.39.245.130:8470']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KramH_e_xoYm"
      },
      "source": [
        "# Parsing and Filtering Feature Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UvB9mNl6M8hL"
      },
      "outputs": [],
      "source": [
        "full_feature_list = sorted(['ATRr_14', 'week_day', 'Open', 'High', 'Low', 'Close', 'Volume', 'SMA_30', 'EMA_10', 'EMA_10_trend', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'RSI_10', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0', 'avgTradingVolume', 'ADX_14', 'DMP_14', 'DMN_14', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'PSAR_combined', '52_week_high', '52_week_low', 'NASDAQ_Close', 'NASDAQ_EMA_10', 'NASDAQ_EMA_30', 'SP500_Close', 'SP500_EMA_10', 'SP500_EMA_30'])\n",
        "\n",
        "features_to_keep = ['ATRr_14', 'week_day', 'Open', 'High', 'Low', 'Close', 'Volume','SMA_30', 'EMA_10', 'EMA_10_trend', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'RSI_10', 'BBP_5_2.0', 'avgTradingVolume', 'STOCHk_14_3_3', '52_week_high', '52_week_low', 'NASDAQ_Close', 'STOCHd_14_3_3', 'ADX_14', 'DMP_14', 'DMN_14', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26', 'PSAR_combined']\n",
        "\n",
        "feature_list = sorted([feature for feature in full_feature_list if feature in features_to_keep])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UiqlJ-c_bflp"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord_fn(example_proto, feature_list):\n",
        "    # Define the feature description\n",
        "    feature_description = {}\n",
        "    num_days = 20\n",
        "\n",
        "    for day in range(num_days):\n",
        "        for feature in feature_list:\n",
        "            feature_key = f\"{feature}_{day}\"\n",
        "            feature_description[feature_key] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "    feature_description['label'] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "    # Parse the input `tf.train.Example` proto\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "    # Extract and reshape features\n",
        "    features = [parsed_features[f\"{feature}_{day}\"] for day in range(num_days) for feature in feature_list]\n",
        "    features_tensor = tf.reshape(tf.stack(features), (num_days, len(feature_list)))\n",
        "\n",
        "\n",
        "    # Extract label\n",
        "    label = parsed_features['label']\n",
        "\n",
        "    # Assuming 'open_price' is the name of the opening price feature\n",
        "    # Adjust 'open_price_key' to match how your features are named\n",
        "    open_price_key = f\"EMA_10_{num_days - 1}\"  # The opening price on the last day of the sequence\n",
        "    last_day_opening_price = parsed_features[open_price_key]\n",
        "\n",
        "    # # Create a tuple for the label\n",
        "    # label_tensor = tf.stack([last_day_opening_price, label], axis=0)\n",
        "\n",
        "\n",
        "    # Changing to binary classification just to see how it performs\n",
        "\n",
        "    label = 1 if label > last_day_opening_price else 0\n",
        "\n",
        "    return features_tensor, label\n",
        "\n",
        "\n",
        "batch_size = 64  # You can adjust this size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz5uu-jTU93R"
      },
      "outputs": [],
      "source": [
        "num_days = 20\n",
        "# Label is same as features for autoencoder\n",
        "def parse_tfrecord_fn_autoenc(example_proto, feature_list):\n",
        "    # Define the feature description\n",
        "    feature_description = {}\n",
        "\n",
        "    for day in range(num_days):\n",
        "        for feature in feature_list:\n",
        "            feature_key = f\"{feature}_{day}\"\n",
        "            feature_description[feature_key] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "    feature_description['label'] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "    # Parse the input `tf.train.Example` proto\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "    # Extract and reshape features\n",
        "    features = [parsed_features[f\"{feature}_{day}\"] for day in range(num_days) for feature in feature_list]\n",
        "    features_tensor = tf.reshape(tf.stack(features), (num_days, len(feature_list)))\n",
        "\n",
        "\n",
        "    # Extract label\n",
        "    label = parsed_features['label']\n",
        "\n",
        "    return features_tensor, features_tensor\n",
        "\n",
        "\n",
        "batch_size = 256  # You can adjust this size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq1AX0ZugayG"
      },
      "outputs": [],
      "source": [
        "def test_tfrecord_parsing(tfrecord_path, timestep_to_print=0):\n",
        "    # Load one example from the TFRecord\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(1):\n",
        "        features_tensor, label = parse_tfrecord_fn(raw_record, feature_list)\n",
        "\n",
        "        # Print the specified timestep and its features\n",
        "        print(f\"Label: {label.numpy()}\")\n",
        "        print(f\"Features at timestep {timestep_to_print}:\")\n",
        "        for index, feature in enumerate(feature_list):\n",
        "            print(f\"  Feature {feature}: {features_tensor[timestep_to_print, index].numpy()}\")\n",
        "\n",
        "# Example usage\n",
        "tfrecord_path = 'gs://trendformer/Datasets/10_features/with_names/training_data.tfrecord'\n",
        "test_tfrecord_parsing(tfrecord_path, timestep_to_print=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NvA5y6jhWR6L"
      },
      "outputs": [],
      "source": [
        "def print_example():\n",
        "    num_days = 20\n",
        "    # for features_tensor, label_tuple in train_dataset.take(1):\n",
        "    for features_tensor, label in train_dataset.take(1):\n",
        "        # Convert the tensor to numpy array\n",
        "        features_array = features_tensor.numpy()\n",
        "        # last_day_open_price, next_day_open_price = label_tuple\n",
        "\n",
        "        # Convert tuple elements to numpy if they are tensors\n",
        "        # last_day_open_price = last_day_open_price.numpy() if hasattr(last_day_open_price, 'numpy') else last_day_open_price\n",
        "        # next_day_open_price = next_day_open_price.numpy() if hasattr(next_day_open_price, 'numpy') else next_day_open_price\n",
        "\n",
        "        # Print the features for each day\n",
        "        for day in range(num_days):\n",
        "            print(f\"Day {day + 1} features:\")\n",
        "            for feature_index, feature_name in enumerate(feature_list):\n",
        "                feature_value = features_array[day, feature_index]\n",
        "                print(f\"  {feature_name}: {feature_value}\")\n",
        "\n",
        "        # Print the label tuple\n",
        "        # print(f\"Last Day Opening Price: {last_day_open_price}\")\n",
        "        # print(f\"Next Day Opening Price: {next_day_open_price}\")\n",
        "        print(f\"Directional Trend: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sx2tar6OsGo"
      },
      "source": [
        "# Loading Training Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hk5nJc5FTULm"
      },
      "outputs": [],
      "source": [
        "train_tfrecord_path = 'gs://trendformer/Datasets/10_EMa_3_pred_2021/training_data.tfrecord'\n",
        "val_tfrecord_path = 'gs://trendformer/Datasets/10_EMa_3_pred_2021/validation_data.tfrecord'\n",
        "train_dataset = tf.data.TFRecordDataset(train_tfrecord_path).map(lambda example: parse_tfrecord_fn(example, feature_list))\n",
        "val_dataset = tf.data.TFRecordDataset(val_tfrecord_path).map(lambda example: parse_tfrecord_fn(example, feature_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZvmBPcoxc7p",
        "outputId": "baa39371-6466-4240-fa37-f5aad45409fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Day 1 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: 0.2990446984767914\n",
            "  ATRr_14: -0.49572935700416565\n",
            "  BBP_5_2.0: -1.633050560951233\n",
            "  Close: -0.6662697792053223\n",
            "  DMN_14: -0.5117749571800232\n",
            "  DMP_14: -0.6463748216629028\n",
            "  EMA_10: -0.6596598625183105\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6604927778244019\n",
            "  IKS_26: -0.6586649417877197\n",
            "  ISA_9: -0.6970540285110474\n",
            "  ISB_26: -0.7047022581100464\n",
            "  ITS_9: -0.661033570766449\n",
            "  Low: -0.665071427822113\n",
            "  MACD_12_26_9: 0.006339964456856251\n",
            "  MACDh_12_26_9: -0.26203271746635437\n",
            "  MACDs_12_26_9: 0.08881185203790665\n",
            "  NASDAQ_Close: -0.3340523838996887\n",
            "  Open: -0.6582360863685608\n",
            "  PSAR_combined: -0.6426226496696472\n",
            "  RSI_10: -0.7257992029190063\n",
            "  SMA_30: -0.6634615063667297\n",
            "  STOCHd_14_3_3: -1.2224878072738647\n",
            "  STOCHk_14_3_3: -1.282347321510315\n",
            "  Volume: 1.1311943531036377\n",
            "  avgTradingVolume: -0.6594743132591248\n",
            "  week_day: -1.4615496397018433\n",
            "Day 2 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: 0.12728913128376007\n",
            "  ATRr_14: -0.49645960330963135\n",
            "  BBP_5_2.0: -0.6164964437484741\n",
            "  Close: -0.6629689335823059\n",
            "  DMN_14: -0.501038670539856\n",
            "  DMP_14: -0.814944326877594\n",
            "  EMA_10: -0.6605505347251892\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6632033586502075\n",
            "  IKS_26: -0.6586649417877197\n",
            "  ISA_9: -0.6958593726158142\n",
            "  ISB_26: -0.7040682435035706\n",
            "  ITS_9: -0.6619192957878113\n",
            "  Low: -0.6668596267700195\n",
            "  MACD_12_26_9: -0.01055976003408432\n",
            "  MACDh_12_26_9: -0.25587907433509827\n",
            "  MACDs_12_26_9: 0.06898275762796402\n",
            "  NASDAQ_Close: -0.2502589523792267\n",
            "  Open: -0.6684697866439819\n",
            "  PSAR_combined: -0.6446455717086792\n",
            "  RSI_10: -0.4214988350868225\n",
            "  SMA_30: -0.6624780893325806\n",
            "  STOCHd_14_3_3: -1.2886534929275513\n",
            "  STOCHk_14_3_3: -1.2989331483840942\n",
            "  Volume: 0.6037791967391968\n",
            "  avgTradingVolume: -0.6606685519218445\n",
            "  week_day: -0.7441567182540894\n",
            "Day 3 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.06183824688196182\n",
            "  ATRr_14: -0.49987468123435974\n",
            "  BBP_5_2.0: -0.23739582300186157\n",
            "  Close: -0.6619787216186523\n",
            "  DMN_14: -0.6485034823417664\n",
            "  DMP_14: -0.7528446912765503\n",
            "  EMA_10: -0.6610982418060303\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6613602042198181\n",
            "  IKS_26: -0.6586649417877197\n",
            "  ISA_9: -0.6920478940010071\n",
            "  ISB_26: -0.7013018727302551\n",
            "  ITS_9: -0.6619192957878113\n",
            "  Low: -0.663506805896759\n",
            "  MACD_12_26_9: -0.022518424317240715\n",
            "  MACDh_12_26_9: -0.2375919371843338\n",
            "  MACDs_12_26_9: 0.0505860261619091\n",
            "  NASDAQ_Close: -0.3046124577522278\n",
            "  Open: -0.6626377105712891\n",
            "  PSAR_combined: -0.6471491456031799\n",
            "  RSI_10: -0.32987743616104126\n",
            "  SMA_30: -0.6613642573356628\n",
            "  STOCHd_14_3_3: -1.2644424438476562\n",
            "  STOCHk_14_3_3: -1.1059256792068481\n",
            "  Volume: 0.9370269775390625\n",
            "  avgTradingVolume: -0.6613098978996277\n",
            "  week_day: -0.02676374278962612\n",
            "Day 4 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.22364725172519684\n",
            "  ATRr_14: -0.5059933662414551\n",
            "  BBP_5_2.0: -0.3107050657272339\n",
            "  Close: -0.6635190844535828\n",
            "  DMN_14: -0.7595393061637878\n",
            "  DMP_14: -0.7791045308113098\n",
            "  EMA_10: -0.6618279218673706\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6606011986732483\n",
            "  IKS_26: -0.6586649417877197\n",
            "  ISA_9: -0.6920478940010071\n",
            "  ISB_26: -0.7013018727302551\n",
            "  ITS_9: -0.6619192957878113\n",
            "  Low: -0.6611598134040833\n",
            "  MACD_12_26_9: -0.035669632256031036\n",
            "  MACDh_12_26_9: -0.22618773579597473\n",
            "  MACDs_12_26_9: 0.033082544803619385\n",
            "  NASDAQ_Close: -0.07745643705129623\n",
            "  Open: -0.6602168083190918\n",
            "  PSAR_combined: -0.649402379989624\n",
            "  RSI_10: -0.4579757750034332\n",
            "  SMA_30: -0.6606863141059875\n",
            "  STOCHd_14_3_3: -1.1239166259765625\n",
            "  STOCHk_14_3_3: -0.8728981614112854\n",
            "  Volume: 0.4368201196193695\n",
            "  avgTradingVolume: -0.661420464515686\n",
            "  week_day: 0.690629243850708\n",
            "Day 5 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.33027151226997375\n",
            "  ATRr_14: -0.5108327865600586\n",
            "  BBP_5_2.0: -1.0502195358276367\n",
            "  Close: -0.6662697792053223\n",
            "  DMN_14: -0.4077010452747345\n",
            "  DMP_14: -0.8976113200187683\n",
            "  EMA_10: -0.6629278063774109\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6642876267433167\n",
            "  IKS_26: -0.6586649417877197\n",
            "  ISA_9: -0.6913936734199524\n",
            "  ISB_26: -0.7013018727302551\n",
            "  ITS_9: -0.6619192957878113\n",
            "  Low: -0.6654067039489746\n",
            "  MACD_12_26_9: -0.052092261612415314\n",
            "  MACDh_12_26_9: -0.2259126603603363\n",
            "  MACDs_12_26_9: 0.01560060866177082\n",
            "  NASDAQ_Close: 0.01606476865708828\n",
            "  Open: -0.6628577709197998\n",
            "  PSAR_combined: -0.6514302492141724\n",
            "  RSI_10: -0.683951735496521\n",
            "  SMA_30: -0.6605708003044128\n",
            "  STOCHd_14_3_3: -1.0233051776885986\n",
            "  STOCHk_14_3_3: -1.0057823657989502\n",
            "  Volume: 0.6775270104408264\n",
            "  avgTradingVolume: -0.662260890007019\n",
            "  week_day: 1.408022165298462\n",
            "Day 6 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.3777754008769989\n",
            "  ATRr_14: -0.5176424980163574\n",
            "  BBP_5_2.0: -1.3273828029632568\n",
            "  Close: -0.6677001714706421\n",
            "  DMN_14: -0.14877477288246155\n",
            "  DMP_14: -0.9895989298820496\n",
            "  EMA_10: -0.6640892028808594\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6696003079414368\n",
            "  IKS_26: -0.653857946395874\n",
            "  ISA_9: -0.6913936734199524\n",
            "  ISB_26: -0.7013018727302551\n",
            "  ITS_9: -0.6630817651748657\n",
            "  Low: -0.6686477661132812\n",
            "  MACD_12_26_9: -0.06817775964736938\n",
            "  MACDh_12_26_9: -0.22478076815605164\n",
            "  MACDs_12_26_9: -0.0017926705768331885\n",
            "  NASDAQ_Close: -0.09904681891202927\n",
            "  Open: -0.6695701479911804\n",
            "  PSAR_combined: -0.6532554030418396\n",
            "  RSI_10: -0.7999465465545654\n",
            "  SMA_30: -0.6605484485626221\n",
            "  STOCHd_14_3_3: -1.041247844696045\n",
            "  STOCHk_14_3_3: -1.1582051515579224\n",
            "  Volume: 0.19050204753875732\n",
            "  avgTradingVolume: -0.6629906892776489\n",
            "  week_day: -1.4615496397018433\n",
            "Day 7 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.5055372714996338\n",
            "  ATRr_14: -0.5212287902832031\n",
            "  BBP_5_2.0: 0.4114076793193817\n",
            "  Close: -0.6635190844535828\n",
            "  DMN_14: -0.3102260231971741\n",
            "  DMP_14: -0.6159519553184509\n",
            "  EMA_10: -0.6642751097679138\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.665371835231781\n",
            "  IKS_26: -0.653857946395874\n",
            "  ISA_9: -0.6860461235046387\n",
            "  ISB_26: -0.6958843469619751\n",
            "  ITS_9: -0.6642442941665649\n",
            "  Low: -0.6667478680610657\n",
            "  MACD_12_26_9: -0.07228534668684006\n",
            "  MACDh_12_26_9: -0.19147828221321106\n",
            "  MACDs_12_26_9: -0.01657748967409134\n",
            "  NASDAQ_Close: -0.07401512563228607\n",
            "  Open: -0.6667091250419617\n",
            "  PSAR_combined: -0.6554391384124756\n",
            "  RSI_10: -0.31171318888664246\n",
            "  SMA_30: -0.6603994965553284\n",
            "  STOCHd_14_3_3: -1.0835450887680054\n",
            "  STOCHk_14_3_3: -0.9961395263671875\n",
            "  Volume: 0.35800257325172424\n",
            "  avgTradingVolume: -0.6637426614761353\n",
            "  week_day: -0.7441567182540894\n",
            "Day 8 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.6384759545326233\n",
            "  ATRr_14: -0.525190532207489\n",
            "  BBP_5_2.0: 1.0722686052322388\n",
            "  Close: -0.661868691444397\n",
            "  DMN_14: -0.45719239115715027\n",
            "  DMP_14: -0.4923936128616333\n",
            "  EMA_10: -0.6641255021095276\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6632033586502075\n",
            "  IKS_26: -0.653857946395874\n",
            "  ISA_9: -0.6822630763053894\n",
            "  ISB_26: -0.6934061050415039\n",
            "  ITS_9: -0.6648532152175903\n",
            "  Low: -0.6641773581504822\n",
            "  MACD_12_26_9: -0.0721617341041565\n",
            "  MACDh_12_26_9: -0.15339207649230957\n",
            "  MACDs_12_26_9: -0.028379157185554504\n",
            "  NASDAQ_Close: -0.03471500426530838\n",
            "  Open: -0.6643983125686646\n",
            "  PSAR_combined: -0.657360851764679\n",
            "  RSI_10: -0.13190607726573944\n",
            "  SMA_30: -0.6598779559135437\n",
            "  STOCHd_14_3_3: -0.9514198303222656\n",
            "  STOCHk_14_3_3: -0.6208099126815796\n",
            "  Volume: 0.25766855478286743\n",
            "  avgTradingVolume: -0.6641075611114502\n",
            "  week_day: -0.02676374278962612\n",
            "Day 9 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.6055874228477478\n",
            "  ATRr_14: -0.5172897577285767\n",
            "  BBP_5_2.0: 1.5699164867401123\n",
            "  Close: -0.6518561244010925\n",
            "  DMN_14: -0.7328020334243774\n",
            "  DMP_14: 0.4294888377189636\n",
            "  EMA_10: -0.6621727347373962\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.652686357498169\n",
            "  IKS_26: -0.653857946395874\n",
            "  ISA_9: -0.6724783182144165\n",
            "  ISB_26: -0.6868359446525574\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.656242311000824\n",
            "  MACD_12_26_9: -0.05154179781675339\n",
            "  MACDh_12_26_9: -0.06748621165752411\n",
            "  MACDs_12_26_9: -0.03345213457942009\n",
            "  NASDAQ_Close: -0.04605613276362419\n",
            "  Open: -0.6584562063217163\n",
            "  PSAR_combined: -0.6714533567428589\n",
            "  RSI_10: 0.7352051138877869\n",
            "  SMA_30: -0.6590695977210999\n",
            "  STOCHd_14_3_3: -0.47394946217536926\n",
            "  STOCHk_14_3_3: 0.2329966276884079\n",
            "  Volume: 1.4589179754257202\n",
            "  avgTradingVolume: -0.6637868881225586\n",
            "  week_day: 0.690629243850708\n",
            "Day 10 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.591960608959198\n",
            "  ATRr_14: -0.5177432298660278\n",
            "  BBP_5_2.0: 0.21302717924118042\n",
            "  Close: -0.6593380570411682\n",
            "  DMN_14: -0.7924150824546814\n",
            "  DMP_14: 0.18394331634044647\n",
            "  EMA_10: -0.661942720413208\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6561558842658997\n",
            "  IKS_26: -0.653857946395874\n",
            "  ISA_9: -0.6724783182144165\n",
            "  ISB_26: -0.6868359446525574\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.6571364402770996\n",
            "  MACD_12_26_9: -0.051046449691057205\n",
            "  MACDh_12_26_9: -0.05319298431277275\n",
            "  MACDs_12_26_9: -0.037405580282211304\n",
            "  NASDAQ_Close: -0.12542027235031128\n",
            "  Open: -0.6547148823738098\n",
            "  PSAR_combined: -0.6710346937179565\n",
            "  RSI_10: 0.008622389286756516\n",
            "  SMA_30: -0.6587343811988831\n",
            "  STOCHd_14_3_3: 0.01540705282241106\n",
            "  STOCHk_14_3_3: 0.4296948313713074\n",
            "  Volume: 0.6620374321937561\n",
            "  avgTradingVolume: -0.663797914981842\n",
            "  week_day: 1.408022165298462\n",
            "Day 11 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.5793071985244751\n",
            "  ATRr_14: -0.5221644639968872\n",
            "  BBP_5_2.0: 0.3220498263835907\n",
            "  Close: -0.6570274233818054\n",
            "  DMN_14: -0.9095404744148254\n",
            "  DMP_14: 0.013927427120506763\n",
            "  EMA_10: -0.6613321900367737\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6562643051147461\n",
            "  IKS_26: -0.6571557521820068\n",
            "  ISA_9: -0.6691219210624695\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.655460000038147\n",
            "  MACD_12_26_9: -0.04620205983519554\n",
            "  MACDh_12_26_9: -0.02999543957412243\n",
            "  MACDs_12_26_9: -0.03954204544425011\n",
            "  NASDAQ_Close: 0.01272666547447443\n",
            "  Open: -0.656695544719696\n",
            "  PSAR_combined: -0.6706244349479675\n",
            "  RSI_10: 0.19439879059791565\n",
            "  SMA_30: -0.6587790846824646\n",
            "  STOCHd_14_3_3: 0.45338374376296997\n",
            "  STOCHk_14_3_3: 0.6553195118904114\n",
            "  Volume: 0.16455398499965668\n",
            "  avgTradingVolume: -0.6628690361976624\n",
            "  week_day: -0.7441567182540894\n",
            "Day 12 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.5488011240959167\n",
            "  ATRr_14: -0.5254278182983398\n",
            "  BBP_5_2.0: 0.4994249939918518\n",
            "  Close: -0.6548268795013428\n",
            "  DMN_14: -1.0312364101409912\n",
            "  DMP_14: -0.008522757329046726\n",
            "  EMA_10: -0.660430371761322\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6549632549285889\n",
            "  IKS_26: -0.6578823924064636\n",
            "  ISA_9: -0.6691219210624695\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.6560187935829163\n",
            "  MACD_12_26_9: -0.03823160007596016\n",
            "  MACDh_12_26_9: -0.0029822406359016895\n",
            "  MACDs_12_26_9: -0.03956266865134239\n",
            "  NASDAQ_Close: 0.19356004893779755\n",
            "  Open: -0.6547148823738098\n",
            "  PSAR_combined: -0.6702223420143127\n",
            "  RSI_10: 0.3698430061340332\n",
            "  SMA_30: -0.6588647365570068\n",
            "  STOCHd_14_3_3: 0.5424845814704895\n",
            "  STOCHk_14_3_3: 0.49260908365249634\n",
            "  Volume: 0.24881187081336975\n",
            "  avgTradingVolume: -0.6620507836341858\n",
            "  week_day: -0.02676374278962612\n",
            "Day 13 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.5871973633766174\n",
            "  ATRr_14: -0.5261421203613281\n",
            "  BBP_5_2.0: -0.7496689558029175\n",
            "  Close: -0.6585678458213806\n",
            "  DMN_14: -0.7980016469955444\n",
            "  DMP_14: -0.21971538662910461\n",
            "  EMA_10: -0.6603763699531555\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6568064093589783\n",
            "  IKS_26: -0.6584413647651672\n",
            "  ISA_9: -0.6686667799949646\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.659148097038269\n",
            "  MACD_12_26_9: -0.04011150449514389\n",
            "  MACDh_12_26_9: -0.008014212362468243\n",
            "  MACDs_12_26_9: -0.03997742757201195\n",
            "  NASDAQ_Close: 0.24477778375148773\n",
            "  Open: -0.656695544719696\n",
            "  PSAR_combined: -0.6698283553123474\n",
            "  RSI_10: 0.0017162199364975095\n",
            "  SMA_30: -0.6593787670135498\n",
            "  STOCHd_14_3_3: 0.5785550475120544\n",
            "  STOCHk_14_3_3: 0.5347930192947388\n",
            "  Volume: 0.515824556350708\n",
            "  avgTradingVolume: -0.6617079973220825\n",
            "  week_day: 0.690629243850708\n",
            "Day 14 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.6460576057434082\n",
            "  ATRr_14: -0.5327004194259644\n",
            "  BBP_5_2.0: -0.5638796091079712\n",
            "  Close: -0.658677875995636\n",
            "  DMN_14: -0.7526212930679321\n",
            "  DMP_14: -0.33678871393203735\n",
            "  EMA_10: -0.6603522896766663\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6609264612197876\n",
            "  IKS_26: -0.6626335382461548\n",
            "  ISA_9: -0.6681263446807861\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6620299816131592\n",
            "  Low: -0.6602657437324524\n",
            "  MACD_12_26_9: -0.04222662001848221\n",
            "  MACDh_12_26_9: -0.01267596147954464\n",
            "  MACDs_12_26_9: -0.04075732082128525\n",
            "  NASDAQ_Close: 0.25322556495666504\n",
            "  Open: -0.6613172292709351\n",
            "  PSAR_combined: -0.6694421768188477\n",
            "  RSI_10: -0.009142987430095673\n",
            "  SMA_30: -0.660053014755249\n",
            "  STOCHd_14_3_3: 0.5061653256416321\n",
            "  STOCHk_14_3_3: 0.4443981647491455\n",
            "  Volume: 0.14477789402008057\n",
            "  avgTradingVolume: -0.661221444606781\n",
            "  week_day: 1.408022165298462\n",
            "Day 15 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.767555296421051\n",
            "  ATRr_14: -0.5299477577209473\n",
            "  BBP_5_2.0: -1.508163332939148\n",
            "  Close: -0.6629689335823059\n",
            "  DMN_14: -0.35197821259498596\n",
            "  DMP_14: -0.5700080990791321\n",
            "  EMA_10: -0.6611170768737793\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6639623045921326\n",
            "  IKS_26: -0.6627452969551086\n",
            "  ISA_9: -0.6633477210998535\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6610889434814453\n",
            "  Low: -0.6651831865310669\n",
            "  MACD_12_26_9: -0.05309322476387024\n",
            "  MACDh_12_26_9: -0.04007573053240776\n",
            "  MACDs_12_26_9: -0.04368333891034126\n",
            "  NASDAQ_Close: 0.317842572927475\n",
            "  Open: -0.6618674397468567\n",
            "  PSAR_combined: -0.6690637469291687\n",
            "  RSI_10: -0.4229916036128998\n",
            "  SMA_30: -0.6606974601745605\n",
            "  STOCHd_14_3_3: 0.33656710386276245\n",
            "  STOCHk_14_3_3: -0.0015479825669899583\n",
            "  Volume: 0.8805123567581177\n",
            "  avgTradingVolume: -0.6608896851539612\n",
            "  week_day: -1.4615496397018433\n",
            "Day 16 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.8660268783569336\n",
            "  ATRr_14: -0.5349710583686829\n",
            "  BBP_5_2.0: -0.7856036424636841\n",
            "  Close: -0.661868691444397\n",
            "  DMN_14: -0.4805883467197418\n",
            "  DMP_14: -0.4074442684650421\n",
            "  EMA_10: -0.6615416407585144\n",
            "  EMA_10_trend: -1.0495871305465698\n",
            "  High: -0.6616854667663574\n",
            "  IKS_26: -0.6630247831344604\n",
            "  ISA_9: -0.6606171131134033\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6603139042854309\n",
            "  Low: -0.6617186069488525\n",
            "  MACD_12_26_9: -0.05961430072784424\n",
            "  MACDh_12_26_9: -0.050242092460393906\n",
            "  MACDs_12_26_9: -0.047405652701854706\n",
            "  NASDAQ_Close: 0.3109375536441803\n",
            "  Open: -0.6618674397468567\n",
            "  PSAR_combined: -0.668692946434021\n",
            "  RSI_10: -0.29993411898612976\n",
            "  SMA_30: -0.6616138219833374\n",
            "  STOCHd_14_3_3: 0.09044293314218521\n",
            "  STOCHk_14_3_3: -0.18233712017536163\n",
            "  Volume: 0.32025203108787537\n",
            "  avgTradingVolume: -0.6603036522865295\n",
            "  week_day: -0.7441567182540894\n",
            "Day 17 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.6890480518341064\n",
            "  ATRr_14: -0.49773865938186646\n",
            "  BBP_5_2.0: 1.5467115640640259\n",
            "  Close: -0.6505358219146729\n",
            "  DMN_14: -1.0486546754837036\n",
            "  DMP_14: 1.306831955909729\n",
            "  EMA_10: -0.6598172783851624\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6395672559738159\n",
            "  IKS_26: -0.6584413647651672\n",
            "  ISA_9: -0.6605033278465271\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6536157727241516\n",
            "  Low: -0.6611598134040833\n",
            "  MACD_12_26_9: -0.04163028299808502\n",
            "  MACDh_12_26_9: 0.007904354482889175\n",
            "  MACDs_12_26_9: -0.046573568135499954\n",
            "  NASDAQ_Close: 0.0637773647904396\n",
            "  Open: -0.6629678010940552\n",
            "  PSAR_combined: -0.6683294773101807\n",
            "  RSI_10: 0.6935179233551025\n",
            "  SMA_30: -0.6617963910102844\n",
            "  STOCHd_14_3_3: -0.12095412611961365\n",
            "  STOCHk_14_3_3: -0.17154785990715027\n",
            "  Volume: 4.637663841247559\n",
            "  avgTradingVolume: -0.6589987874031067\n",
            "  week_day: -0.02676374278962612\n",
            "Day 18 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: -0.3212723433971405\n",
            "  ATRr_14: -0.4046364724636078\n",
            "  BBP_5_2.0: 1.5450927019119263\n",
            "  Close: -0.6335914731025696\n",
            "  DMN_14: -1.7265214920043945\n",
            "  DMP_14: 3.018127918243408\n",
            "  EMA_10: -0.6553089022636414\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.5966318249702454\n",
            "  IKS_26: -0.6363067626953125\n",
            "  ISA_9: -0.6605033278465271\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6316944360733032\n",
            "  Low: -0.6450662612915039\n",
            "  MACD_12_26_9: 0.006878445390611887\n",
            "  MACDh_12_26_9: 0.13698242604732513\n",
            "  MACDs_12_26_9: -0.03563127666711807\n",
            "  NASDAQ_Close: 0.11005857586860657\n",
            "  Open: -0.6089385151863098\n",
            "  PSAR_combined: -0.6670811176300049\n",
            "  RSI_10: 1.5233237743377686\n",
            "  SMA_30: -0.6612748503684998\n",
            "  STOCHd_14_3_3: -0.14051486551761627\n",
            "  STOCHk_14_3_3: -0.05854194983839989\n",
            "  Volume: 9.18457317352295\n",
            "  avgTradingVolume: -0.6561569571495056\n",
            "  week_day: 0.690629243850708\n",
            "Day 19 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: 0.009902199730277061\n",
            "  ATRr_14: -0.386187881231308\n",
            "  BBP_5_2.0: 0.4876478612422943\n",
            "  Close: -0.6438241004943848\n",
            "  DMN_14: -1.8330515623092651\n",
            "  DMP_14: 2.275473117828369\n",
            "  EMA_10: -0.6534908413887024\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6295923590660095\n",
            "  IKS_26: -0.6363067626953125\n",
            "  ISA_9: -0.6616410613059998\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6316944360733032\n",
            "  Low: -0.6458485722541809\n",
            "  MACD_12_26_9: 0.02290603332221508\n",
            "  MACDh_12_26_9: 0.15239235758781433\n",
            "  MACDs_12_26_9: -0.023481981828808784\n",
            "  NASDAQ_Close: -0.07522447407245636\n",
            "  Open: -0.6269849538803101\n",
            "  PSAR_combined: -0.6640329360961914\n",
            "  RSI_10: 0.6535845994949341\n",
            "  SMA_30: -0.6612152457237244\n",
            "  STOCHd_14_3_3: -0.13141852617263794\n",
            "  STOCHk_14_3_3: -0.1558331847190857\n",
            "  Volume: 2.5274555683135986\n",
            "  avgTradingVolume: -0.6553497314453125\n",
            "  week_day: 1.408022165298462\n",
            "Day 20 features:\n",
            "  52_week_high: -0.5824743509292603\n",
            "  52_week_low: -0.7214404940605164\n",
            "  ADX_14: 0.25451672077178955\n",
            "  ATRr_14: -0.3896896541118622\n",
            "  BBP_5_2.0: -0.036073341965675354\n",
            "  Close: -0.6474550366401672\n",
            "  DMN_14: -1.575136661529541\n",
            "  DMP_14: 1.942484736442566\n",
            "  EMA_10: -0.6526671051979065\n",
            "  EMA_10_trend: 0.9527556300163269\n",
            "  High: -0.6447715163230896\n",
            "  IKS_26: -0.6363067626953125\n",
            "  ISA_9: -0.6625512838363647\n",
            "  ISB_26: -0.6836084723472595\n",
            "  ITS_9: -0.6316944360733032\n",
            "  Low: -0.6505425572395325\n",
            "  MACD_12_26_9: 0.026868056505918503\n",
            "  MACDh_12_26_9: 0.13208627700805664\n",
            "  MACDs_12_26_9: -0.012923186644911766\n",
            "  NASDAQ_Close: 0.15610960125923157\n",
            "  Open: -0.6428306102752686\n",
            "  PSAR_combined: -0.6597866415977478\n",
            "  RSI_10: 0.3878413140773773\n",
            "  SMA_30: -0.6612226963043213\n",
            "  STOCHd_14_3_3: -0.24810566008090973\n",
            "  STOCHk_14_3_3: -0.5115382671356201\n",
            "  Volume: 0.4770458936691284\n",
            "  avgTradingVolume: -0.6541554927825928\n",
            "  week_day: -1.4615496397018433\n",
            "Directional Trend: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function Executor.__del__ at 0x7e4865f6dab0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"
          ]
        }
      ],
      "source": [
        "print_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a8CkodH6e6N-"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(buffer_size=100000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "xq8unQD-Uw7q",
        "outputId": "a3f7fd41-89b5-4687-c1c7-50c338e49862"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-92830a226450>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfrecord_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparse_tfrecord_fn_autoenc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder_val_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_tfrecord_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparse_tfrecord_fn_autoenc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mautoencoder_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mautoencoder_val_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder_val_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2238\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m       warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m     36\u001b[0m                     \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m---> 37\u001b[0;31m     return _MapDataset(\n\u001b[0m\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     concrete_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m    233\u001b[0m         *args, **kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    236\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileleaik_h0.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_tfrecord_fn_autoenc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/function_wrappers.py\u001b[0m in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lambda_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/__autograph_generated_fileleaik_h0.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_tfrecord_fn_autoenc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"<ipython-input-9-92830a226450>\", line 1, in None  *\n        lambda example: parse_tfrecord_fn_autoenc(example, feature_list)\n\n    NameError: name 'parse_tfrecord_fn_autoenc' is not defined\n"
          ]
        }
      ],
      "source": [
        "autoencoder_train_dataset = tf.data.TFRecordDataset(train_tfrecord_path).map(lambda example: parse_tfrecord_fn_autoenc(example, feature_list))\n",
        "autoencoder_val_dataset = tf.data.TFRecordDataset(val_tfrecord_path).map(lambda example: parse_tfrecord_fn_autoenc(example, feature_list))\n",
        "\n",
        "autoencoder_train_dataset = autoencoder_train_dataset.shuffle(buffer_size=10000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "autoencoder_val_dataset = autoencoder_val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWWaTyYkyvVX"
      },
      "source": [
        "# Autoencoder Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjE6vn8pQIN4",
        "outputId": "604a32e1-e03b-4c2c-850e-e7e639a49b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_182 (InputLayer)      [(None, 20, 10)]          0         \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 128)               71168     \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " repeat_vector_9 (RepeatVect  (None, 20, 64)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 20, 128)           98816     \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 20, 10)           1290      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179,530\n",
            "Trainable params: 179,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with tpu_strategy.scope():\n",
        "  def create_recurrent_autoencoder(timesteps, n_features, latent_dim, lstm_units):\n",
        "    \"\"\"\n",
        "    Creates a recurrent autoencoder (RAE).\n",
        "\n",
        "    Parameters:\n",
        "    timesteps (int): Length of the input sequences.\n",
        "    n_features (int): Number of features for each timestep.\n",
        "    latent_dim (int): Dimensionality of the encoding space.\n",
        "    lstm_units (int): Number of LSTM units.\n",
        "\n",
        "    Returns:\n",
        "    autoencoder (Model): The RAE model.\n",
        "    encoder (Model): The encoder part of the RAE.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the encoder\n",
        "    encoder_inputs = Input(shape=(timesteps, n_features))\n",
        "    encoded = LSTM(lstm_units, return_sequences=False)(encoder_inputs)\n",
        "    # This Dense layer sets the latent dimension\n",
        "    encoded = Dense(latent_dim, activation='relu')(encoded)\n",
        "    encoded = RepeatVector(timesteps)(encoded)\n",
        "\n",
        "    # Define the decoder\n",
        "    decoder_lstm = LSTM(lstm_units, return_sequences=True)(encoded)\n",
        "    decoded = TimeDistributed(Dense(n_features))(decoder_lstm)\n",
        "\n",
        "    # Define the autoencoder model\n",
        "    autoencoder = Model(encoder_inputs, decoded)\n",
        "\n",
        "    # Define the encoder model\n",
        "    encoder = Model(encoder_inputs, encoded)\n",
        "\n",
        "    # Compile the model\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder, encoder\n",
        "\n",
        "  # Set the RAE parameters\n",
        "  timesteps = 20  # Length of input sequences\n",
        "  n_features = 10  # Number of features in your dataset, adjust accordingly\n",
        "  latent_dim = 64  # Dimensionality of the encoding space\n",
        "  lstm_units = 128  # Number of LSTM units\n",
        "\n",
        "  # Create the RAE and encoder models\n",
        "  autoencoder_model, encoder_model = create_recurrent_autoencoder(timesteps, n_features, latent_dim, lstm_units)\n",
        "\n",
        "  # Print the autoencoder summary\n",
        "  autoencoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzcpNLglRCDF"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "\n",
        "history = autoencoder_model.fit(\n",
        "    autoencoder_train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=autoencoder_val_dataset,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etjsZau6P7ZE"
      },
      "source": [
        "# Prediction Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMnx_dph768d",
        "outputId": "9cb58508-f2f7-4fe3-95f1-5e78a20f2a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_40 (InputLayer)       [(None, 20, 29)]          0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 20, 512)           15360     \n",
            "                                                                 \n",
            " tf.__operators__.add_75 (TF  (None, 20, 512)          0         \n",
            " OpLambda)                                                       \n",
            "                                                                 \n",
            " encoder_layer_1 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_2 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_3 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_4 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_5 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_6 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_7 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_8 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_9 (Functional  (None, None, 512)        17329664  \n",
            " )                                                               \n",
            "                                                                 \n",
            " encoder_layer_10 (Functiona  (None, None, 512)        17329664  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " encoder_layer_11 (Functiona  (None, None, 512)        17329664  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " encoder_layer_12 (Functiona  (None, None, 512)        17329664  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 10240)             0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 1)                 10241     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 207,981,569\n",
            "Trainable params: 207,981,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the Transformer's parameters\n",
        "d_model = 512  # Embedding dimension\n",
        "\n",
        "num_heads = 16  # Number of attention heads\n",
        "dff = 512  # Dimension of the feed-forward network\n",
        "num_layers = 12  # Number of encoder and decoder layers\n",
        "dropout_rate = 0.1  # Dropout rate\n",
        "\n",
        "# Constant learning rate\n",
        "constant_learning_rate = 1e-6\n",
        "\n",
        "# [32, 20, x]\n",
        "seq_length = 20  # Length of your input sequences\n",
        "feature_size = len(feature_list)  # Number of features in your dataset\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "\n",
        "  def custom_loss(y_true, y_pred):\n",
        "    next_day_open_price = tf.expand_dims(y_true[:, 1], axis=-1)\n",
        "\n",
        "    return tf.keras.losses.mean_squared_error(next_day_open_price, y_pred)\n",
        "\n",
        "\n",
        "  def directional_accuracy(y_true, y_pred):\n",
        "    last_day_opening_price = tf.expand_dims(y_true[:, 0], axis=-1)\n",
        "    next_day_open_price = tf.expand_dims(y_true[:, 1], axis=-1)\n",
        "\n",
        "    sign_true = K.sign(next_day_open_price - last_day_opening_price)\n",
        "    sign_pred = K.sign(y_pred - last_day_opening_price)\n",
        "\n",
        "    return K.mean(K.equal(sign_true, sign_pred), axis=-1)\n",
        "\n",
        "  def positional_encoding(seq_length, num_features):\n",
        "      \"\"\"\n",
        "      Create positional encodings for the input.\n",
        "\n",
        "      Parameters:\n",
        "      seq_length (int): The length of the sequence.\n",
        "      num_features (int): The number of features being encoded.\n",
        "\n",
        "      Returns:\n",
        "      np.ndarray: A seq_length x num_features array of positional encodings.\n",
        "      \"\"\"\n",
        "\n",
        "      # Initialize the positional encoding matrix\n",
        "      position = np.arange(seq_length)[:, np.newaxis]\n",
        "      div_term = np.exp(np.arange(0, num_features, 2) * -(np.log(10000.0) / num_features))\n",
        "\n",
        "      # Compute the positional encodings\n",
        "      pe = np.zeros((seq_length, num_features))\n",
        "      pe[:, 0::2] = np.sin(position * div_term)\n",
        "      pe[:, 1::2] = np.cos(position * div_term)\n",
        "\n",
        "      return pe\n",
        "\n",
        "  def transformer_encoder_layer(d_model, num_heads, dff, dropout_rate, name):\n",
        "      inputs = Input(shape=(None, d_model))\n",
        "      attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
        "      attention = Dropout(dropout_rate)(attention)\n",
        "      attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "      outputs = Dense(dff, activation='relu')(attention)\n",
        "      outputs = Dense(d_model)(outputs)\n",
        "      outputs = Dropout(dropout_rate)(outputs)\n",
        "      outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "      return Model(inputs=inputs, outputs=outputs, name=name)\n",
        "\n",
        "  def transformer_decoder_layer(d_model, num_heads, dff, dropout_rate, name):\n",
        "      inputs = Input(shape=(None, d_model))\n",
        "      enc_outputs = Input(shape=(None, d_model))\n",
        "\n",
        "      # Create a look-ahead mask for masked self-attention\n",
        "      seq_length = tf.shape(inputs)[1]\n",
        "      look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_length, seq_length)), -1, 0)\n",
        "\n",
        "      attention1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs, attention_mask=look_ahead_mask)\n",
        "      attention1 = Dropout(dropout_rate)(attention1)\n",
        "      attention1 = LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "      attention2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(attention1, enc_outputs)\n",
        "      attention2 = Dropout(dropout_rate)(attention2)\n",
        "      attention2 = LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "      outputs = Dense(dff, activation='relu')(attention2)\n",
        "      outputs = Dense(d_model)(outputs)\n",
        "      outputs = Dropout(dropout_rate)(outputs)\n",
        "      outputs = LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "      return Model(inputs=[inputs, enc_outputs], outputs=outputs, name=name)\n",
        "\n",
        "  def transformer_model(seq_length, feature_size, d_model, num_heads, dff, num_layers, dropout_rate):\n",
        "      inputs = Input(shape=(seq_length, feature_size))\n",
        "\n",
        "      # Ensure that the encoder model is not trainable\n",
        "      # encoder_model.trainable = False\n",
        "\n",
        "      # Extracting the open prices and applying positional encoding\n",
        "      # open_prices = inputs[:, :, 7:8]  # Assuming 0-based indexing, the 11th feature is at index 10\n",
        "      # open_prices_pos_encoding = positional_encoding(seq_length, d_model)\n",
        "      # open_prices += open_prices_pos_encoding\n",
        "\n",
        "      # feature_embeddings = encoder_model(inputs)\n",
        "      feature_embeddings = Dense(d_model, activation='leaky_relu')(inputs)\n",
        "      # feature_embeddings = LayerNormalization(epsilon=1e-6)(feature_embeddings)\n",
        "      pos_encoding = positional_encoding(seq_length, d_model)\n",
        "      feature_embeddings += pos_encoding\n",
        "\n",
        "      x = feature_embeddings\n",
        "      for i in range(num_layers):\n",
        "          x = transformer_encoder_layer(d_model, num_heads, dff, dropout_rate, f\"encoder_layer_{i+1}\")(x)\n",
        "\n",
        "      encoder_output = x\n",
        "\n",
        "      # Preparing the decoder inputs by expanding the dimensions of the open prices to match the encoder output\n",
        "      # decoder_output = open_prices\n",
        "      # Passing the combined inputs through the decoder layers\n",
        "      # for i in range(num_layers):\n",
        "      #   decoder_output = transformer_decoder_layer(d_model, num_heads, dff, dropout_rate, f\"decoder_layer_{i+1}\")([decoder_output, encoder_output])\n",
        "\n",
        "      # decoder_output = Lambda(lambda x: x[:, -1, :])(decoder_output)\n",
        "\n",
        "      # Flatten the encoder's output and pass it through a Dense layer to predict the target value\n",
        "      encoder_output = Flatten()(encoder_output)\n",
        "\n",
        "      outputs = Dense(1, activation='sigmoid')(encoder_output)\n",
        "\n",
        "      model = Model(inputs=inputs, outputs=outputs)\n",
        "      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=constant_learning_rate),\n",
        "                    loss=BinaryCrossentropy(),\n",
        "                    metrics=['accuracy'])\n",
        "      # metrics=[directional_accuracy, tf.keras.metrics.MeanSquaredError(name=\"MSE\"), tf.keras.metrics.MeanAbsoluteError(name=\"MAE\"), tf.keras.metrics.MeanAbsolutePercentageError(name=\"MAPE\")])\n",
        "      return model\n",
        "\n",
        "  # Create the model\n",
        "  model = transformer_model(seq_length, feature_size, d_model, num_heads,\n",
        "                                  dff, num_layers, dropout_rate)\n",
        "\n",
        "  # Print the model summary to verify the unique naming\n",
        "  model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXUFQ_Afy1I_"
      },
      "source": [
        "# Fitting Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN39gSTWmJcv",
        "outputId": "82229224-f63e-4423-8c40-7d2cd284fc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "266/266 [==============================] - 46s 167ms/step - loss: 0.5100 - accuracy: 0.7605 - val_loss: 0.4908 - val_accuracy: 0.7860\n",
            "Epoch 2/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.5122 - accuracy: 0.7611 - val_loss: 0.4920 - val_accuracy: 0.7864\n",
            "Epoch 3/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.5117 - accuracy: 0.7588 - val_loss: 0.4941 - val_accuracy: 0.7871\n",
            "Epoch 4/50\n",
            "266/266 [==============================] - 47s 174ms/step - loss: 0.5069 - accuracy: 0.7630 - val_loss: 0.4950 - val_accuracy: 0.7848\n",
            "Epoch 5/50\n",
            "266/266 [==============================] - 46s 167ms/step - loss: 0.5076 - accuracy: 0.7645 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
            "Epoch 6/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.5017 - accuracy: 0.7652 - val_loss: 0.4835 - val_accuracy: 0.7868\n",
            "Epoch 7/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.5025 - accuracy: 0.7653 - val_loss: 0.4821 - val_accuracy: 0.7891\n",
            "Epoch 8/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4987 - accuracy: 0.7679 - val_loss: 0.4840 - val_accuracy: 0.7879\n",
            "Epoch 9/50\n",
            "266/266 [==============================] - 46s 167ms/step - loss: 0.5006 - accuracy: 0.7646 - val_loss: 0.4846 - val_accuracy: 0.7895\n",
            "Epoch 10/50\n",
            "266/266 [==============================] - 46s 168ms/step - loss: 0.5007 - accuracy: 0.7629 - val_loss: 0.4872 - val_accuracy: 0.7891\n",
            "Epoch 11/50\n",
            "266/266 [==============================] - 46s 168ms/step - loss: 0.4985 - accuracy: 0.7658 - val_loss: 0.4872 - val_accuracy: 0.7864\n",
            "Epoch 12/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.4993 - accuracy: 0.7651 - val_loss: 0.4742 - val_accuracy: 0.7856\n",
            "Epoch 13/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4931 - accuracy: 0.7684 - val_loss: 0.4748 - val_accuracy: 0.7868\n",
            "Epoch 14/50\n",
            "266/266 [==============================] - 46s 168ms/step - loss: 0.4989 - accuracy: 0.7619 - val_loss: 0.4846 - val_accuracy: 0.7868\n",
            "Epoch 15/50\n",
            "266/266 [==============================] - 45s 167ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.4879 - val_accuracy: 0.7864\n",
            "Epoch 16/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.4935 - accuracy: 0.7676 - val_loss: 0.4903 - val_accuracy: 0.7856\n",
            "Epoch 17/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4925 - accuracy: 0.7663 - val_loss: 0.4763 - val_accuracy: 0.7883\n",
            "Epoch 18/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4906 - accuracy: 0.7717 - val_loss: 0.4823 - val_accuracy: 0.7899\n",
            "Epoch 19/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4926 - accuracy: 0.7709 - val_loss: 0.4779 - val_accuracy: 0.7922\n",
            "Epoch 20/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.4912 - accuracy: 0.7681 - val_loss: 0.4776 - val_accuracy: 0.7887\n",
            "Epoch 21/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4887 - accuracy: 0.7712 - val_loss: 0.4873 - val_accuracy: 0.7844\n",
            "Epoch 22/50\n",
            "266/266 [==============================] - 46s 170ms/step - loss: 0.4866 - accuracy: 0.7686 - val_loss: 0.4857 - val_accuracy: 0.7860\n",
            "Epoch 23/50\n",
            "266/266 [==============================] - 46s 168ms/step - loss: 0.4921 - accuracy: 0.7665 - val_loss: 0.4700 - val_accuracy: 0.7907\n",
            "Epoch 24/50\n",
            "266/266 [==============================] - 46s 168ms/step - loss: 0.4868 - accuracy: 0.7710 - val_loss: 0.4689 - val_accuracy: 0.7911\n",
            "Epoch 25/50\n",
            "266/266 [==============================] - 45s 167ms/step - loss: 0.4867 - accuracy: 0.7664 - val_loss: 0.4764 - val_accuracy: 0.7875\n",
            "Epoch 26/50\n",
            "266/266 [==============================] - 45s 167ms/step - loss: 0.4884 - accuracy: 0.7699 - val_loss: 0.4840 - val_accuracy: 0.7856\n",
            "Epoch 27/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4850 - accuracy: 0.7712 - val_loss: 0.4734 - val_accuracy: 0.7879\n",
            "Epoch 28/50\n",
            "266/266 [==============================] - 45s 167ms/step - loss: 0.4860 - accuracy: 0.7688 - val_loss: 0.4830 - val_accuracy: 0.7868\n",
            "Epoch 29/50\n",
            "266/266 [==============================] - 45s 165ms/step - loss: 0.4875 - accuracy: 0.7648 - val_loss: 0.4727 - val_accuracy: 0.7907\n",
            "Epoch 30/50\n",
            "266/266 [==============================] - 45s 166ms/step - loss: 0.4849 - accuracy: 0.7661 - val_loss: 0.4716 - val_accuracy: 0.7895\n",
            "Epoch 31/50\n",
            "266/266 [==============================] - 46s 170ms/step - loss: 0.4815 - accuracy: 0.7730 - val_loss: 0.4749 - val_accuracy: 0.7860\n",
            "Epoch 32/50\n",
            " 74/266 [=======>......................] - ETA: 30s - loss: 0.4683 - accuracy: 0.7819"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "# model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    verbose=1\n",
        "    # callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wib3skry5qo"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg1o1na94jfL",
        "outputId": "6941f981-81eb-499f-f4f8-b5fa53701d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 4s 3s/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 41ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 60ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 62ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 49ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 3s 45ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 51ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 44ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 42ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 27ms/step\n",
            "2/2 [==============================] - 1s 28ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 76ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 50ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 36ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 27ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 28ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 69ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 27ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 52ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 26ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 22ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 51ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 23ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 28ms/step\n",
            "2/2 [==============================] - 1s 24ms/step\n",
            "2/2 [==============================] - 1s 25ms/step\n",
            "2/2 [==============================] - 1s 42ms/step\n",
            "2/2 [==============================] - 5s 3s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function Executor.__del__ at 0x7e4865f6dab0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "True label: 1\n",
            "Predicted label: [0.9040742]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4002:\n",
            "True label: 1\n",
            "Predicted label: [0.9307147]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4003:\n",
            "True label: 1\n",
            "Predicted label: [0.9001632]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4004:\n",
            "True label: 1\n",
            "Predicted label: [0.89695585]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4005:\n",
            "True label: 1\n",
            "Predicted label: [0.5619734]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4006:\n",
            "True label: 1\n",
            "Predicted label: [0.70572805]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4007:\n",
            "True label: 1\n",
            "Predicted label: [0.7391517]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4008:\n",
            "True label: 1\n",
            "Predicted label: [0.2570312]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4009:\n",
            "True label: 0\n",
            "Predicted label: [0.64310366]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4010:\n",
            "True label: 0\n",
            "Predicted label: [0.5857889]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4011:\n",
            "True label: 0\n",
            "Predicted label: [0.41908944]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4012:\n",
            "True label: 1\n",
            "Predicted label: [0.16119802]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4013:\n",
            "True label: 1\n",
            "Predicted label: [0.21406382]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4014:\n",
            "True label: 1\n",
            "Predicted label: [0.66544527]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4015:\n",
            "True label: 0\n",
            "Predicted label: [0.64010066]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4016:\n",
            "True label: 0\n",
            "Predicted label: [0.37038407]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4017:\n",
            "True label: 0\n",
            "Predicted label: [0.28726837]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4018:\n",
            "True label: 0\n",
            "Predicted label: [0.11603269]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4019:\n",
            "True label: 0\n",
            "Predicted label: [0.08641958]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4020:\n",
            "True label: 0\n",
            "Predicted label: [0.1283859]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4021:\n",
            "True label: 0\n",
            "Predicted label: [0.11579826]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4022:\n",
            "True label: 0\n",
            "Predicted label: [0.36241746]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4023:\n",
            "True label: 0\n",
            "Predicted label: [0.42982042]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4024:\n",
            "True label: 0\n",
            "Predicted label: [0.15532976]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4025:\n",
            "True label: 0\n",
            "Predicted label: [0.02514094]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4026:\n",
            "True label: 0\n",
            "Predicted label: [0.02462742]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4027:\n",
            "True label: 0\n",
            "Predicted label: [0.05195442]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4028:\n",
            "True label: 0\n",
            "Predicted label: [0.03505921]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4029:\n",
            "True label: 0\n",
            "Predicted label: [0.12963691]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4030:\n",
            "True label: 0\n",
            "Predicted label: [0.02295229]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4031:\n",
            "True label: 0\n",
            "Predicted label: [0.06101355]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4032:\n",
            "True label: 0\n",
            "Predicted label: [0.05961818]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4033:\n",
            "True label: 0\n",
            "Predicted label: [0.02983052]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4034:\n",
            "True label: 1\n",
            "Predicted label: [0.26950973]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4035:\n",
            "True label: 1\n",
            "Predicted label: [0.3966625]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4036:\n",
            "True label: 1\n",
            "Predicted label: [0.5891788]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4037:\n",
            "True label: 1\n",
            "Predicted label: [0.8220992]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4038:\n",
            "True label: 1\n",
            "Predicted label: [0.8060994]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4039:\n",
            "True label: 1\n",
            "Predicted label: [0.9443606]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4040:\n",
            "True label: 1\n",
            "Predicted label: [0.96735716]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4041:\n",
            "True label: 1\n",
            "Predicted label: [0.9527096]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4042:\n",
            "True label: 1\n",
            "Predicted label: [0.95596784]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4043:\n",
            "True label: 1\n",
            "Predicted label: [0.97635186]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4044:\n",
            "True label: 0\n",
            "Predicted label: [0.9568229]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4045:\n",
            "True label: 0\n",
            "Predicted label: [0.8290541]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4046:\n",
            "True label: 1\n",
            "Predicted label: [0.37583286]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4047:\n",
            "True label: 1\n",
            "Predicted label: [0.22661757]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4048:\n",
            "True label: 1\n",
            "Predicted label: [0.6511567]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4049:\n",
            "True label: 1\n",
            "Predicted label: [0.85400915]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4050:\n",
            "True label: 0\n",
            "Predicted label: [0.7692461]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4051:\n",
            "True label: 0\n",
            "Predicted label: [0.67564076]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4052:\n",
            "True label: 0\n",
            "Predicted label: [0.7892762]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4053:\n",
            "True label: 0\n",
            "Predicted label: [0.01955456]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4054:\n",
            "True label: 1\n",
            "Predicted label: [0.02893946]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4055:\n",
            "True label: 1\n",
            "Predicted label: [0.0903177]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4056:\n",
            "True label: 1\n",
            "Predicted label: [0.3996351]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4057:\n",
            "True label: 1\n",
            "Predicted label: [0.764081]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4058:\n",
            "True label: 0\n",
            "Predicted label: [0.8264609]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4059:\n",
            "True label: 0\n",
            "Predicted label: [0.3214779]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4060:\n",
            "True label: 0\n",
            "Predicted label: [0.4481116]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4061:\n",
            "True label: 0\n",
            "Predicted label: [0.19769889]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4062:\n",
            "True label: 0\n",
            "Predicted label: [0.11097202]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4063:\n",
            "True label: 1\n",
            "Predicted label: [0.14569029]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4064:\n",
            "True label: 1\n",
            "Predicted label: [0.46996617]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4065:\n",
            "True label: 0\n",
            "Predicted label: [0.5442909]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4066:\n",
            "True label: 0\n",
            "Predicted label: [0.6003969]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4067:\n",
            "True label: 0\n",
            "Predicted label: [0.27135897]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4068:\n",
            "True label: 0\n",
            "Predicted label: [0.08298007]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4069:\n",
            "True label: 0\n",
            "Predicted label: [0.01540351]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4070:\n",
            "True label: 0\n",
            "Predicted label: [0.01524666]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4071:\n",
            "True label: 0\n",
            "Predicted label: [0.02241519]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4072:\n",
            "True label: 0\n",
            "Predicted label: [0.0255616]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4073:\n",
            "True label: 0\n",
            "Predicted label: [0.02542093]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4074:\n",
            "True label: 0\n",
            "Predicted label: [0.02525878]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4075:\n",
            "True label: 1\n",
            "Predicted label: [0.12460268]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4076:\n",
            "True label: 0\n",
            "Predicted label: [0.50323373]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4077:\n",
            "True label: 0\n",
            "Predicted label: [0.587258]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4078:\n",
            "True label: 0\n",
            "Predicted label: [0.400629]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4079:\n",
            "True label: 1\n",
            "Predicted label: [0.19360167]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4080:\n",
            "True label: 1\n",
            "Predicted label: [0.36280474]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4081:\n",
            "True label: 1\n",
            "Predicted label: [0.6673703]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4082:\n",
            "True label: 1\n",
            "Predicted label: [0.81911874]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4083:\n",
            "True label: 1\n",
            "Predicted label: [0.7200702]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4084:\n",
            "True label: 1\n",
            "Predicted label: [0.89286435]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4085:\n",
            "True label: 1\n",
            "Predicted label: [0.91620857]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4086:\n",
            "True label: 1\n",
            "Predicted label: [0.984322]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4087:\n",
            "True label: 1\n",
            "Predicted label: [0.96352136]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4088:\n",
            "True label: 1\n",
            "Predicted label: [0.8683592]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4089:\n",
            "True label: 1\n",
            "Predicted label: [0.5329651]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4090:\n",
            "True label: 1\n",
            "Predicted label: [0.37570864]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4091:\n",
            "True label: 1\n",
            "Predicted label: [0.74682784]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4092:\n",
            "True label: 1\n",
            "Predicted label: [0.8205398]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4093:\n",
            "True label: 1\n",
            "Predicted label: [0.73760515]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4094:\n",
            "True label: 1\n",
            "Predicted label: [0.7133059]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4095:\n",
            "True label: 1\n",
            "Predicted label: [0.96796906]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4096:\n",
            "True label: 1\n",
            "Predicted label: [0.97700465]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4097:\n",
            "True label: 1\n",
            "Predicted label: [0.98108804]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4098:\n",
            "True label: 1\n",
            "Predicted label: [0.97839427]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4099:\n",
            "True label: 1\n",
            "Predicted label: [0.97677314]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4100:\n",
            "True label: 1\n",
            "Predicted label: [0.933195]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4101:\n",
            "True label: 1\n",
            "Predicted label: [0.9028628]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4102:\n",
            "True label: 1\n",
            "Predicted label: [0.77508926]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4103:\n",
            "True label: 1\n",
            "Predicted label: [0.72778195]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4104:\n",
            "True label: 1\n",
            "Predicted label: [0.5964549]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4105:\n",
            "True label: 0\n",
            "Predicted label: [0.65288556]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4106:\n",
            "True label: 0\n",
            "Predicted label: [0.45731348]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4107:\n",
            "True label: 0\n",
            "Predicted label: [0.6850269]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4108:\n",
            "True label: 0\n",
            "Predicted label: [0.34562147]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4109:\n",
            "True label: 0\n",
            "Predicted label: [0.09661546]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4110:\n",
            "True label: 0\n",
            "Predicted label: [0.07050702]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4111:\n",
            "True label: 0\n",
            "Predicted label: [0.02013668]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4112:\n",
            "True label: 0\n",
            "Predicted label: [0.01590976]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4113:\n",
            "True label: 0\n",
            "Predicted label: [0.01073828]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4114:\n",
            "True label: 1\n",
            "Predicted label: [0.01214236]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4115:\n",
            "True label: 0\n",
            "Predicted label: [0.10634094]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4116:\n",
            "True label: 0\n",
            "Predicted label: [0.671407]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4117:\n",
            "True label: 1\n",
            "Predicted label: [0.30577323]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4118:\n",
            "True label: 1\n",
            "Predicted label: [0.1818699]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4119:\n",
            "True label: 1\n",
            "Predicted label: [0.5760483]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4120:\n",
            "True label: 1\n",
            "Predicted label: [0.8012408]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4121:\n",
            "True label: 0\n",
            "Predicted label: [0.7601297]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4122:\n",
            "True label: 0\n",
            "Predicted label: [0.60405046]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4123:\n",
            "True label: 0\n",
            "Predicted label: [0.20079681]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4124:\n",
            "True label: 0\n",
            "Predicted label: [0.16331008]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4125:\n",
            "True label: 0\n",
            "Predicted label: [0.03876492]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4126:\n",
            "True label: 0\n",
            "Predicted label: [0.08072978]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4127:\n",
            "True label: 0\n",
            "Predicted label: [0.29925883]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4128:\n",
            "True label: 0\n",
            "Predicted label: [0.199341]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4129:\n",
            "True label: 1\n",
            "Predicted label: [0.1354737]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4130:\n",
            "True label: 1\n",
            "Predicted label: [0.49019468]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4131:\n",
            "True label: 0\n",
            "Predicted label: [0.60216534]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4132:\n",
            "True label: 0\n",
            "Predicted label: [0.6926288]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4133:\n",
            "True label: 0\n",
            "Predicted label: [0.31565464]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4134:\n",
            "True label: 0\n",
            "Predicted label: [0.10309607]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4135:\n",
            "True label: 1\n",
            "Predicted label: [0.01554313]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4136:\n",
            "True label: 1\n",
            "Predicted label: [0.2568928]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4137:\n",
            "True label: 1\n",
            "Predicted label: [0.65355873]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4138:\n",
            "True label: 1\n",
            "Predicted label: [0.84339166]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4139:\n",
            "True label: 1\n",
            "Predicted label: [0.8068299]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4140:\n",
            "True label: 1\n",
            "Predicted label: [0.83968437]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4141:\n",
            "True label: 1\n",
            "Predicted label: [0.31652087]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4142:\n",
            "True label: 1\n",
            "Predicted label: [0.6292465]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4143:\n",
            "True label: 1\n",
            "Predicted label: [0.73023844]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4144:\n",
            "True label: 1\n",
            "Predicted label: [0.81417906]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4145:\n",
            "True label: 1\n",
            "Predicted label: [0.7037309]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4146:\n",
            "True label: 1\n",
            "Predicted label: [0.88351214]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4147:\n",
            "True label: 1\n",
            "Predicted label: [0.9105567]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4148:\n",
            "True label: 1\n",
            "Predicted label: [0.9607518]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4149:\n",
            "True label: 1\n",
            "Predicted label: [0.96136224]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4150:\n",
            "True label: 0\n",
            "Predicted label: [0.9625457]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4151:\n",
            "True label: 0\n",
            "Predicted label: [0.7958214]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4152:\n",
            "True label: 0\n",
            "Predicted label: [0.14643982]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4153:\n",
            "True label: 1\n",
            "Predicted label: [0.12473276]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4154:\n",
            "True label: 1\n",
            "Predicted label: [0.21824881]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4155:\n",
            "True label: 1\n",
            "Predicted label: [0.32167202]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4156:\n",
            "True label: 0\n",
            "Predicted label: [0.6506163]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4157:\n",
            "True label: 0\n",
            "Predicted label: [0.45242393]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4158:\n",
            "True label: 0\n",
            "Predicted label: [0.1612905]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4159:\n",
            "True label: 0\n",
            "Predicted label: [0.4468414]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4160:\n",
            "True label: 0\n",
            "Predicted label: [0.52530485]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4161:\n",
            "True label: 0\n",
            "Predicted label: [0.09254014]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4162:\n",
            "True label: 0\n",
            "Predicted label: [0.03328994]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4163:\n",
            "True label: 1\n",
            "Predicted label: [0.06685749]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4164:\n",
            "True label: 1\n",
            "Predicted label: [0.29305255]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4165:\n",
            "True label: 1\n",
            "Predicted label: [0.5764582]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4166:\n",
            "True label: 1\n",
            "Predicted label: [0.7354657]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4167:\n",
            "True label: 1\n",
            "Predicted label: [0.7353512]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4168:\n",
            "True label: 1\n",
            "Predicted label: [0.40704346]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4169:\n",
            "True label: 1\n",
            "Predicted label: [0.8298174]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4170:\n",
            "True label: 1\n",
            "Predicted label: [0.83708733]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4171:\n",
            "True label: 0\n",
            "Predicted label: [0.8092383]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4172:\n",
            "True label: 1\n",
            "Predicted label: [0.2790755]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4173:\n",
            "True label: 1\n",
            "Predicted label: [0.54299897]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4174:\n",
            "True label: 1\n",
            "Predicted label: [0.3945223]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4175:\n",
            "True label: 1\n",
            "Predicted label: [0.5855737]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4176:\n",
            "True label: 1\n",
            "Predicted label: [0.6698786]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4177:\n",
            "True label: 1\n",
            "Predicted label: [0.7017088]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4178:\n",
            "True label: 1\n",
            "Predicted label: [0.9266873]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4179:\n",
            "True label: 1\n",
            "Predicted label: [0.7700703]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4180:\n",
            "True label: 0\n",
            "Predicted label: [0.7566972]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4181:\n",
            "True label: 1\n",
            "Predicted label: [0.21003926]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4182:\n",
            "True label: 1\n",
            "Predicted label: [0.3841981]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4183:\n",
            "True label: 0\n",
            "Predicted label: [0.6039916]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4184:\n",
            "True label: 0\n",
            "Predicted label: [0.60887176]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4185:\n",
            "True label: 0\n",
            "Predicted label: [0.49813682]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4186:\n",
            "True label: 1\n",
            "Predicted label: [0.12349433]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4187:\n",
            "True label: 1\n",
            "Predicted label: [0.2766987]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4188:\n",
            "True label: 0\n",
            "Predicted label: [0.48631728]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4189:\n",
            "True label: 0\n",
            "Predicted label: [0.7185393]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4190:\n",
            "True label: 0\n",
            "Predicted label: [0.29649264]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4191:\n",
            "True label: 0\n",
            "Predicted label: [0.04222956]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4192:\n",
            "True label: 0\n",
            "Predicted label: [0.01658884]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4193:\n",
            "True label: 0\n",
            "Predicted label: [0.04422683]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4194:\n",
            "True label: 0\n",
            "Predicted label: [0.1356397]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4195:\n",
            "True label: 0\n",
            "Predicted label: [0.13169876]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4196:\n",
            "True label: 0\n",
            "Predicted label: [0.50462604]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4197:\n",
            "True label: 1\n",
            "Predicted label: [0.11350721]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4198:\n",
            "True label: 1\n",
            "Predicted label: [0.31530812]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4199:\n",
            "True label: 1\n",
            "Predicted label: [0.51720953]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4200:\n",
            "True label: 1\n",
            "Predicted label: [0.66996604]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4201:\n",
            "True label: 1\n",
            "Predicted label: [0.7103684]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4202:\n",
            "True label: 1\n",
            "Predicted label: [0.8380523]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4203:\n",
            "True label: 1\n",
            "Predicted label: [0.94316363]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4204:\n",
            "True label: 1\n",
            "Predicted label: [0.9324149]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4205:\n",
            "True label: 1\n",
            "Predicted label: [0.91608]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4206:\n",
            "True label: 1\n",
            "Predicted label: [0.9634818]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4207:\n",
            "True label: 1\n",
            "Predicted label: [0.95276713]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4208:\n",
            "True label: 1\n",
            "Predicted label: [0.9474544]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4209:\n",
            "True label: 1\n",
            "Predicted label: [0.9617934]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4210:\n",
            "True label: 1\n",
            "Predicted label: [0.9287542]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4211:\n",
            "True label: 0\n",
            "Predicted label: [0.9090622]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4212:\n",
            "True label: 0\n",
            "Predicted label: [0.60161805]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4213:\n",
            "True label: 0\n",
            "Predicted label: [0.6713862]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4214:\n",
            "True label: 0\n",
            "Predicted label: [0.07084501]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4215:\n",
            "True label: 0\n",
            "Predicted label: [0.01090837]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4216:\n",
            "True label: 0\n",
            "Predicted label: [0.01113701]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4217:\n",
            "True label: 0\n",
            "Predicted label: [0.01248327]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4218:\n",
            "True label: 0\n",
            "Predicted label: [0.01394883]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4219:\n",
            "True label: 0\n",
            "Predicted label: [0.01355121]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4220:\n",
            "True label: 1\n",
            "Predicted label: [0.09737271]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4221:\n",
            "True label: 1\n",
            "Predicted label: [0.3261665]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4222:\n",
            "True label: 1\n",
            "Predicted label: [0.5354483]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4223:\n",
            "True label: 1\n",
            "Predicted label: [0.51424944]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4224:\n",
            "True label: 1\n",
            "Predicted label: [0.61565655]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4225:\n",
            "True label: 1\n",
            "Predicted label: [0.7204862]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4226:\n",
            "True label: 1\n",
            "Predicted label: [0.71355724]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4227:\n",
            "True label: 1\n",
            "Predicted label: [0.7529658]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4228:\n",
            "True label: 1\n",
            "Predicted label: [0.6439693]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4229:\n",
            "True label: 1\n",
            "Predicted label: [0.7728866]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4230:\n",
            "True label: 1\n",
            "Predicted label: [0.8406641]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4231:\n",
            "True label: 1\n",
            "Predicted label: [0.82718325]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4232:\n",
            "True label: 0\n",
            "Predicted label: [0.34734187]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4233:\n",
            "True label: 0\n",
            "Predicted label: [0.6292342]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4234:\n",
            "True label: 0\n",
            "Predicted label: [0.3002904]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4235:\n",
            "True label: 0\n",
            "Predicted label: [0.1862143]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4236:\n",
            "True label: 0\n",
            "Predicted label: [0.21857929]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4237:\n",
            "True label: 0\n",
            "Predicted label: [0.06101534]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4238:\n",
            "True label: 0\n",
            "Predicted label: [0.01600572]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4239:\n",
            "True label: 0\n",
            "Predicted label: [0.08044031]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4240:\n",
            "True label: 0\n",
            "Predicted label: [0.01629007]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4241:\n",
            "True label: 1\n",
            "Predicted label: [0.01549953]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4242:\n",
            "True label: 1\n",
            "Predicted label: [0.54365987]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4243:\n",
            "True label: 1\n",
            "Predicted label: [0.70770293]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4244:\n",
            "True label: 1\n",
            "Predicted label: [0.84571815]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4245:\n",
            "True label: 1\n",
            "Predicted label: [0.90666103]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4246:\n",
            "True label: 1\n",
            "Predicted label: [0.941419]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4247:\n",
            "True label: 1\n",
            "Predicted label: [0.9524015]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4248:\n",
            "True label: 1\n",
            "Predicted label: [0.9220204]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4249:\n",
            "True label: 1\n",
            "Predicted label: [0.95229745]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4250:\n",
            "True label: 1\n",
            "Predicted label: [0.81676024]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4251:\n",
            "True label: 1\n",
            "Predicted label: [0.75216544]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4252:\n",
            "True label: 1\n",
            "Predicted label: [0.90326715]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4253:\n",
            "True label: 1\n",
            "Predicted label: [0.75424016]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4254:\n",
            "True label: 1\n",
            "Predicted label: [0.88217986]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4255:\n",
            "True label: 1\n",
            "Predicted label: [0.9549513]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4256:\n",
            "True label: 1\n",
            "Predicted label: [0.98918796]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4257:\n",
            "True label: 1\n",
            "Predicted label: [0.9917486]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4258:\n",
            "True label: 1\n",
            "Predicted label: [0.99164474]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4259:\n",
            "True label: 1\n",
            "Predicted label: [0.9733862]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4260:\n",
            "True label: 1\n",
            "Predicted label: [0.9359118]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4261:\n",
            "True label: 1\n",
            "Predicted label: [0.9234026]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4262:\n",
            "True label: 1\n",
            "Predicted label: [0.9144698]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4263:\n",
            "True label: 1\n",
            "Predicted label: [0.92938054]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4264:\n",
            "True label: 1\n",
            "Predicted label: [0.95897985]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4265:\n",
            "True label: 0\n",
            "Predicted label: [0.92296934]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4266:\n",
            "True label: 0\n",
            "Predicted label: [0.663853]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4267:\n",
            "True label: 0\n",
            "Predicted label: [0.13536644]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4268:\n",
            "True label: 0\n",
            "Predicted label: [0.1217396]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4269:\n",
            "True label: 1\n",
            "Predicted label: [0.05109838]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4270:\n",
            "True label: 1\n",
            "Predicted label: [0.17707014]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4271:\n",
            "True label: 1\n",
            "Predicted label: [0.50970274]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4272:\n",
            "True label: 1\n",
            "Predicted label: [0.8312787]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4273:\n",
            "True label: 0\n",
            "Predicted label: [0.00997901]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4274:\n",
            "True label: 0\n",
            "Predicted label: [0.01341465]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4275:\n",
            "True label: 0\n",
            "Predicted label: [0.01245284]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4276:\n",
            "True label: 1\n",
            "Predicted label: [0.5304719]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4277:\n",
            "True label: 1\n",
            "Predicted label: [0.573858]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4278:\n",
            "True label: 1\n",
            "Predicted label: [0.594692]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4279:\n",
            "True label: 1\n",
            "Predicted label: [0.31657207]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4280:\n",
            "True label: 1\n",
            "Predicted label: [0.80832744]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4281:\n",
            "True label: 1\n",
            "Predicted label: [0.7950084]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4282:\n",
            "True label: 1\n",
            "Predicted label: [0.8316895]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4283:\n",
            "True label: 1\n",
            "Predicted label: [0.91776276]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4284:\n",
            "True label: 1\n",
            "Predicted label: [0.8664777]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4285:\n",
            "True label: 1\n",
            "Predicted label: [0.7739819]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4286:\n",
            "True label: 1\n",
            "Predicted label: [0.5778923]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4287:\n",
            "True label: 1\n",
            "Predicted label: [0.6850182]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4288:\n",
            "True label: 1\n",
            "Predicted label: [0.90063876]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4289:\n",
            "True label: 1\n",
            "Predicted label: [0.95661664]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4290:\n",
            "True label: 1\n",
            "Predicted label: [0.962715]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4291:\n",
            "True label: 1\n",
            "Predicted label: [0.9800177]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4292:\n",
            "True label: 1\n",
            "Predicted label: [0.98805237]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4293:\n",
            "True label: 1\n",
            "Predicted label: [0.96464837]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4294:\n",
            "True label: 1\n",
            "Predicted label: [0.9739864]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4295:\n",
            "True label: 1\n",
            "Predicted label: [0.9564374]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4296:\n",
            "True label: 1\n",
            "Predicted label: [0.9381528]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4297:\n",
            "True label: 1\n",
            "Predicted label: [0.9149957]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4298:\n",
            "True label: 1\n",
            "Predicted label: [0.83712745]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4299:\n",
            "True label: 1\n",
            "Predicted label: [0.7169292]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4300:\n",
            "True label: 1\n",
            "Predicted label: [0.5918515]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4301:\n",
            "True label: 1\n",
            "Predicted label: [0.74890065]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4302:\n",
            "True label: 1\n",
            "Predicted label: [0.8058787]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4303:\n",
            "True label: 1\n",
            "Predicted label: [0.8876476]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4304:\n",
            "True label: 0\n",
            "Predicted label: [0.86921304]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4305:\n",
            "True label: 0\n",
            "Predicted label: [0.88888854]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4306:\n",
            "True label: 0\n",
            "Predicted label: [0.3548857]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4307:\n",
            "True label: 0\n",
            "Predicted label: [0.026335]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4308:\n",
            "True label: 1\n",
            "Predicted label: [0.07881489]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4309:\n",
            "True label: 1\n",
            "Predicted label: [0.28615066]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4310:\n",
            "True label: 1\n",
            "Predicted label: [0.32955164]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4311:\n",
            "True label: 1\n",
            "Predicted label: [0.5843216]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4312:\n",
            "True label: 1\n",
            "Predicted label: [0.27568814]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4313:\n",
            "True label: 1\n",
            "Predicted label: [0.70108616]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4314:\n",
            "True label: 0\n",
            "Predicted label: [0.8267418]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4315:\n",
            "True label: 0\n",
            "Predicted label: [0.3356653]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4316:\n",
            "True label: 1\n",
            "Predicted label: [0.491177]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4317:\n",
            "True label: 1\n",
            "Predicted label: [0.2696323]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4318:\n",
            "True label: 1\n",
            "Predicted label: [0.23016378]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4319:\n",
            "True label: 1\n",
            "Predicted label: [0.8219022]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4320:\n",
            "True label: 1\n",
            "Predicted label: [0.9167027]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4321:\n",
            "True label: 1\n",
            "Predicted label: [0.80544794]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4322:\n",
            "True label: 0\n",
            "Predicted label: [0.9079225]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4323:\n",
            "True label: 0\n",
            "Predicted label: [0.5998945]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4324:\n",
            "True label: 0\n",
            "Predicted label: [0.08527291]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4325:\n",
            "True label: 0\n",
            "Predicted label: [0.07629162]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4326:\n",
            "True label: 1\n",
            "Predicted label: [0.09752145]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4327:\n",
            "True label: 1\n",
            "Predicted label: [0.22254074]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4328:\n",
            "True label: 1\n",
            "Predicted label: [0.29088867]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4329:\n",
            "True label: 1\n",
            "Predicted label: [0.91343486]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4330:\n",
            "True label: 1\n",
            "Predicted label: [0.9000312]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4331:\n",
            "True label: 1\n",
            "Predicted label: [0.9091624]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4332:\n",
            "True label: 1\n",
            "Predicted label: [0.77827585]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4333:\n",
            "True label: 0\n",
            "Predicted label: [0.6335889]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4334:\n",
            "True label: 0\n",
            "Predicted label: [0.56101304]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4335:\n",
            "True label: 0\n",
            "Predicted label: [0.30764052]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4336:\n",
            "True label: 0\n",
            "Predicted label: [0.14097455]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4337:\n",
            "True label: 1\n",
            "Predicted label: [0.2663773]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4338:\n",
            "True label: 1\n",
            "Predicted label: [0.2291171]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4339:\n",
            "True label: 1\n",
            "Predicted label: [0.4082159]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4340:\n",
            "True label: 1\n",
            "Predicted label: [0.67803264]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4341:\n",
            "True label: 1\n",
            "Predicted label: [0.6830494]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4342:\n",
            "True label: 1\n",
            "Predicted label: [0.86576664]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4343:\n",
            "True label: 0\n",
            "Predicted label: [0.9655433]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4344:\n",
            "True label: 0\n",
            "Predicted label: [0.42427868]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4345:\n",
            "True label: 0\n",
            "Predicted label: [0.18654242]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4346:\n",
            "True label: 1\n",
            "Predicted label: [0.03632262]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4347:\n",
            "True label: 1\n",
            "Predicted label: [0.19489568]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4348:\n",
            "True label: 1\n",
            "Predicted label: [0.3019901]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4349:\n",
            "True label: 1\n",
            "Predicted label: [0.72950745]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4350:\n",
            "True label: 1\n",
            "Predicted label: [0.82379127]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4351:\n",
            "True label: 1\n",
            "Predicted label: [0.60242856]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4352:\n",
            "True label: 1\n",
            "Predicted label: [0.8199197]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4353:\n",
            "True label: 0\n",
            "Predicted label: [0.8947694]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4354:\n",
            "True label: 0\n",
            "Predicted label: [0.29070646]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4355:\n",
            "True label: 0\n",
            "Predicted label: [0.28131425]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4356:\n",
            "True label: 0\n",
            "Predicted label: [0.02344042]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4357:\n",
            "True label: 0\n",
            "Predicted label: [0.01367289]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4358:\n",
            "True label: 0\n",
            "Predicted label: [0.01052776]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4359:\n",
            "True label: 0\n",
            "Predicted label: [0.01323798]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4360:\n",
            "True label: 0\n",
            "Predicted label: [0.01899463]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4361:\n",
            "True label: 0\n",
            "Predicted label: [0.01517475]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4362:\n",
            "True label: 0\n",
            "Predicted label: [0.01164246]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4363:\n",
            "True label: 0\n",
            "Predicted label: [0.09193933]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4364:\n",
            "True label: 0\n",
            "Predicted label: [0.2147736]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4365:\n",
            "True label: 0\n",
            "Predicted label: [0.08222187]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4366:\n",
            "True label: 0\n",
            "Predicted label: [0.05288637]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4367:\n",
            "True label: 0\n",
            "Predicted label: [0.12048379]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4368:\n",
            "True label: 0\n",
            "Predicted label: [0.04013941]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4369:\n",
            "True label: 1\n",
            "Predicted label: [0.13507521]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4370:\n",
            "True label: 1\n",
            "Predicted label: [0.5578486]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4371:\n",
            "True label: 0\n",
            "Predicted label: [0.5464066]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4372:\n",
            "True label: 0\n",
            "Predicted label: [0.73511827]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4373:\n",
            "True label: 0\n",
            "Predicted label: [0.20468014]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4374:\n",
            "True label: 0\n",
            "Predicted label: [0.47223812]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4375:\n",
            "True label: 0\n",
            "Predicted label: [0.4950144]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4376:\n",
            "True label: 0\n",
            "Predicted label: [0.1161629]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4377:\n",
            "True label: 0\n",
            "Predicted label: [0.06816459]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4378:\n",
            "True label: 0\n",
            "Predicted label: [0.04188466]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4379:\n",
            "True label: 0\n",
            "Predicted label: [0.02233469]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4380:\n",
            "True label: 0\n",
            "Predicted label: [0.02899495]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4381:\n",
            "True label: 1\n",
            "Predicted label: [0.05651629]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4382:\n",
            "True label: 1\n",
            "Predicted label: [0.18271354]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4383:\n",
            "True label: 1\n",
            "Predicted label: [0.5597677]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4384:\n",
            "True label: 1\n",
            "Predicted label: [0.77550066]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4385:\n",
            "True label: 1\n",
            "Predicted label: [0.7980722]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4386:\n",
            "True label: 1\n",
            "Predicted label: [0.8382105]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4387:\n",
            "True label: 1\n",
            "Predicted label: [0.9270018]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4388:\n",
            "True label: 1\n",
            "Predicted label: [0.2716568]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4389:\n",
            "True label: 0\n",
            "Predicted label: [0.6615041]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4390:\n",
            "True label: 0\n",
            "Predicted label: [0.6005936]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4391:\n",
            "True label: 0\n",
            "Predicted label: [0.6064841]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4392:\n",
            "True label: 0\n",
            "Predicted label: [0.04199833]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4393:\n",
            "True label: 1\n",
            "Predicted label: [0.03829962]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4394:\n",
            "True label: 1\n",
            "Predicted label: [0.3761865]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4395:\n",
            "True label: 1\n",
            "Predicted label: [0.66275775]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4396:\n",
            "True label: 1\n",
            "Predicted label: [0.73136795]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4397:\n",
            "True label: 1\n",
            "Predicted label: [0.8746023]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4398:\n",
            "True label: 1\n",
            "Predicted label: [0.9253076]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4399:\n",
            "True label: 1\n",
            "Predicted label: [0.9170276]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4400:\n",
            "True label: 1\n",
            "Predicted label: [0.902177]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4401:\n",
            "True label: 1\n",
            "Predicted label: [0.91068375]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4402:\n",
            "True label: 1\n",
            "Predicted label: [0.9084843]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4403:\n",
            "True label: 0\n",
            "Predicted label: [0.85338235]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4404:\n",
            "True label: 0\n",
            "Predicted label: [0.382248]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4405:\n",
            "True label: 1\n",
            "Predicted label: [0.1729537]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4406:\n",
            "True label: 0\n",
            "Predicted label: [0.27929854]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4407:\n",
            "True label: 0\n",
            "Predicted label: [0.6007336]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4408:\n",
            "True label: 0\n",
            "Predicted label: [0.57092464]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4409:\n",
            "True label: 0\n",
            "Predicted label: [0.17394882]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4410:\n",
            "True label: 1\n",
            "Predicted label: [0.12429789]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4411:\n",
            "True label: 0\n",
            "Predicted label: [0.50875884]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4412:\n",
            "True label: 0\n",
            "Predicted label: [0.2747276]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4413:\n",
            "True label: 0\n",
            "Predicted label: [0.53256893]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4414:\n",
            "True label: 0\n",
            "Predicted label: [0.16338816]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4415:\n",
            "True label: 0\n",
            "Predicted label: [0.14853776]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4416:\n",
            "True label: 1\n",
            "Predicted label: [0.02655527]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4417:\n",
            "True label: 1\n",
            "Predicted label: [0.6676668]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4418:\n",
            "True label: 1\n",
            "Predicted label: [0.26005584]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4419:\n",
            "True label: 1\n",
            "Predicted label: [0.45352888]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4420:\n",
            "True label: 1\n",
            "Predicted label: [0.7544143]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4421:\n",
            "True label: 1\n",
            "Predicted label: [0.62771875]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4422:\n",
            "True label: 1\n",
            "Predicted label: [0.75220686]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4423:\n",
            "True label: 1\n",
            "Predicted label: [0.76751256]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4424:\n",
            "True label: 1\n",
            "Predicted label: [0.8239223]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4425:\n",
            "True label: 0\n",
            "Predicted label: [0.30110145]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4426:\n",
            "True label: 0\n",
            "Predicted label: [0.45444176]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4427:\n",
            "True label: 0\n",
            "Predicted label: [0.6832567]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4428:\n",
            "True label: 0\n",
            "Predicted label: [0.1211533]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4429:\n",
            "True label: 0\n",
            "Predicted label: [0.09178784]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4430:\n",
            "True label: 0\n",
            "Predicted label: [0.07794517]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4431:\n",
            "True label: 0\n",
            "Predicted label: [0.15454656]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4432:\n",
            "True label: 0\n",
            "Predicted label: [0.02022189]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4433:\n",
            "True label: 0\n",
            "Predicted label: [0.04367015]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4434:\n",
            "True label: 0\n",
            "Predicted label: [0.223443]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4435:\n",
            "True label: 0\n",
            "Predicted label: [0.25069422]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4436:\n",
            "True label: 0\n",
            "Predicted label: [0.54051083]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4437:\n",
            "True label: 0\n",
            "Predicted label: [0.29371104]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4438:\n",
            "True label: 0\n",
            "Predicted label: [0.05489761]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4439:\n",
            "True label: 0\n",
            "Predicted label: [0.03998515]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4440:\n",
            "True label: 0\n",
            "Predicted label: [0.05573756]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4441:\n",
            "True label: 0\n",
            "Predicted label: [0.02471465]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4442:\n",
            "True label: 0\n",
            "Predicted label: [0.20731723]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4443:\n",
            "True label: 0\n",
            "Predicted label: [0.08637065]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4444:\n",
            "True label: 0\n",
            "Predicted label: [0.12260848]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4445:\n",
            "True label: 0\n",
            "Predicted label: [0.3406343]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4446:\n",
            "True label: 0\n",
            "Predicted label: [0.28942114]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4447:\n",
            "True label: 1\n",
            "Predicted label: [0.0825893]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4448:\n",
            "True label: 1\n",
            "Predicted label: [0.27302474]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4449:\n",
            "True label: 1\n",
            "Predicted label: [0.6145038]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4450:\n",
            "True label: 1\n",
            "Predicted label: [0.66835237]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4451:\n",
            "True label: 1\n",
            "Predicted label: [0.7857698]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4452:\n",
            "True label: 1\n",
            "Predicted label: [0.91594744]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4453:\n",
            "True label: 1\n",
            "Predicted label: [0.9331318]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4454:\n",
            "True label: 1\n",
            "Predicted label: [0.6547091]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4455:\n",
            "True label: 1\n",
            "Predicted label: [0.8073569]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4456:\n",
            "True label: 1\n",
            "Predicted label: [0.79129726]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4457:\n",
            "True label: 1\n",
            "Predicted label: [0.75699914]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4458:\n",
            "True label: 1\n",
            "Predicted label: [0.7792419]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4459:\n",
            "True label: 1\n",
            "Predicted label: [0.9283612]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4460:\n",
            "True label: 1\n",
            "Predicted label: [0.96101296]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4461:\n",
            "True label: 1\n",
            "Predicted label: [0.9158669]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4462:\n",
            "True label: 1\n",
            "Predicted label: [0.9347569]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4463:\n",
            "True label: 1\n",
            "Predicted label: [0.88155246]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4464:\n",
            "True label: 0\n",
            "Predicted label: [0.7124217]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4465:\n",
            "True label: 0\n",
            "Predicted label: [0.27469736]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4466:\n",
            "True label: 0\n",
            "Predicted label: [0.3486172]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4467:\n",
            "True label: 0\n",
            "Predicted label: [0.4042669]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4468:\n",
            "True label: 1\n",
            "Predicted label: [0.29366326]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4469:\n",
            "True label: 1\n",
            "Predicted label: [0.39735427]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4470:\n",
            "True label: 1\n",
            "Predicted label: [0.19520512]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4471:\n",
            "True label: 1\n",
            "Predicted label: [0.73432803]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4472:\n",
            "True label: 0\n",
            "Predicted label: [0.7708466]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4473:\n",
            "True label: 0\n",
            "Predicted label: [0.6982963]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4474:\n",
            "True label: 1\n",
            "Predicted label: [0.05791652]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4475:\n",
            "True label: 1\n",
            "Predicted label: [0.08682185]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4476:\n",
            "True label: 1\n",
            "Predicted label: [0.13957876]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4477:\n",
            "True label: 1\n",
            "Predicted label: [0.7681174]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4478:\n",
            "True label: 1\n",
            "Predicted label: [0.7170307]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4479:\n",
            "True label: 1\n",
            "Predicted label: [0.8094766]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4480:\n",
            "True label: 1\n",
            "Predicted label: [0.9033541]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4481:\n",
            "True label: 1\n",
            "Predicted label: [0.92817223]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4482:\n",
            "True label: 1\n",
            "Predicted label: [0.9086439]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4483:\n",
            "True label: 1\n",
            "Predicted label: [0.9020306]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4484:\n",
            "True label: 1\n",
            "Predicted label: [0.7216039]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4485:\n",
            "True label: 0\n",
            "Predicted label: [0.8774809]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4486:\n",
            "True label: 0\n",
            "Predicted label: [0.7615682]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4487:\n",
            "True label: 0\n",
            "Predicted label: [0.39657742]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4488:\n",
            "True label: 0\n",
            "Predicted label: [0.21972063]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4489:\n",
            "True label: 1\n",
            "Predicted label: [0.2576499]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4490:\n",
            "True label: 1\n",
            "Predicted label: [0.3508525]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4491:\n",
            "True label: 0\n",
            "Predicted label: [0.707919]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4492:\n",
            "True label: 0\n",
            "Predicted label: [0.7020796]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4493:\n",
            "True label: 0\n",
            "Predicted label: [0.10451317]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4494:\n",
            "True label: 1\n",
            "Predicted label: [0.03720289]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4495:\n",
            "True label: 1\n",
            "Predicted label: [0.44348115]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4496:\n",
            "True label: 1\n",
            "Predicted label: [0.7555018]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4497:\n",
            "True label: 1\n",
            "Predicted label: [0.8023282]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4498:\n",
            "True label: 1\n",
            "Predicted label: [0.8464776]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4499:\n",
            "True label: 1\n",
            "Predicted label: [0.86132264]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4500:\n",
            "True label: 1\n",
            "Predicted label: [0.9146532]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4501:\n",
            "True label: 1\n",
            "Predicted label: [0.95401883]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4502:\n",
            "True label: 1\n",
            "Predicted label: [0.8856267]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4503:\n",
            "True label: 1\n",
            "Predicted label: [0.89290696]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4504:\n",
            "True label: 1\n",
            "Predicted label: [0.94020176]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4505:\n",
            "True label: 1\n",
            "Predicted label: [0.9658967]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4506:\n",
            "True label: 1\n",
            "Predicted label: [0.9538975]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4507:\n",
            "True label: 1\n",
            "Predicted label: [0.97118324]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4508:\n",
            "True label: 1\n",
            "Predicted label: [0.9787173]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4509:\n",
            "True label: 1\n",
            "Predicted label: [0.93179584]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4510:\n",
            "True label: 1\n",
            "Predicted label: [0.85775524]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4511:\n",
            "True label: 0\n",
            "Predicted label: [0.82260585]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4512:\n",
            "True label: 0\n",
            "Predicted label: [0.5104438]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4513:\n",
            "True label: 1\n",
            "Predicted label: [0.17444876]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4514:\n",
            "True label: 1\n",
            "Predicted label: [0.37543166]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4515:\n",
            "True label: 1\n",
            "Predicted label: [0.6952394]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4516:\n",
            "True label: 1\n",
            "Predicted label: [0.7929454]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4517:\n",
            "True label: 1\n",
            "Predicted label: [0.72905177]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4518:\n",
            "True label: 1\n",
            "Predicted label: [0.1321722]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4519:\n",
            "True label: 0\n",
            "Predicted label: [0.75491446]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4520:\n",
            "True label: 0\n",
            "Predicted label: [0.31071952]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4521:\n",
            "True label: 0\n",
            "Predicted label: [0.20050949]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4522:\n",
            "True label: 1\n",
            "Predicted label: [0.22732833]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4523:\n",
            "True label: 0\n",
            "Predicted label: [0.5590178]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4524:\n",
            "True label: 0\n",
            "Predicted label: [0.28744656]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4525:\n",
            "True label: 0\n",
            "Predicted label: [0.6113866]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4526:\n",
            "True label: 1\n",
            "Predicted label: [0.23640159]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4527:\n",
            "True label: 1\n",
            "Predicted label: [0.15638879]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4528:\n",
            "True label: 1\n",
            "Predicted label: [0.5034861]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4529:\n",
            "True label: 1\n",
            "Predicted label: [0.78435326]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4530:\n",
            "True label: 1\n",
            "Predicted label: [0.6959591]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4531:\n",
            "True label: 1\n",
            "Predicted label: [0.68810195]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4532:\n",
            "True label: 1\n",
            "Predicted label: [0.78493863]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4533:\n",
            "True label: 1\n",
            "Predicted label: [0.22200128]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4534:\n",
            "True label: 1\n",
            "Predicted label: [0.66120243]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4535:\n",
            "True label: 0\n",
            "Predicted label: [0.6293795]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4536:\n",
            "True label: 0\n",
            "Predicted label: [0.29150915]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4537:\n",
            "True label: 0\n",
            "Predicted label: [0.2478317]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4538:\n",
            "True label: 0\n",
            "Predicted label: [0.05645552]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4539:\n",
            "True label: 0\n",
            "Predicted label: [0.03666502]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4540:\n",
            "True label: 0\n",
            "Predicted label: [0.02736023]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4541:\n",
            "True label: 0\n",
            "Predicted label: [0.02197447]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4542:\n",
            "True label: 0\n",
            "Predicted label: [0.02220488]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4543:\n",
            "True label: 0\n",
            "Predicted label: [0.11953372]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4544:\n",
            "True label: 0\n",
            "Predicted label: [0.12603447]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4545:\n",
            "True label: 0\n",
            "Predicted label: [0.02368879]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4546:\n",
            "True label: 0\n",
            "Predicted label: [0.02020016]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4547:\n",
            "True label: 0\n",
            "Predicted label: [0.02334365]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4548:\n",
            "True label: 0\n",
            "Predicted label: [0.02218196]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4549:\n",
            "True label: 1\n",
            "Predicted label: [0.11403614]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4550:\n",
            "True label: 1\n",
            "Predicted label: [0.07008195]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4551:\n",
            "True label: 1\n",
            "Predicted label: [0.45406333]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4552:\n",
            "True label: 1\n",
            "Predicted label: [0.7796142]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4553:\n",
            "True label: 1\n",
            "Predicted label: [0.60994834]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4554:\n",
            "True label: 1\n",
            "Predicted label: [0.37475833]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4555:\n",
            "True label: 1\n",
            "Predicted label: [0.8039354]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4556:\n",
            "True label: 0\n",
            "Predicted label: [0.90224797]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4557:\n",
            "True label: 0\n",
            "Predicted label: [0.6507651]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4558:\n",
            "True label: 0\n",
            "Predicted label: [0.21943936]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4559:\n",
            "True label: 0\n",
            "Predicted label: [0.41904208]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4560:\n",
            "True label: 0\n",
            "Predicted label: [0.09122249]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4561:\n",
            "True label: 0\n",
            "Predicted label: [0.04305807]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4562:\n",
            "True label: 1\n",
            "Predicted label: [0.03654322]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4563:\n",
            "True label: 1\n",
            "Predicted label: [0.11437613]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4564:\n",
            "True label: 1\n",
            "Predicted label: [0.5559435]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4565:\n",
            "True label: 1\n",
            "Predicted label: [0.5138481]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4566:\n",
            "True label: 1\n",
            "Predicted label: [0.68673235]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4567:\n",
            "True label: 1\n",
            "Predicted label: [0.7277794]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4568:\n",
            "True label: 1\n",
            "Predicted label: [0.7566905]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4569:\n",
            "True label: 1\n",
            "Predicted label: [0.7000633]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4570:\n",
            "True label: 0\n",
            "Predicted label: [0.39921325]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4571:\n",
            "True label: 0\n",
            "Predicted label: [0.7969178]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4572:\n",
            "True label: 0\n",
            "Predicted label: [0.15854031]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4573:\n",
            "True label: 0\n",
            "Predicted label: [0.20224765]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4574:\n",
            "True label: 0\n",
            "Predicted label: [0.16113257]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4575:\n",
            "True label: 0\n",
            "Predicted label: [0.05974019]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4576:\n",
            "True label: 0\n",
            "Predicted label: [0.02098054]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4577:\n",
            "True label: 0\n",
            "Predicted label: [0.15944642]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4578:\n",
            "True label: 0\n",
            "Predicted label: [0.2733227]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4579:\n",
            "True label: 0\n",
            "Predicted label: [0.19028232]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4580:\n",
            "True label: 1\n",
            "Predicted label: [0.03090751]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4581:\n",
            "True label: 1\n",
            "Predicted label: [0.17879906]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4582:\n",
            "True label: 1\n",
            "Predicted label: [0.44195148]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4583:\n",
            "True label: 1\n",
            "Predicted label: [0.5886786]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4584:\n",
            "True label: 1\n",
            "Predicted label: [0.46904746]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4585:\n",
            "True label: 1\n",
            "Predicted label: [0.6726787]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4586:\n",
            "True label: 1\n",
            "Predicted label: [0.8362912]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4587:\n",
            "True label: 1\n",
            "Predicted label: [0.64087725]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4588:\n",
            "True label: 0\n",
            "Predicted label: [0.6548215]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4589:\n",
            "True label: 0\n",
            "Predicted label: [0.66786057]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4590:\n",
            "True label: 0\n",
            "Predicted label: [0.49630588]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4591:\n",
            "True label: 0\n",
            "Predicted label: [0.11487177]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4592:\n",
            "True label: 0\n",
            "Predicted label: [0.29477385]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4593:\n",
            "True label: 1\n",
            "Predicted label: [0.31363624]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4594:\n",
            "True label: 1\n",
            "Predicted label: [0.39446557]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4595:\n",
            "True label: 1\n",
            "Predicted label: [0.5392257]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4596:\n",
            "True label: 1\n",
            "Predicted label: [0.51746917]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4597:\n",
            "True label: 0\n",
            "Predicted label: [0.83406794]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4598:\n",
            "True label: 0\n",
            "Predicted label: [0.6098379]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4599:\n",
            "True label: 1\n",
            "Predicted label: [0.3850683]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4600:\n",
            "True label: 1\n",
            "Predicted label: [0.1429433]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4601:\n",
            "True label: 1\n",
            "Predicted label: [0.49722067]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4602:\n",
            "True label: 1\n",
            "Predicted label: [0.8436672]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4603:\n",
            "True label: 1\n",
            "Predicted label: [0.9059985]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4604:\n",
            "True label: 1\n",
            "Predicted label: [0.8736795]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4605:\n",
            "True label: 1\n",
            "Predicted label: [0.9568201]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4606:\n",
            "True label: 1\n",
            "Predicted label: [0.93322873]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4607:\n",
            "True label: 1\n",
            "Predicted label: [0.93413806]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4608:\n",
            "True label: 1\n",
            "Predicted label: [0.9673244]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4609:\n",
            "True label: 1\n",
            "Predicted label: [0.8696643]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4610:\n",
            "True label: 1\n",
            "Predicted label: [0.94093347]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4611:\n",
            "True label: 1\n",
            "Predicted label: [0.94958746]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4612:\n",
            "True label: 1\n",
            "Predicted label: [0.96063435]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4613:\n",
            "True label: 1\n",
            "Predicted label: [0.946975]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4614:\n",
            "True label: 1\n",
            "Predicted label: [0.97016615]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4615:\n",
            "True label: 1\n",
            "Predicted label: [0.8908727]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4616:\n",
            "True label: 1\n",
            "Predicted label: [0.90150845]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4617:\n",
            "True label: 1\n",
            "Predicted label: [0.7585994]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4618:\n",
            "True label: 1\n",
            "Predicted label: [0.72281456]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4619:\n",
            "True label: 1\n",
            "Predicted label: [0.8916799]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4620:\n",
            "True label: 1\n",
            "Predicted label: [0.86253035]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4621:\n",
            "True label: 1\n",
            "Predicted label: [0.8588963]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4622:\n",
            "True label: 1\n",
            "Predicted label: [0.8718063]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4623:\n",
            "True label: 1\n",
            "Predicted label: [0.6979538]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4624:\n",
            "True label: 1\n",
            "Predicted label: [0.8563884]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4625:\n",
            "True label: 1\n",
            "Predicted label: [0.7267405]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4626:\n",
            "True label: 1\n",
            "Predicted label: [0.8417312]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4627:\n",
            "True label: 1\n",
            "Predicted label: [0.8708082]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4628:\n",
            "True label: 1\n",
            "Predicted label: [0.7287152]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4629:\n",
            "True label: 0\n",
            "Predicted label: [0.22008601]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4630:\n",
            "True label: 0\n",
            "Predicted label: [0.27542758]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4631:\n",
            "True label: 0\n",
            "Predicted label: [0.13484797]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4632:\n",
            "True label: 0\n",
            "Predicted label: [0.44538912]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4633:\n",
            "True label: 0\n",
            "Predicted label: [0.26749265]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4634:\n",
            "True label: 0\n",
            "Predicted label: [0.0432182]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4635:\n",
            "True label: 0\n",
            "Predicted label: [0.02437136]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4636:\n",
            "True label: 0\n",
            "Predicted label: [0.02648717]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4637:\n",
            "True label: 0\n",
            "Predicted label: [0.01692745]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4638:\n",
            "True label: 0\n",
            "Predicted label: [0.01402426]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4639:\n",
            "True label: 0\n",
            "Predicted label: [0.0187501]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4640:\n",
            "True label: 1\n",
            "Predicted label: [0.12929758]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4641:\n",
            "True label: 1\n",
            "Predicted label: [0.45360494]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4642:\n",
            "True label: 1\n",
            "Predicted label: [0.56660295]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4643:\n",
            "True label: 1\n",
            "Predicted label: [0.69469494]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4644:\n",
            "True label: 0\n",
            "Predicted label: [0.6008953]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4645:\n",
            "True label: 0\n",
            "Predicted label: [0.19794762]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4646:\n",
            "True label: 0\n",
            "Predicted label: [0.619764]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4647:\n",
            "True label: 0\n",
            "Predicted label: [0.06733438]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4648:\n",
            "True label: 0\n",
            "Predicted label: [0.07301524]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4649:\n",
            "True label: 0\n",
            "Predicted label: [0.05263075]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4650:\n",
            "True label: 0\n",
            "Predicted label: [0.5190554]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4651:\n",
            "True label: 0\n",
            "Predicted label: [0.49663013]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4652:\n",
            "True label: 0\n",
            "Predicted label: [0.16919094]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4653:\n",
            "True label: 0\n",
            "Predicted label: [0.254279]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4654:\n",
            "True label: 0\n",
            "Predicted label: [0.48952743]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4655:\n",
            "True label: 0\n",
            "Predicted label: [0.1456793]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4656:\n",
            "True label: 0\n",
            "Predicted label: [0.02268094]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4657:\n",
            "True label: 0\n",
            "Predicted label: [0.02120498]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4658:\n",
            "True label: 0\n",
            "Predicted label: [0.02613196]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4659:\n",
            "True label: 0\n",
            "Predicted label: [0.04921085]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4660:\n",
            "True label: 0\n",
            "Predicted label: [0.03278962]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4661:\n",
            "True label: 0\n",
            "Predicted label: [0.02531829]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4662:\n",
            "True label: 0\n",
            "Predicted label: [0.02127942]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4663:\n",
            "True label: 0\n",
            "Predicted label: [0.02983683]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4664:\n",
            "True label: 0\n",
            "Predicted label: [0.06457871]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4665:\n",
            "True label: 1\n",
            "Predicted label: [0.15212145]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4666:\n",
            "True label: 1\n",
            "Predicted label: [0.09236217]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4667:\n",
            "True label: 1\n",
            "Predicted label: [0.7251631]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4668:\n",
            "True label: 0\n",
            "Predicted label: [0.82770294]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4669:\n",
            "True label: 0\n",
            "Predicted label: [0.3382987]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4670:\n",
            "True label: 0\n",
            "Predicted label: [0.23593947]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4671:\n",
            "True label: 0\n",
            "Predicted label: [0.0358474]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4672:\n",
            "True label: 0\n",
            "Predicted label: [0.02710372]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4673:\n",
            "True label: 1\n",
            "Predicted label: [0.05137357]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4674:\n",
            "True label: 1\n",
            "Predicted label: [0.21376607]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4675:\n",
            "True label: 1\n",
            "Predicted label: [0.55134094]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4676:\n",
            "True label: 1\n",
            "Predicted label: [0.5700432]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4677:\n",
            "True label: 1\n",
            "Predicted label: [0.6442466]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4678:\n",
            "True label: 1\n",
            "Predicted label: [0.64006144]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4679:\n",
            "True label: 1\n",
            "Predicted label: [0.7806816]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4680:\n",
            "True label: 1\n",
            "Predicted label: [0.41433883]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4681:\n",
            "True label: 1\n",
            "Predicted label: [0.3053053]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4682:\n",
            "True label: 1\n",
            "Predicted label: [0.55359983]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4683:\n",
            "True label: 1\n",
            "Predicted label: [0.36567953]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4684:\n",
            "True label: 1\n",
            "Predicted label: [0.7732738]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4685:\n",
            "True label: 1\n",
            "Predicted label: [0.7059063]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4686:\n",
            "True label: 1\n",
            "Predicted label: [0.30898052]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4687:\n",
            "True label: 1\n",
            "Predicted label: [0.6035097]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4688:\n",
            "True label: 1\n",
            "Predicted label: [0.62884253]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4689:\n",
            "True label: 1\n",
            "Predicted label: [0.24255851]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4690:\n",
            "True label: 1\n",
            "Predicted label: [0.6736817]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4691:\n",
            "True label: 1\n",
            "Predicted label: [0.7367704]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4692:\n",
            "True label: 1\n",
            "Predicted label: [0.8824991]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4693:\n",
            "True label: 1\n",
            "Predicted label: [0.73866767]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4694:\n",
            "True label: 0\n",
            "Predicted label: [0.0161064]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4695:\n",
            "True label: 0\n",
            "Predicted label: [0.03194949]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4696:\n",
            "True label: 0\n",
            "Predicted label: [0.02181938]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4697:\n",
            "True label: 1\n",
            "Predicted label: [0.73218215]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4698:\n",
            "True label: 1\n",
            "Predicted label: [0.9706273]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4699:\n",
            "True label: 0\n",
            "Predicted label: [0.96242154]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4700:\n",
            "True label: 0\n",
            "Predicted label: [0.2955872]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4701:\n",
            "True label: 0\n",
            "Predicted label: [0.20425704]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4702:\n",
            "True label: 0\n",
            "Predicted label: [0.07952499]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4703:\n",
            "True label: 0\n",
            "Predicted label: [0.29500735]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4704:\n",
            "True label: 0\n",
            "Predicted label: [0.0652414]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4705:\n",
            "True label: 0\n",
            "Predicted label: [0.04605469]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4706:\n",
            "True label: 1\n",
            "Predicted label: [0.08942086]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4707:\n",
            "True label: 1\n",
            "Predicted label: [0.09190223]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4708:\n",
            "True label: 1\n",
            "Predicted label: [0.5447207]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4709:\n",
            "True label: 1\n",
            "Predicted label: [0.5608719]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4710:\n",
            "True label: 1\n",
            "Predicted label: [0.43012944]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4711:\n",
            "True label: 1\n",
            "Predicted label: [0.62064743]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4712:\n",
            "True label: 1\n",
            "Predicted label: [0.50222766]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4713:\n",
            "True label: 1\n",
            "Predicted label: [0.8968864]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4714:\n",
            "True label: 1\n",
            "Predicted label: [0.83350766]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4715:\n",
            "True label: 1\n",
            "Predicted label: [0.8600153]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4716:\n",
            "True label: 1\n",
            "Predicted label: [0.8510952]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4717:\n",
            "True label: 0\n",
            "Predicted label: [0.73980284]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4718:\n",
            "True label: 0\n",
            "Predicted label: [0.35185984]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4719:\n",
            "True label: 0\n",
            "Predicted label: [0.3123284]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4720:\n",
            "True label: 0\n",
            "Predicted label: [0.09502524]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4721:\n",
            "True label: 0\n",
            "Predicted label: [0.02782968]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4722:\n",
            "True label: 0\n",
            "Predicted label: [0.02051193]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4723:\n",
            "True label: 0\n",
            "Predicted label: [0.02947316]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4724:\n",
            "True label: 0\n",
            "Predicted label: [0.29926965]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4725:\n",
            "True label: 0\n",
            "Predicted label: [0.05600247]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4726:\n",
            "True label: 0\n",
            "Predicted label: [0.02696213]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4727:\n",
            "True label: 0\n",
            "Predicted label: [0.01913992]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4728:\n",
            "True label: 0\n",
            "Predicted label: [0.12652943]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4729:\n",
            "True label: 0\n",
            "Predicted label: [0.3974725]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4730:\n",
            "True label: 0\n",
            "Predicted label: [0.15345576]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4731:\n",
            "True label: 1\n",
            "Predicted label: [0.08868566]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4732:\n",
            "True label: 1\n",
            "Predicted label: [0.12270588]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4733:\n",
            "True label: 1\n",
            "Predicted label: [0.2693169]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4734:\n",
            "True label: 0\n",
            "Predicted label: [0.7172848]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4735:\n",
            "True label: 0\n",
            "Predicted label: [0.64551616]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4736:\n",
            "True label: 0\n",
            "Predicted label: [0.05358088]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4737:\n",
            "True label: 0\n",
            "Predicted label: [0.02341577]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4738:\n",
            "True label: 0\n",
            "Predicted label: [0.02293545]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4739:\n",
            "True label: 0\n",
            "Predicted label: [0.02104327]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4740:\n",
            "True label: 0\n",
            "Predicted label: [0.04020676]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4741:\n",
            "True label: 0\n",
            "Predicted label: [0.03210846]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4742:\n",
            "True label: 0\n",
            "Predicted label: [0.02042228]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4743:\n",
            "True label: 0\n",
            "Predicted label: [0.02497011]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4744:\n",
            "True label: 0\n",
            "Predicted label: [0.02382711]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4745:\n",
            "True label: 0\n",
            "Predicted label: [0.02273223]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4746:\n",
            "True label: 0\n",
            "Predicted label: [0.02155077]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4747:\n",
            "True label: 0\n",
            "Predicted label: [0.21875945]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4748:\n",
            "True label: 0\n",
            "Predicted label: [0.12721682]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4749:\n",
            "True label: 0\n",
            "Predicted label: [0.1643135]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4750:\n",
            "True label: 0\n",
            "Predicted label: [0.33024365]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4751:\n",
            "True label: 0\n",
            "Predicted label: [0.395135]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4752:\n",
            "True label: 0\n",
            "Predicted label: [0.3395724]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4753:\n",
            "True label: 0\n",
            "Predicted label: [0.33415315]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4754:\n",
            "True label: 0\n",
            "Predicted label: [0.08127642]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4755:\n",
            "True label: 0\n",
            "Predicted label: [0.18605265]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4756:\n",
            "True label: 0\n",
            "Predicted label: [0.09455061]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4757:\n",
            "True label: 0\n",
            "Predicted label: [0.10330421]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4758:\n",
            "True label: 0\n",
            "Predicted label: [0.22061855]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4759:\n",
            "True label: 1\n",
            "Predicted label: [0.15719643]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4760:\n",
            "True label: 0\n",
            "Predicted label: [0.5590968]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4761:\n",
            "True label: 0\n",
            "Predicted label: [0.45309547]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4762:\n",
            "True label: 0\n",
            "Predicted label: [0.48944664]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4763:\n",
            "True label: 1\n",
            "Predicted label: [0.37336135]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4764:\n",
            "True label: 1\n",
            "Predicted label: [0.1818052]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4765:\n",
            "True label: 0\n",
            "Predicted label: [0.26054317]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4766:\n",
            "True label: 0\n",
            "Predicted label: [0.74309015]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4767:\n",
            "True label: 0\n",
            "Predicted label: [0.22976872]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4768:\n",
            "True label: 0\n",
            "Predicted label: [0.01381373]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4769:\n",
            "True label: 0\n",
            "Predicted label: [0.00925171]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4770:\n",
            "True label: 0\n",
            "Predicted label: [0.01016518]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4771:\n",
            "True label: 0\n",
            "Predicted label: [0.01271111]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4772:\n",
            "True label: 0\n",
            "Predicted label: [0.01354131]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4773:\n",
            "True label: 0\n",
            "Predicted label: [0.01386604]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4774:\n",
            "True label: 0\n",
            "Predicted label: [0.01709151]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4775:\n",
            "True label: 1\n",
            "Predicted label: [0.11729431]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4776:\n",
            "True label: 1\n",
            "Predicted label: [0.16463244]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4777:\n",
            "True label: 1\n",
            "Predicted label: [0.43540236]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4778:\n",
            "True label: 1\n",
            "Predicted label: [0.7448576]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4779:\n",
            "True label: 1\n",
            "Predicted label: [0.79921126]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4780:\n",
            "True label: 1\n",
            "Predicted label: [0.80235064]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4781:\n",
            "True label: 1\n",
            "Predicted label: [0.8245199]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4782:\n",
            "True label: 1\n",
            "Predicted label: [0.6036443]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4783:\n",
            "True label: 1\n",
            "Predicted label: [0.4214669]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4784:\n",
            "True label: 1\n",
            "Predicted label: [0.47311336]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4785:\n",
            "True label: 1\n",
            "Predicted label: [0.3400363]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4786:\n",
            "True label: 1\n",
            "Predicted label: [0.4267059]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4787:\n",
            "True label: 0\n",
            "Predicted label: [0.53430355]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4788:\n",
            "True label: 1\n",
            "Predicted label: [0.42640436]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4789:\n",
            "True label: 1\n",
            "Predicted label: [0.23185396]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4790:\n",
            "True label: 1\n",
            "Predicted label: [0.25484386]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4791:\n",
            "True label: 1\n",
            "Predicted label: [0.825399]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4792:\n",
            "True label: 1\n",
            "Predicted label: [0.8751175]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4793:\n",
            "True label: 1\n",
            "Predicted label: [0.9414619]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4794:\n",
            "True label: 0\n",
            "Predicted label: [0.8917686]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4795:\n",
            "True label: 0\n",
            "Predicted label: [0.24311477]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4796:\n",
            "True label: 0\n",
            "Predicted label: [0.17441264]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4797:\n",
            "True label: 1\n",
            "Predicted label: [0.26637495]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4798:\n",
            "True label: 1\n",
            "Predicted label: [0.39726546]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4799:\n",
            "True label: 1\n",
            "Predicted label: [0.28367987]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4800:\n",
            "True label: 1\n",
            "Predicted label: [0.7577003]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4801:\n",
            "True label: 0\n",
            "Predicted label: [0.80709445]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4802:\n",
            "True label: 0\n",
            "Predicted label: [0.25383425]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4803:\n",
            "True label: 0\n",
            "Predicted label: [0.5764959]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4804:\n",
            "True label: 1\n",
            "Predicted label: [0.14923596]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4805:\n",
            "True label: 1\n",
            "Predicted label: [0.31701165]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4806:\n",
            "True label: 0\n",
            "Predicted label: [0.6090905]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4807:\n",
            "True label: 0\n",
            "Predicted label: [0.32286948]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4808:\n",
            "True label: 1\n",
            "Predicted label: [0.50517803]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4809:\n",
            "True label: 1\n",
            "Predicted label: [0.2777185]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4810:\n",
            "True label: 1\n",
            "Predicted label: [0.16356775]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4811:\n",
            "True label: 1\n",
            "Predicted label: [0.67601395]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4812:\n",
            "True label: 1\n",
            "Predicted label: [0.6477416]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4813:\n",
            "True label: 1\n",
            "Predicted label: [0.8678856]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4814:\n",
            "True label: 1\n",
            "Predicted label: [0.9101137]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4815:\n",
            "True label: 1\n",
            "Predicted label: [0.8786168]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4816:\n",
            "True label: 1\n",
            "Predicted label: [0.92503846]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4817:\n",
            "True label: 1\n",
            "Predicted label: [0.9067947]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4818:\n",
            "True label: 1\n",
            "Predicted label: [0.9248977]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4819:\n",
            "True label: 1\n",
            "Predicted label: [0.8955505]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4820:\n",
            "True label: 1\n",
            "Predicted label: [0.94996464]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4821:\n",
            "True label: 1\n",
            "Predicted label: [0.9417298]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4822:\n",
            "True label: 1\n",
            "Predicted label: [0.86813664]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4823:\n",
            "True label: 1\n",
            "Predicted label: [0.682315]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4824:\n",
            "True label: 1\n",
            "Predicted label: [0.8099725]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4825:\n",
            "True label: 1\n",
            "Predicted label: [0.8872299]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4826:\n",
            "True label: 1\n",
            "Predicted label: [0.9124476]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4827:\n",
            "True label: 1\n",
            "Predicted label: [0.90471196]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4828:\n",
            "True label: 1\n",
            "Predicted label: [0.8554802]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4829:\n",
            "True label: 1\n",
            "Predicted label: [0.9463766]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4830:\n",
            "True label: 1\n",
            "Predicted label: [0.97330105]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4831:\n",
            "True label: 1\n",
            "Predicted label: [0.9038247]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4832:\n",
            "True label: 1\n",
            "Predicted label: [0.8949344]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4833:\n",
            "True label: 1\n",
            "Predicted label: [0.93899703]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4834:\n",
            "True label: 1\n",
            "Predicted label: [0.98446465]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4835:\n",
            "True label: 1\n",
            "Predicted label: [0.98819745]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4836:\n",
            "True label: 1\n",
            "Predicted label: [0.987659]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4837:\n",
            "True label: 1\n",
            "Predicted label: [0.9872494]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4838:\n",
            "True label: 1\n",
            "Predicted label: [0.9688002]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4839:\n",
            "True label: 1\n",
            "Predicted label: [0.9232447]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4840:\n",
            "True label: 1\n",
            "Predicted label: [0.86040056]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4841:\n",
            "True label: 1\n",
            "Predicted label: [0.84010464]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4842:\n",
            "True label: 0\n",
            "Predicted label: [0.8117875]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4843:\n",
            "True label: 0\n",
            "Predicted label: [0.76638496]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4844:\n",
            "True label: 0\n",
            "Predicted label: [0.47297078]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4845:\n",
            "True label: 0\n",
            "Predicted label: [0.4274101]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4846:\n",
            "True label: 0\n",
            "Predicted label: [0.3907513]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4847:\n",
            "True label: 0\n",
            "Predicted label: [0.30489767]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4848:\n",
            "True label: 0\n",
            "Predicted label: [0.35563788]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4849:\n",
            "True label: 1\n",
            "Predicted label: [0.18484664]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4850:\n",
            "True label: 1\n",
            "Predicted label: [0.16463712]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4851:\n",
            "True label: 1\n",
            "Predicted label: [0.5250949]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4852:\n",
            "True label: 1\n",
            "Predicted label: [0.5018075]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4853:\n",
            "True label: 1\n",
            "Predicted label: [0.5364633]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4854:\n",
            "True label: 1\n",
            "Predicted label: [0.82067347]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4855:\n",
            "True label: 1\n",
            "Predicted label: [0.8614233]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4856:\n",
            "True label: 1\n",
            "Predicted label: [0.8523613]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4857:\n",
            "True label: 1\n",
            "Predicted label: [0.84022605]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4858:\n",
            "True label: 1\n",
            "Predicted label: [0.66843307]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4859:\n",
            "True label: 1\n",
            "Predicted label: [0.5232924]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4860:\n",
            "True label: 1\n",
            "Predicted label: [0.6158805]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4861:\n",
            "True label: 1\n",
            "Predicted label: [0.8466869]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4862:\n",
            "True label: 1\n",
            "Predicted label: [0.8908193]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4863:\n",
            "True label: 1\n",
            "Predicted label: [0.94902074]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4864:\n",
            "True label: 1\n",
            "Predicted label: [0.8907174]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4865:\n",
            "True label: 1\n",
            "Predicted label: [0.870443]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4866:\n",
            "True label: 1\n",
            "Predicted label: [0.90967757]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4867:\n",
            "True label: 1\n",
            "Predicted label: [0.8719562]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4868:\n",
            "True label: 1\n",
            "Predicted label: [0.8870931]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4869:\n",
            "True label: 1\n",
            "Predicted label: [0.8775953]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4870:\n",
            "True label: 1\n",
            "Predicted label: [0.814206]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4871:\n",
            "True label: 1\n",
            "Predicted label: [0.71254313]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4872:\n",
            "True label: 1\n",
            "Predicted label: [0.80887264]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4873:\n",
            "True label: 1\n",
            "Predicted label: [0.8376597]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4874:\n",
            "True label: 1\n",
            "Predicted label: [0.8623173]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4875:\n",
            "True label: 1\n",
            "Predicted label: [0.8681837]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4876:\n",
            "True label: 1\n",
            "Predicted label: [0.8967806]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4877:\n",
            "True label: 1\n",
            "Predicted label: [0.83391356]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4878:\n",
            "True label: 1\n",
            "Predicted label: [0.8828244]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4879:\n",
            "True label: 1\n",
            "Predicted label: [0.82861805]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4880:\n",
            "True label: 1\n",
            "Predicted label: [0.7591733]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4881:\n",
            "True label: 1\n",
            "Predicted label: [0.7355101]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4882:\n",
            "True label: 1\n",
            "Predicted label: [0.84135854]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4883:\n",
            "True label: 1\n",
            "Predicted label: [0.84992653]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4884:\n",
            "True label: 0\n",
            "Predicted label: [0.77529824]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4885:\n",
            "True label: 0\n",
            "Predicted label: [0.7053636]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4886:\n",
            "True label: 0\n",
            "Predicted label: [0.46326622]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4887:\n",
            "True label: 0\n",
            "Predicted label: [0.390224]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4888:\n",
            "True label: 0\n",
            "Predicted label: [0.36090288]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4889:\n",
            "True label: 1\n",
            "Predicted label: [0.33451736]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4890:\n",
            "True label: 1\n",
            "Predicted label: [0.10626701]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4891:\n",
            "True label: 1\n",
            "Predicted label: [0.19054335]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4892:\n",
            "True label: 1\n",
            "Predicted label: [0.8125153]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4893:\n",
            "True label: 1\n",
            "Predicted label: [0.95761853]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4894:\n",
            "True label: 1\n",
            "Predicted label: [0.9667345]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4895:\n",
            "True label: 1\n",
            "Predicted label: [0.96208245]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4896:\n",
            "True label: 1\n",
            "Predicted label: [0.91496634]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4897:\n",
            "True label: 1\n",
            "Predicted label: [0.8442739]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4898:\n",
            "True label: 1\n",
            "Predicted label: [0.79837275]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4899:\n",
            "True label: 1\n",
            "Predicted label: [0.74620324]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4900:\n",
            "True label: 1\n",
            "Predicted label: [0.69260895]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4901:\n",
            "True label: 1\n",
            "Predicted label: [0.6522747]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4902:\n",
            "True label: 1\n",
            "Predicted label: [0.7742704]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4903:\n",
            "True label: 1\n",
            "Predicted label: [0.65432274]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4904:\n",
            "True label: 1\n",
            "Predicted label: [0.7932638]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4905:\n",
            "True label: 1\n",
            "Predicted label: [0.7925846]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4906:\n",
            "True label: 1\n",
            "Predicted label: [0.8726387]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4907:\n",
            "True label: 1\n",
            "Predicted label: [0.9146809]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4908:\n",
            "True label: 1\n",
            "Predicted label: [0.90511304]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4909:\n",
            "True label: 1\n",
            "Predicted label: [0.9138417]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4910:\n",
            "True label: 1\n",
            "Predicted label: [0.8611735]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4911:\n",
            "True label: 1\n",
            "Predicted label: [0.8743944]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4912:\n",
            "True label: 1\n",
            "Predicted label: [0.90002453]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4913:\n",
            "True label: 1\n",
            "Predicted label: [0.93019295]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4914:\n",
            "True label: 1\n",
            "Predicted label: [0.9400896]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4915:\n",
            "True label: 1\n",
            "Predicted label: [0.9405682]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4916:\n",
            "True label: 1\n",
            "Predicted label: [0.96003294]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4917:\n",
            "True label: 1\n",
            "Predicted label: [0.9601125]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4918:\n",
            "True label: 1\n",
            "Predicted label: [0.9373019]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4919:\n",
            "True label: 1\n",
            "Predicted label: [0.9116111]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4920:\n",
            "True label: 1\n",
            "Predicted label: [0.6762804]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4921:\n",
            "True label: 1\n",
            "Predicted label: [0.6640298]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4922:\n",
            "True label: 1\n",
            "Predicted label: [0.6555538]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4923:\n",
            "True label: 1\n",
            "Predicted label: [0.7505251]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4924:\n",
            "True label: 1\n",
            "Predicted label: [0.75550795]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4925:\n",
            "True label: 1\n",
            "Predicted label: [0.7631206]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4926:\n",
            "True label: 1\n",
            "Predicted label: [0.8605125]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4927:\n",
            "True label: 1\n",
            "Predicted label: [0.8752519]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4928:\n",
            "True label: 1\n",
            "Predicted label: [0.87552327]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4929:\n",
            "True label: 1\n",
            "Predicted label: [0.82945794]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4930:\n",
            "True label: 1\n",
            "Predicted label: [0.85718846]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4931:\n",
            "True label: 1\n",
            "Predicted label: [0.87308633]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4932:\n",
            "True label: 1\n",
            "Predicted label: [0.5244846]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4933:\n",
            "True label: 1\n",
            "Predicted label: [0.71451867]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4934:\n",
            "True label: 1\n",
            "Predicted label: [0.6597958]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4935:\n",
            "True label: 1\n",
            "Predicted label: [0.5258982]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4936:\n",
            "True label: 1\n",
            "Predicted label: [0.6424073]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4937:\n",
            "True label: 1\n",
            "Predicted label: [0.61873126]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4938:\n",
            "True label: 1\n",
            "Predicted label: [0.77468324]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4939:\n",
            "True label: 1\n",
            "Predicted label: [0.753998]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4940:\n",
            "True label: 1\n",
            "Predicted label: [0.70963955]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4941:\n",
            "True label: 1\n",
            "Predicted label: [0.7491142]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4942:\n",
            "True label: 1\n",
            "Predicted label: [0.81424344]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4943:\n",
            "True label: 1\n",
            "Predicted label: [0.8798846]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4944:\n",
            "True label: 1\n",
            "Predicted label: [0.9028988]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4945:\n",
            "True label: 1\n",
            "Predicted label: [0.8685671]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4946:\n",
            "True label: 1\n",
            "Predicted label: [0.85124713]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4947:\n",
            "True label: 0\n",
            "Predicted label: [0.86626303]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4948:\n",
            "True label: 0\n",
            "Predicted label: [0.8935276]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4949:\n",
            "True label: 0\n",
            "Predicted label: [0.4846752]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4950:\n",
            "True label: 0\n",
            "Predicted label: [0.18664387]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4951:\n",
            "True label: 1\n",
            "Predicted label: [0.13217545]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4952:\n",
            "True label: 1\n",
            "Predicted label: [0.18421212]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4953:\n",
            "True label: 1\n",
            "Predicted label: [0.3041649]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4954:\n",
            "True label: 1\n",
            "Predicted label: [0.64787793]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4955:\n",
            "True label: 1\n",
            "Predicted label: [0.8315315]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4956:\n",
            "True label: 1\n",
            "Predicted label: [0.808676]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4957:\n",
            "True label: 1\n",
            "Predicted label: [0.84578323]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4958:\n",
            "True label: 1\n",
            "Predicted label: [0.68739384]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4959:\n",
            "True label: 1\n",
            "Predicted label: [0.5990023]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4960:\n",
            "True label: 0\n",
            "Predicted label: [0.48358437]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4961:\n",
            "True label: 0\n",
            "Predicted label: [0.6313649]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4962:\n",
            "True label: 0\n",
            "Predicted label: [0.5246718]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4963:\n",
            "True label: 0\n",
            "Predicted label: [0.269695]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4964:\n",
            "True label: 0\n",
            "Predicted label: [0.2863816]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4965:\n",
            "True label: 0\n",
            "Predicted label: [0.19865695]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4966:\n",
            "True label: 0\n",
            "Predicted label: [0.31186038]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4967:\n",
            "True label: 0\n",
            "Predicted label: [0.22614798]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4968:\n",
            "True label: 0\n",
            "Predicted label: [0.14323434]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4969:\n",
            "True label: 0\n",
            "Predicted label: [0.07542184]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4970:\n",
            "True label: 0\n",
            "Predicted label: [0.05969024]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4971:\n",
            "True label: 0\n",
            "Predicted label: [0.18320131]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4972:\n",
            "True label: 0\n",
            "Predicted label: [0.1858288]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4973:\n",
            "True label: 0\n",
            "Predicted label: [0.3542595]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4974:\n",
            "True label: 0\n",
            "Predicted label: [0.2130037]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4975:\n",
            "True label: 1\n",
            "Predicted label: [0.1572814]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4976:\n",
            "True label: 1\n",
            "Predicted label: [0.38565025]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4977:\n",
            "True label: 1\n",
            "Predicted label: [0.6726005]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4978:\n",
            "True label: 1\n",
            "Predicted label: [0.58451146]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4979:\n",
            "True label: 1\n",
            "Predicted label: [0.5957819]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4980:\n",
            "True label: 1\n",
            "Predicted label: [0.60763246]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4981:\n",
            "True label: 1\n",
            "Predicted label: [0.75726354]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4982:\n",
            "True label: 1\n",
            "Predicted label: [0.66931903]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4983:\n",
            "True label: 1\n",
            "Predicted label: [0.5668055]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4984:\n",
            "True label: 1\n",
            "Predicted label: [0.45670983]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4985:\n",
            "True label: 1\n",
            "Predicted label: [0.78113794]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4986:\n",
            "True label: 1\n",
            "Predicted label: [0.5498549]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4987:\n",
            "True label: 1\n",
            "Predicted label: [0.6061163]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4988:\n",
            "True label: 1\n",
            "Predicted label: [0.79508436]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4989:\n",
            "True label: 1\n",
            "Predicted label: [0.26248145]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4990:\n",
            "True label: 0\n",
            "Predicted label: [0.38604823]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4991:\n",
            "True label: 0\n",
            "Predicted label: [0.47143212]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4992:\n",
            "True label: 0\n",
            "Predicted label: [0.29118824]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4993:\n",
            "True label: 0\n",
            "Predicted label: [0.16843823]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4994:\n",
            "True label: 0\n",
            "Predicted label: [0.29083484]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4995:\n",
            "True label: 0\n",
            "Predicted label: [0.40883008]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4996:\n",
            "True label: 1\n",
            "Predicted label: [0.33966228]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4997:\n",
            "True label: 1\n",
            "Predicted label: [0.24607295]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 4998:\n",
            "True label: 1\n",
            "Predicted label: [0.61758983]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Sample 4999:\n",
            "True label: 1\n",
            "Predicted label: [0.39991936]\n",
            "Is the prediction correct? No\n",
            "---\n",
            "Sample 5000:\n",
            "True label: 1\n",
            "Predicted label: [0.7025305]\n",
            "Is the prediction correct? Yes\n",
            "---\n",
            "Total correct predictions: 3613\n"
          ]
        }
      ],
      "source": [
        "# # Evaluate the model on the entire validation dataset\n",
        "# evaluation_results = model.evaluate(val_dataset, verbose=0)\n",
        "\n",
        "# # Loop through the results and print them\n",
        "# for i, metric_name in enumerate(model.metrics_names):\n",
        "#     print(f\"Validation {metric_name}: {evaluation_results[i]}\")\n",
        "\n",
        "# # Sample a subset of the validation dataset\n",
        "# num_samples_to_inspect = 1000\n",
        "# sampled_val_dataset = val_dataset.take(num_samples_to_inspect)\n",
        "\n",
        "# y_val_true = []\n",
        "# y_val_pred = []\n",
        "# last_day_open_prices = []\n",
        "\n",
        "# # Iterate over the sampled validation dataset\n",
        "# for x_batch_val, y_batch_val in sampled_val_dataset:\n",
        "#     # Store the true labels\n",
        "#     y_val_true.extend(y_batch_val.numpy())\n",
        "\n",
        "#     # Predict the batch and store the predictions\n",
        "#     batch_pred = model.predict(x_batch_val)\n",
        "#     y_val_pred.extend(batch_pred)\n",
        "\n",
        "#     # Store the opening prices of the last day in the input sequence\n",
        "#     last_day_open_prices.extend(x_batch_val.numpy()[:, -1, 20])\n",
        "\n",
        "# # Convert the lists to numpy arrays for easier handling\n",
        "# y_val_true = np.array(y_val_true)\n",
        "# y_val_pred = np.array(y_val_pred)\n",
        "# last_day_open_prices = np.array(last_day_open_prices)\n",
        "\n",
        "# yes = 0\n",
        "\n",
        "# up = 0\n",
        "# down = 0\n",
        "\n",
        "# # Print a detailed example-by-example analysis\n",
        "# for i in range(num_samples_to_inspect):\n",
        "#     # Print the last day of the input batch\n",
        "#     print(f\"Sample {i+1}:\")\n",
        "#     print(f\"Opening price of the last day in the input sequence Sanity check X: {last_day_open_prices[i]}\")\n",
        "#     print(f\"Opening price of the last day in the input sequence: {y_val_true[i][0]}\")\n",
        "\n",
        "#     # Print the Y label\n",
        "#     print(f\"True Y label: {y_val_true[i][1]}\")\n",
        "\n",
        "#     # Print the predicted label\n",
        "#     print(f\"Predicted Y label: {y_val_pred[i]}\")\n",
        "\n",
        "\n",
        "\n",
        "#     # Calculate and print whether the predicted label followed the same direction as the Y label\n",
        "#     actual_direction = 'Up' if y_val_true[i][1] > y_val_true[i][0] else 'Down'\n",
        "#     predicted_direction = 'Up' if y_val_pred[i] > y_val_true[i][0] else 'Down'\n",
        "#     correct_prediction = actual_direction == predicted_direction\n",
        "\n",
        "#     if actual_direction == 'Up':\n",
        "#       up += 1\n",
        "#     else:\n",
        "#       down += 1\n",
        "\n",
        "#     if correct_prediction:\n",
        "#       yes += 1\n",
        "\n",
        "#     print(f\"Up Count: {up}, Down Count: {down}\")\n",
        "#     print(f\"Did the prediction follow the actual direction? {'Yes' if correct_prediction else 'No'}\")\n",
        "#     print(f\"Total correct: {yes}\")\n",
        "#     print(\"---\")\n",
        "\n",
        "\n",
        "# Sample a subset of the validation dataset\n",
        "num_samples_to_predict = 5000\n",
        "sampled_val_dataset = val_dataset.take(num_samples_to_predict)\n",
        "\n",
        "y_val_true = []\n",
        "y_val_pred = []\n",
        "\n",
        "# Iterate over the sampled validation dataset\n",
        "for x_batch_val, y_batch_val in sampled_val_dataset:\n",
        "    # Store the true labels\n",
        "    y_val_true.extend(y_batch_val.numpy())\n",
        "\n",
        "    # Predict the batch and store the predictions\n",
        "    batch_pred = model.predict(x_batch_val)\n",
        "    y_val_pred.extend(batch_pred)\n",
        "\n",
        "# Convert the lists to numpy arrays for easier handling\n",
        "y_val_true = np.array(y_val_true)\n",
        "y_val_pred = np.array(y_val_pred)\n",
        "\n",
        "correct_predictions = 0\n",
        "\n",
        "# Print a detailed example-by-example analysis\n",
        "for i in range(num_samples_to_predict):\n",
        "    # Print the true and predicted labels\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"True label: {y_val_true[i]}\")\n",
        "    print(f\"Predicted label: {y_val_pred[i]}\")\n",
        "\n",
        "    # Calculate and print whether the predicted label is the same as the true label\n",
        "    correct_prediction = np.allclose(y_val_true[i], y_val_pred[i], atol=0.4)  # tolerance can be adjusted\n",
        "    if correct_prediction:\n",
        "        correct_predictions += 1\n",
        "\n",
        "    print(f\"Is the prediction correct? {'Yes' if correct_prediction else 'No'}\")\n",
        "    print(\"---\")\n",
        "\n",
        "print(f\"Total correct predictions: {correct_predictions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVRexsSjWOjC",
        "outputId": "56a63d9b-a291-4867-f2fa-8d352319ebe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "    Training:   Loss: 0.1202, directional_accuracy: 0.4935\n",
            "    Validation: Loss: 0.0192, directional_accuracy: 0.5203\n",
            "\n",
            "Epoch 2:\n",
            "    Training:   Loss: 0.0306, directional_accuracy: 0.4962\n",
            "    Validation: Loss: 0.0047, directional_accuracy: 0.5478\n",
            "\n",
            "Epoch 3:\n",
            "    Training:   Loss: 0.0184, directional_accuracy: 0.5014\n",
            "    Validation: Loss: 0.0128, directional_accuracy: 0.5718\n",
            "\n",
            "Epoch 4:\n",
            "    Training:   Loss: 0.0130, directional_accuracy: 0.5062\n",
            "    Validation: Loss: 0.0113, directional_accuracy: 0.5389\n",
            "\n",
            "Epoch 5:\n",
            "    Training:   Loss: 0.0105, directional_accuracy: 0.5057\n",
            "    Validation: Loss: 0.0394, directional_accuracy: 0.5836\n",
            "\n",
            "Epoch 6:\n",
            "    Training:   Loss: 0.0086, directional_accuracy: 0.5107\n",
            "    Validation: Loss: 0.0084, directional_accuracy: 0.5375\n",
            "\n",
            "Epoch 7:\n",
            "    Training:   Loss: 0.0072, directional_accuracy: 0.5133\n",
            "    Validation: Loss: 0.0153, directional_accuracy: 0.5104\n",
            "\n",
            "Epoch 8:\n",
            "    Training:   Loss: 0.0064, directional_accuracy: 0.5124\n",
            "    Validation: Loss: 0.0069, directional_accuracy: 0.5784\n",
            "\n",
            "Epoch 9:\n",
            "    Training:   Loss: 0.0060, directional_accuracy: 0.5118\n",
            "    Validation: Loss: 0.0245, directional_accuracy: 0.5812\n",
            "\n",
            "Epoch 10:\n",
            "    Training:   Loss: 0.0053, directional_accuracy: 0.5143\n",
            "    Validation: Loss: 0.0096, directional_accuracy: 0.5437\n",
            "\n",
            "Epoch 11:\n",
            "    Training:   Loss: 0.0045, directional_accuracy: 0.5139\n",
            "    Validation: Loss: 0.0222, directional_accuracy: 0.5647\n",
            "\n",
            "Epoch 12:\n",
            "    Training:   Loss: 0.0046, directional_accuracy: 0.5129\n",
            "    Validation: Loss: 0.0155, directional_accuracy: 0.5798\n",
            "\n",
            "Epoch 13:\n",
            "    Training:   Loss: 0.0040, directional_accuracy: 0.5171\n",
            "    Validation: Loss: 0.0095, directional_accuracy: 0.5857\n",
            "\n",
            "Epoch 14:\n",
            "    Training:   Loss: 0.0036, directional_accuracy: 0.5171\n",
            "    Validation: Loss: 0.0081, directional_accuracy: 0.5759\n",
            "\n",
            "Epoch 15:\n",
            "    Training:   Loss: 0.0034, directional_accuracy: 0.5164\n",
            "    Validation: Loss: 0.0090, directional_accuracy: 0.5528\n",
            "\n",
            "Epoch 16:\n",
            "    Training:   Loss: 0.0031, directional_accuracy: 0.5205\n",
            "    Validation: Loss: 0.0068, directional_accuracy: 0.5894\n",
            "\n",
            "Epoch 17:\n",
            "    Training:   Loss: 0.0031, directional_accuracy: 0.5179\n",
            "    Validation: Loss: 0.0081, directional_accuracy: 0.5429\n",
            "\n",
            "Epoch 18:\n",
            "    Training:   Loss: 0.0029, directional_accuracy: 0.5206\n",
            "    Validation: Loss: 0.0072, directional_accuracy: 0.5688\n",
            "\n",
            "Epoch 19:\n",
            "    Training:   Loss: 0.0027, directional_accuracy: 0.5150\n",
            "    Validation: Loss: 0.0123, directional_accuracy: 0.5775\n",
            "\n",
            "Epoch 20:\n",
            "    Training:   Loss: 0.0025, directional_accuracy: 0.5245\n",
            "    Validation: Loss: 0.0040, directional_accuracy: 0.5883\n",
            "\n",
            "Epoch 21:\n",
            "    Training:   Loss: 0.0024, directional_accuracy: 0.5203\n",
            "    Validation: Loss: 0.0183, directional_accuracy: 0.5774\n",
            "\n",
            "Epoch 22:\n",
            "    Training:   Loss: 0.0023, directional_accuracy: 0.5229\n",
            "    Validation: Loss: 0.0082, directional_accuracy: 0.5399\n",
            "\n",
            "Epoch 23:\n",
            "    Training:   Loss: 0.0022, directional_accuracy: 0.5232\n",
            "    Validation: Loss: 0.0104, directional_accuracy: 0.5479\n",
            "\n",
            "Epoch 24:\n",
            "    Training:   Loss: 0.0021, directional_accuracy: 0.5251\n",
            "    Validation: Loss: 0.0166, directional_accuracy: 0.5970\n",
            "\n",
            "Epoch 25:\n",
            "    Training:   Loss: 0.0020, directional_accuracy: 0.5259\n",
            "    Validation: Loss: 0.0128, directional_accuracy: 0.5479\n",
            "\n",
            "Epoch 26:\n",
            "    Training:   Loss: 0.0019, directional_accuracy: 0.5262\n",
            "    Validation: Loss: 0.0085, directional_accuracy: 0.5929\n",
            "\n",
            "Epoch 27:\n",
            "    Training:   Loss: 0.0019, directional_accuracy: 0.5306\n",
            "    Validation: Loss: 0.0097, directional_accuracy: 0.5398\n",
            "\n",
            "Epoch 28:\n",
            "    Training:   Loss: 0.0018, directional_accuracy: 0.5286\n",
            "    Validation: Loss: 0.0102, directional_accuracy: 0.5894\n",
            "\n",
            "Epoch 29:\n",
            "    Training:   Loss: 0.0017, directional_accuracy: 0.5295\n",
            "    Validation: Loss: 0.0098, directional_accuracy: 0.6403\n",
            "\n",
            "Epoch 30:\n",
            "    Training:   Loss: 0.0016, directional_accuracy: 0.5303\n",
            "    Validation: Loss: 0.0067, directional_accuracy: 0.5742\n",
            "\n",
            "Epoch 31:\n",
            "    Training:   Loss: 0.0016, directional_accuracy: 0.5306\n",
            "    Validation: Loss: 0.0034, directional_accuracy: 0.5794\n",
            "\n",
            "Epoch 32:\n",
            "    Training:   Loss: 0.0016, directional_accuracy: 0.5318\n",
            "    Validation: Loss: 0.0037, directional_accuracy: 0.6119\n",
            "\n",
            "Epoch 33:\n",
            "    Training:   Loss: 0.0015, directional_accuracy: 0.5305\n",
            "    Validation: Loss: 0.0049, directional_accuracy: 0.6102\n",
            "\n",
            "Epoch 34:\n",
            "    Training:   Loss: 0.0015, directional_accuracy: 0.5313\n",
            "    Validation: Loss: 0.0097, directional_accuracy: 0.5683\n",
            "\n",
            "Epoch 35:\n",
            "    Training:   Loss: 0.0013, directional_accuracy: 0.5343\n",
            "    Validation: Loss: 0.0057, directional_accuracy: 0.5909\n",
            "\n",
            "Epoch 36:\n",
            "    Training:   Loss: 0.0013, directional_accuracy: 0.5339\n",
            "    Validation: Loss: 0.0060, directional_accuracy: 0.6098\n",
            "\n",
            "Epoch 37:\n",
            "    Training:   Loss: 0.0014, directional_accuracy: 0.5363\n",
            "    Validation: Loss: 0.0037, directional_accuracy: 0.6472\n",
            "\n",
            "Epoch 38:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5372\n",
            "    Validation: Loss: 0.0074, directional_accuracy: 0.5391\n",
            "\n",
            "Epoch 39:\n",
            "    Training:   Loss: 0.0013, directional_accuracy: 0.5326\n",
            "    Validation: Loss: 0.0076, directional_accuracy: 0.5951\n",
            "\n",
            "Epoch 40:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5352\n",
            "    Validation: Loss: 0.0064, directional_accuracy: 0.5446\n",
            "\n",
            "Epoch 41:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5385\n",
            "    Validation: Loss: 0.0053, directional_accuracy: 0.5522\n",
            "\n",
            "Epoch 42:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5311\n",
            "    Validation: Loss: 0.0075, directional_accuracy: 0.5563\n",
            "\n",
            "Epoch 43:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5376\n",
            "    Validation: Loss: 0.0036, directional_accuracy: 0.5421\n",
            "\n",
            "Epoch 44:\n",
            "    Training:   Loss: 0.0012, directional_accuracy: 0.5352\n",
            "    Validation: Loss: 0.0071, directional_accuracy: 0.5816\n",
            "\n",
            "Epoch 45:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5381\n",
            "    Validation: Loss: 0.0044, directional_accuracy: 0.6152\n",
            "\n",
            "Epoch 46:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5378\n",
            "    Validation: Loss: 0.0054, directional_accuracy: 0.6152\n",
            "\n",
            "Epoch 47:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5383\n",
            "    Validation: Loss: 0.0055, directional_accuracy: 0.6468\n",
            "\n",
            "Epoch 48:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5368\n",
            "    Validation: Loss: 0.0045, directional_accuracy: 0.6239\n",
            "\n",
            "Epoch 49:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5402\n",
            "    Validation: Loss: 0.0091, directional_accuracy: 0.5799\n",
            "\n",
            "Epoch 50:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5426\n",
            "    Validation: Loss: 0.0030, directional_accuracy: 0.6851\n",
            "\n",
            "Epoch 51:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5410\n",
            "    Validation: Loss: 0.0053, directional_accuracy: 0.5952\n",
            "\n",
            "Epoch 52:\n",
            "    Training:   Loss: 0.0011, directional_accuracy: 0.5399\n",
            "    Validation: Loss: 0.0058, directional_accuracy: 0.6408\n",
            "\n",
            "Epoch 53:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5416\n",
            "    Validation: Loss: 0.0062, directional_accuracy: 0.5553\n",
            "\n",
            "Epoch 54:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5410\n",
            "    Validation: Loss: 0.0041, directional_accuracy: 0.5547\n",
            "\n",
            "Epoch 55:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5392\n",
            "    Validation: Loss: 0.0039, directional_accuracy: 0.5441\n",
            "\n",
            "Epoch 56:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5436\n",
            "    Validation: Loss: 0.0057, directional_accuracy: 0.4917\n",
            "\n",
            "Epoch 57:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5427\n",
            "    Validation: Loss: 0.0129, directional_accuracy: 0.4981\n",
            "\n",
            "Epoch 58:\n",
            "    Training:   Loss: 0.0010, directional_accuracy: 0.5442\n",
            "    Validation: Loss: 0.0058, directional_accuracy: 0.5927\n",
            "\n",
            "Epoch 59:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5437\n",
            "    Validation: Loss: 0.0057, directional_accuracy: 0.5769\n",
            "\n",
            "Epoch 60:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5416\n",
            "    Validation: Loss: 0.0056, directional_accuracy: 0.5924\n",
            "\n",
            "Epoch 61:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5465\n",
            "    Validation: Loss: 0.0062, directional_accuracy: 0.5669\n",
            "\n",
            "Epoch 62:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5458\n",
            "    Validation: Loss: 0.0074, directional_accuracy: 0.5855\n",
            "\n",
            "Epoch 63:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5445\n",
            "    Validation: Loss: 0.0055, directional_accuracy: 0.5981\n",
            "\n",
            "Epoch 64:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5490\n",
            "    Validation: Loss: 0.0060, directional_accuracy: 0.5855\n",
            "\n",
            "Epoch 65:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5493\n",
            "    Validation: Loss: 0.0060, directional_accuracy: 0.5958\n",
            "\n",
            "Epoch 66:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5472\n",
            "    Validation: Loss: 0.0068, directional_accuracy: 0.5748\n",
            "\n",
            "Epoch 67:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5451\n",
            "    Validation: Loss: 0.0048, directional_accuracy: 0.5970\n",
            "\n",
            "Epoch 68:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5481\n",
            "    Validation: Loss: 0.0044, directional_accuracy: 0.5801\n",
            "\n",
            "Epoch 69:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5506\n",
            "    Validation: Loss: 0.0035, directional_accuracy: 0.6301\n",
            "\n",
            "Epoch 70:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5465\n",
            "    Validation: Loss: 0.0054, directional_accuracy: 0.6902\n",
            "\n",
            "Epoch 71:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5493\n",
            "    Validation: Loss: 0.0055, directional_accuracy: 0.6798\n",
            "\n",
            "Epoch 72:\n",
            "    Training:   Loss: 0.0009, directional_accuracy: 0.5508\n",
            "    Validation: Loss: 0.0078, directional_accuracy: 0.5754\n",
            "\n",
            "Epoch 73:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5523\n",
            "    Validation: Loss: 0.0065, directional_accuracy: 0.5972\n",
            "\n",
            "Epoch 74:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5493\n",
            "    Validation: Loss: 0.0094, directional_accuracy: 0.5905\n",
            "\n",
            "Epoch 75:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5509\n",
            "    Validation: Loss: 0.0039, directional_accuracy: 0.5955\n",
            "\n",
            "Epoch 76:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5498\n",
            "    Validation: Loss: 0.0078, directional_accuracy: 0.5823\n",
            "\n",
            "Epoch 77:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5499\n",
            "    Validation: Loss: 0.0064, directional_accuracy: 0.6049\n",
            "\n",
            "Epoch 78:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5520\n",
            "    Validation: Loss: 0.0055, directional_accuracy: 0.6678\n",
            "\n",
            "Epoch 79:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5497\n",
            "    Validation: Loss: 0.0071, directional_accuracy: 0.5961\n",
            "\n",
            "Epoch 80:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5536\n",
            "    Validation: Loss: 0.0096, directional_accuracy: 0.5734\n",
            "\n",
            "Epoch 81:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5514\n",
            "    Validation: Loss: 0.0061, directional_accuracy: 0.6064\n",
            "\n",
            "Epoch 82:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5533\n",
            "    Validation: Loss: 0.0038, directional_accuracy: 0.6139\n",
            "\n",
            "Epoch 83:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5512\n",
            "    Validation: Loss: 0.0085, directional_accuracy: 0.5796\n",
            "\n",
            "Epoch 84:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5551\n",
            "    Validation: Loss: 0.0061, directional_accuracy: 0.6148\n",
            "\n",
            "Epoch 85:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5569\n",
            "    Validation: Loss: 0.0061, directional_accuracy: 0.5676\n",
            "\n",
            "Epoch 86:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5549\n",
            "    Validation: Loss: 0.0044, directional_accuracy: 0.6538\n",
            "\n",
            "Epoch 87:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5606\n",
            "    Validation: Loss: 0.0061, directional_accuracy: 0.5365\n",
            "\n",
            "Epoch 88:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5613\n",
            "    Validation: Loss: 0.0065, directional_accuracy: 0.5897\n",
            "\n",
            "Epoch 89:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5547\n",
            "    Validation: Loss: 0.0057, directional_accuracy: 0.5681\n",
            "\n",
            "Epoch 90:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5569\n",
            "    Validation: Loss: 0.0066, directional_accuracy: 0.5969\n",
            "\n",
            "Epoch 91:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5532\n",
            "    Validation: Loss: 0.0067, directional_accuracy: 0.5855\n",
            "\n",
            "Epoch 92:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5543\n",
            "    Validation: Loss: 0.0026, directional_accuracy: 0.7354\n",
            "\n",
            "Epoch 93:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5537\n",
            "    Validation: Loss: 0.0114, directional_accuracy: 0.5504\n",
            "\n",
            "Epoch 94:\n",
            "    Training:   Loss: 0.0008, directional_accuracy: 0.5531\n",
            "    Validation: Loss: 0.0078, directional_accuracy: 0.6131\n",
            "\n",
            "Epoch 95:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5552\n",
            "    Validation: Loss: 0.0048, directional_accuracy: 0.6043\n",
            "\n",
            "Epoch 96:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5516\n",
            "    Validation: Loss: 0.0117, directional_accuracy: 0.6066\n",
            "\n",
            "Epoch 97:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5529\n",
            "    Validation: Loss: 0.0093, directional_accuracy: 0.6210\n",
            "\n",
            "Epoch 98:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5569\n",
            "    Validation: Loss: 0.0077, directional_accuracy: 0.5900\n",
            "\n",
            "Epoch 99:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5569\n",
            "    Validation: Loss: 0.0057, directional_accuracy: 0.5956\n",
            "\n",
            "Epoch 100:\n",
            "    Training:   Loss: 0.0007, directional_accuracy: 0.5560\n",
            "    Validation: Loss: 0.0046, directional_accuracy: 0.5993\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to print the results for each epoch\n",
        "def print_history_stats(history):\n",
        "    for epoch, stats in enumerate(zip(history.history['loss'], history.history['directional_accuracy'], history.history['val_loss'], history.history['val_directional_accuracy']), start=1):\n",
        "        train_loss, train_da, val_loss, val_da = stats\n",
        "        print(f\"Epoch {epoch}:\")\n",
        "\n",
        "        print(f\"    Training:   Loss: {train_loss:.4f}, directional_accuracy: {train_da:.4f}\")\n",
        "        print(f\"    Validation: Loss: {val_loss:.4f}, directional_accuracy: {val_da:.4f}\\n\")\n",
        "\n",
        "# Call the function with the history object\n",
        "print_history_stats(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "UoR1C_A3yQCA",
        "outputId": "64a38eeb-2d53-4ec1-cf45-71c59b8c3e4c"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a0e975eef5b4>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Directional Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'directional_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Directional Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_directional_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Directional Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and Validation Directional Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'directional_accuracy'"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+EAAAGzCAYAAABAYBYzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACw5klEQVR4nOzdd3hU1dbH8e9Meg+hhBYIHUILXVCKGqSJgg0VpSj6WrDFgsgVFFHutaJYsAE2lKsioiL1ggVRmghK7zWhJiEhZJLMvH+czJBACClTksnv8zx55uTkzD57YChr1tprm2w2mw0RERERERERcTmzpycgIiIiIiIiUlkoCBcRERERERFxEwXhIiIiIiIiIm6iIFxERERERETETRSEi4iIiIiIiLiJgnARERERERERN1EQLiIiIiIiIuImCsJFRERERERE3ERBuIiIiIiIiIibKAiXSmHEiBHExsaW6rnPPPMMJpPJuRMqZ/bs2YPJZGLmzJluv7fJZOKZZ55xfD9z5kxMJhN79uy56HNjY2MZMWKEU+dTlveKiIiIiMjFKAgXjzKZTMX6Wr58uaenWuk9+OCDmEwmduzYccFrxo0bh8lkYsOGDW6cWckdOnSIZ555hvXr13t6Kg72D0JefvllT09FRERERFzI19MTkMrtk08+KfD9xx9/zOLFi88736JFizLd5/3338dqtZbquf/617948skny3R/bzB06FCmTp3KrFmzGD9+fKHXfP7557Ru3Zo2bdqU+j633347N998MwEBAaUe42IOHTrEs88+S2xsLPHx8QV+Vpb3ioiIiIjIxSgIF4+67bbbCnz/+++/s3jx4vPOn+v06dMEBwcX+z5+fn6lmh+Ar68vvr76o9KlSxcaN27M559/XmgQvnLlSnbv3s2///3vMt3Hx8cHHx+fMo1RFmV5r4iIiIiIXIzK0aXc69WrF61atWLt2rX06NGD4OBgnnrqKQC+/fZbBgwYQO3atQkICKBRo0Y899xz5ObmFhjj3HW++Ut/33vvPRo1akRAQACdOnVi9erVBZ5b2Jpwk8nE6NGjmTt3Lq1atSIgIICWLVuyYMGC8+a/fPlyOnbsSGBgII0aNeLdd98t9jrzX375hRtvvJF69eoREBBATEwMjzzyCJmZmee9vtDQUA4ePMigQYMIDQ2levXqPPbYY+f9WqSkpDBixAgiIiKIjIxk+PDhpKSkXHQuYGTDt2zZwrp168772axZszCZTNxyyy1YLBbGjx9Phw4diIiIICQkhO7du7Ns2bKL3qOwNeE2m41JkyZRt25dgoODufzyy/nnn3/Oe+6JEyd47LHHaN26NaGhoYSHh9OvXz/++usvxzXLly+nU6dOAIwcOdKx5MG+Hr6wNeEZGRk8+uijxMTEEBAQQLNmzXj55Zex2WwFrivJ+6K0jhw5wp133kl0dDSBgYG0bduWjz766LzrvvjiCzp06EBYWBjh4eG0bt2a119/3fHz7Oxsnn32WZo0aUJgYCBVq1blsssuY/HixU6bq4iIiIicT+k9qRCOHz9Ov379uPnmm7ntttuIjo4GjIAtNDSUxMREQkND+d///sf48eNJS0vjpZdeuui4s2bN4tSpU/zf//0fJpOJF198keuuu45du3ZdNCP666+/MmfOHO677z7CwsJ44403uP7669m3bx9Vq1YF4M8//6Rv377UqlWLZ599ltzcXCZOnEj16tWL9bq//PJLTp8+zb333kvVqlVZtWoVU6dO5cCBA3z55ZcFrs3NzaVPnz506dKFl19+mSVLlvDKK6/QqFEj7r33XsAIZq+99lp+/fVX7rnnHlq0aME333zD8OHDizWfoUOH8uyzzzJr1izat29f4N7//e9/6d69O/Xq1ePYsWN88MEH3HLLLdx1112cOnWKDz/8kD59+rBq1arzSsAvZvz48UyaNIn+/fvTv39/1q1bx1VXXYXFYilw3a5du5g7dy433ngjDRo0IDk5mXfffZeePXuyadMmateuTYsWLZg4cSLjx4/n7rvvpnv37gB069at0HvbbDauueYali1bxp133kl8fDwLFy7k8ccf5+DBg7z22msFri/O+6K0MjMz6dWrFzt27GD06NE0aNCAL7/8khEjRpCSksJDDz0EwOLFi7nlllu48sor+c9//gPA5s2bWbFiheOaZ555hsmTJzNq1Cg6d+5MWloaa9asYd26dfTu3btM8xQRERGRIthEypH777/fdu7bsmfPnjbANm3atPOuP3369Hnn/u///s8WHBxsO3PmjOPc8OHDbfXr13d8v3v3bhtgq1q1qu3EiROO899++60NsH333XeOcxMmTDhvToDN39/ftmPHDse5v/76ywbYpk6d6jg3cOBAW3BwsO3gwYOOc9u3b7f5+vqeN2ZhCnt9kydPtplMJtvevXsLvD7ANnHixALXtmvXztahQwfH93PnzrUBthdffNFxLicnx9a9e3cbYJsxY8ZF59SpUydb3bp1bbm5uY5zCxYssAG2d9991zFmVlZWgeedPHnSFh0dbbvjjjsKnAdsEyZMcHw/Y8YMG2DbvXu3zWaz2Y4cOWLz9/e3DRgwwGa1Wh3XPfXUUzbANnz4cMe5M2fOFJiXzWb8XgcEBBT4tVm9evUFX++57xX7r9mkSZMKXHfDDTfYTCZTgfdAcd8XhbG/J1966aULXjNlyhQbYPv0008d5ywWi61r16620NBQW1pams1ms9keeughW3h4uC0nJ+eCY7Vt29Y2YMCAIuckIiIiIs6ncnSpEAICAhg5cuR554OCghzHp06d4tixY3Tv3p3Tp0+zZcuWi447ZMgQqlSp4vjenhXdtWvXRZ+bkJBAo0aNHN+3adOG8PBwx3Nzc3NZsmQJgwYNonbt2o7rGjduTL9+/S46PhR8fRkZGRw7doxu3bphs9n4888/z7v+nnvuKfB99+7dC7yW+fPn4+vr68iMg7EG+4EHHijWfMBYx3/gwAF+/vlnx7lZs2bh7+/PjTfe6BjT398fAKvVyokTJ8jJyaFjx46FlrIXZcmSJVgsFh544IECJfwPP/zwedcGBARgNht/reXm5nL8+HFCQ0Np1qxZie9rN3/+fHx8fHjwwQcLnH/00Uex2Wz8+OOPBc5f7H1RFvPnz6dmzZrccsstjnN+fn48+OCDpKen89NPPwEQGRlJRkZGkaXlkZGR/PPPP2zfvr3M8xIRERGR4lMQLhVCnTp1HEFdfv/88w+DBw8mIiKC8PBwqlev7mjqlpqaetFx69WrV+B7e0B+8uTJEj/X/nz7c48cOUJmZiaNGzc+77rCzhVm3759jBgxgqioKMc67549ewLnv77AwMDzytzzzwdg79691KpVi9DQ0ALXNWvWrFjzAbj55pvx8fFh1qxZAJw5c4ZvvvmGfv36FfhA46OPPqJNmzaO9cbVq1fnhx9+KNbvS3579+4FoEmTJgXOV69evcD9wAj4X3vtNZo0aUJAQADVqlWjevXqbNiwocT3zX//2rVrExYWVuC8vWO/fX52F3tflMXevXtp0qSJ44OGC83lvvvuo2nTpvTr14+6detyxx13nLcufeLEiaSkpNC0aVNat27N448/Xu63lhMRERHxBgrCpULInxG2S0lJoWfPnvz1119MnDiR7777jsWLFzvWwBZnm6kLdeG2ndNwy9nPLY7c3Fx69+7NDz/8wJgxY5g7dy6LFy92NBA79/W5q6N4jRo16N27N19//TXZ2dl89913nDp1iqFDhzqu+fTTTxkxYgSNGjXiww8/ZMGCBSxevJgrrrjCpdt/vfDCCyQmJtKjRw8+/fRTFi5cyOLFi2nZsqXbth1z9fuiOGrUqMH69euZN2+eYz17v379Cqz979GjBzt37mT69Om0atWKDz74gPbt2/PBBx+4bZ4iIiIilZEas0mFtXz5co4fP86cOXPo0aOH4/zu3bs9OKuzatSoQWBgIDt27DjvZ4WdO9fGjRvZtm0bH330EcOGDXOcL0v36vr167N06VLS09MLZMO3bt1aonGGDh3KggUL+PHHH5k1axbh4eEMHDjQ8fOvvvqKhg0bMmfOnAIl5BMmTCjVnAG2b99Ow4YNHeePHj16Xnb5q6++4vLLL+fDDz8scD4lJYVq1ao5vi9OZ/r891+yZAmnTp0qkA23L3ewz88d6tevz4YNG7BarQWy4YXNxd/fn4EDBzJw4ECsViv33Xcf7777Lk8//bSjEiMqKoqRI0cycuRI0tPT6dGjB8888wyjRo1y22sSERERqWyUCZcKy55xzJ9htFgsvP32256aUgE+Pj4kJCQwd+5cDh065Di/Y8eO89YRX+j5UPD12Wy2AttMlVT//v3JycnhnXfecZzLzc1l6tSpJRpn0KBBBAcH8/bbb/Pjjz9y3XXXERgYWOTc//jjD1auXFniOSckJODn58fUqVMLjDdlypTzrvXx8Tkv4/zll19y8ODBAudCQkIAirU1W//+/cnNzeXNN98scP61117DZDIVe32/M/Tv35+kpCRmz57tOJeTk8PUqVMJDQ11LFU4fvx4geeZzWbatGkDQFZWVqHXhIaG0rhxY8fPRURERMQ1lAmXCqtbt25UqVKF4cOH8+CDD2Iymfjkk0/cWvZ7Mc888wyLFi3i0ksv5d5773UEc61atWL9+vVFPrd58+Y0atSIxx57jIMHDxIeHs7XX39dprXFAwcO5NJLL+XJJ59kz549xMXFMWfOnBKvlw4NDWXQoEGOdeH5S9EBrr76aubMmcPgwYMZMGAAu3fvZtq0acTFxZGenl6ie9n3O588eTJXX301/fv3588//+THH38skN2233fixImMHDmSbt26sXHjRj777LMCGXSARo0aERkZybRp0wgLCyMkJIQuXbrQoEGD8+4/cOBALr/8csaNG8eePXto27YtixYt4ttvv+Xhhx8u0ITNGZYuXcqZM2fOOz9o0CDuvvtu3n33XUaMGMHatWuJjY3lq6++YsWKFUyZMsWRqR81ahQnTpzgiiuuoG7duuzdu5epU6cSHx/vWD8eFxdHr1696NChA1FRUaxZs4avvvqK0aNHO/X1iIiIiEhBCsKlwqpatSrff/89jz76KP/617+oUqUKt912G1deeSV9+vTx9PQA6NChAz/++COPPfYYTz/9NDExMUycOJHNmzdftHu7n58f3333HQ8++CCTJ08mMDCQwYMHM3r0aNq2bVuq+ZjNZubNm8fDDz/Mp59+islk4pprruGVV16hXbt2JRpr6NChzJo1i1q1anHFFVcU+NmIESNISkri3XffZeHChcTFxfHpp5/y5Zdfsnz58hLPe9KkSQQGBjJt2jSWLVtGly5dWLRoEQMGDChw3VNPPUVGRgazZs1i9uzZtG/fnh9++IEnn3yywHV+fn589NFHjB07lnvuuYecnBxmzJhRaBBu/zUbP348s2fPZsaMGcTGxvLSSy/x6KOPlvi1XMyCBQvOa6IGEBsbS6tWrVi+fDlPPvkkH330EWlpaTRr1owZM2YwYsQIx7W33XYb7733Hm+//TYpKSnUrFmTIUOG8MwzzzjK2B988EHmzZvHokWLyMrKon79+kyaNInHH3/c6a9JRERERM4y2cpT2lCkkhg0aJC2hxIRERERqYS0JlzExTIzMwt8v337dubPn0+vXr08MyEREREREfEYZcJFXKxWrVqMGDGChg0bsnfvXt555x2ysrL4888/z9v7WkREREREvJvWhIu4WN++ffn8889JSkoiICCArl278sILLygAFxERERGphFSOLuJiM2bMYM+ePZw5c4bU1FQWLFhA+/btPT0tERGn+vnnnxk4cCC1a9fGZDIxd+7ciz5n+fLltG/fnoCAABo3bszMmTNdPk8RERFPUxAuIiIiZZaRkUHbtm156623inX97t27GTBgAJdffjnr16/n4YcfZtSoUSxcuNDFMxUREfEsrQkXERERpzKZTHzzzTcMGjTogteMGTOGH374gb///ttx7uabbyYlJaXQbfpERES8hdaEF8JqtXLo0CHCwsIwmUyeno6IiHgZm83GqVOnqF27tmPv9spm5cqVJCQkFDjXp08fHn744Qs+Jysri6ysLMf3VquVEydOULVqVf17LSIiLuGKf7MVhBfi0KFDxMTEeHoaIiLi5fbv30/dunU9PQ2PSEpKIjo6usC56Oho0tLSyMzMJCgo6LznTJ48mWeffdZdUxQREXFw5r/ZCsILERYWBhi/0OHh4R6ejYiIeJu0tDRiYmIc/95I8YwdO5bExETH96mpqdSrV0//XouIiMu44t9sBeGFsJe0hYeH6x91ERFxmcpcQl2zZk2Sk5MLnEtOTiY8PLzQLDhAQEAAAQEB553Xv9ciIuJqzvw3u3IuRBMRERGP6tq1K0uXLi1wbvHixXTt2tVDMxIREXEPBeEiIiJSZunp6axfv57169cDxhZk69evZ9++fYBRSj5s2DDH9ffccw+7du3iiSeeYMuWLbz99tv897//5ZFHHvHE9EVERNxGQbiIiIiU2Zo1a2jXrh3t2rUDIDExkXbt2jF+/HgADh8+7AjIARo0aMAPP/zA4sWLadu2La+88goffPABffr08cj8RURE3EX7hBciLS2NiIgIUlNTtcZMxMvZbDZycnLIzc319FTEy/j5+eHj41Poz/TvjHPo11FERFzNFf/WqDGbiFRaFouFw4cPc/r0aU9PRbyQyWSibt26hIaGenoqIiIiUo4oCBeRSslqtbJ79258fHyoXbs2/v7+lbpTtTiXzWbj6NGjHDhwgCZNmlwwIy4iIiKVj4JwEamULBYLVquVmJgYgoODPT0d8ULVq1dnz549ZGdnKwgXERERBzVmE5FKzWzWX4PiGqqsEBERkcLof58iIiIiIiIibqIgXERERERERMRNFISLiFRysbGxTJkypdjXL1++HJPJREpKisvmJCIiIuKtFIRXZrk5sGU+nD7h6ZmISDGYTKYiv5555plSjbt69WruvvvuYl/frVs3Dh8+TERERKnuV1wK9kVERMQbqTt6Zbble/hyOLS7Ha5909OzEZGLOHz4sON49uzZjB8/nq1btzrO5d+P2mazkZubi6/vxf+ar169eonm4e/vT82aNUv0HBERERExKBNemaXuNx5T9np2HiLlgM1m47QlxyNfNputWHOsWbOm4ysiIgKTyeT4fsuWLYSFhfHjjz/SoUMHAgIC+PXXX9m5cyfXXnst0dHRhIaG0qlTJ5YsWVJg3HPL0U0mEx988AGDBw8mODiYJk2aMG/ePMfPz81Qz5w5k8jISBYuXEiLFi0IDQ2lb9++BT40yMnJ4cEHHyQyMpKqVasyZswYhg8fzqBBg0r9e3by5EmGDRtGlSpVCA4Opl+/fmzfvt3x87179zJw4ECqVKlCSEgILVu2ZP78+Y7nDh06lOrVqxMUFESTJk2YMWNGqeciIiIiUlzKhFdmWaeMxzOpnp2HSDmQmZ1L3PiFHrn3pol9CPZ3zl/HTz75JC+//DINGzakSpUq7N+/n/79+/P8888TEBDAxx9/zMCBA9m6dSv16tW74DjPPvssL774Ii+99BJTp05l6NCh7N27l6ioqEKvP336NC+//DKffPIJZrOZ2267jccee4zPPvsMgP/85z989tlnzJgxgxYtWvD6668zd+5cLr/88lK/1hEjRrB9+3bmzZtHeHg4Y8aMoX///mzatAk/Pz/uv/9+LBYLP//8MyEhIWzatMlRLfD000+zadMmfvzxR6pVq8aOHTvIzMws9VxEREREiktBeGWWlW48ZqZ4dBoi4jwTJ06kd+/eju+joqJo27at4/vnnnuOb775hnnz5jF69OgLjjNixAhuueUWAF544QXeeOMNVq1aRd++fQu9Pjs7m2nTptGoUSMARo8ezcSJEx0/nzp1KmPHjmXw4MEAvPnmm46sdGnYg+8VK1bQrVs3AD777DNiYmKYO3cuN954I/v27eP666+ndevWADRs2NDx/H379tGuXTs6duwIGNUAIiIiIu6gILwyy0ozHpUJFyHIz4dNE/t47N7OYg8q7dLT03nmmWf44YcfOHz4MDk5OWRmZrJv374ix2nTpo3jOCQkhPDwcI4cOXLB64ODgx0BOECtWrUc16emppKcnEznzp0dP/fx8aFDhw5YrdYSvT67zZs34+vrS5cuXRznqlatSrNmzdi8eTMADz74IPfeey+LFi0iISGB66+/3vG67r33Xq6//nrWrVvHVVddxaBBgxzBvIiIiIgraU14ZWbJy4RnpUEp/yMs4i1MJhPB/r4e+TKZTE57HSEhIQW+f+yxx/jmm2944YUX+OWXX1i/fj2tW7fGYrEUOY6fn995vz5FBcyFXV/cte6uMmrUKHbt2sXtt9/Oxo0b6dixI1OnTgWgX79+7N27l0ceeYRDhw5x5ZVX8thjj3l0viIiIlI5KAivzOxrwm1WsJzy7FxExCVWrFjBiBEjGDx4MK1bt6ZmzZrs2bPHrXOIiIggOjqa1atXO87l5uaybt26Uo/ZokULcnJy+OOPPxznjh8/ztatW4mLi3Oci4mJ4Z577mHOnDk8+uijvP/++46fVa9eneHDh/Ppp58yZcoU3nvvvVLPR0RERKS4VI5emWXlC7zPpEKga/f8FRH3a9KkCXPmzGHgwIGYTCaefvrpUpeAl8UDDzzA5MmTady4Mc2bN2fq1KmcPHmyWFUAGzduJCwszPG9yWSibdu2XHvttdx11128++67hIWF8eSTT1KnTh2uvfZaAB5++GH69etH06ZNOXnyJMuWLaNFixYAjB8/ng4dOtCyZUuysrL4/vvvHT8TERERcSUF4ZWZvTEbaF24iJd69dVXueOOO+jWrRvVqlVjzJgxpKWluX0eY8aMISkpiWHDhuHj48Pdd99Nnz598PG5+Hr4Hj16FPjex8eHnJwcZsyYwUMPPcTVV1+NxWKhR48ezJ8/31Ean5uby/3338+BAwcIDw+nb9++vPbaa4Cx1/nYsWPZs2cPQUFBdO/enS+++ML5L1xERETkHCabpxftlUNpaWlERESQmppKeHi4p6fjOq+1htS85kzDv4cG3T07HxE3OnPmDLt376ZBgwYEBgZ6ejqVjtVqpUWLFtx0000899xznp6OSxT1Hqs0/864mH4dRUTE1Vzxb40y4ZWZ5ZxydBERF9m7dy+LFi2iZ8+eZGVl8eabb7J7925uvfVWT09NRERExK3UmK2ystnOXxMuIuIiZrOZmTNn0qlTJy699FI2btzIkiVLtA5bREREKh1lwiurnCyw5pz9/kyKx6YiIt4vJiaGFStWeHoaIiIiIh6nTHhllXXOlmTKhIs3O7gO/vnG07MQEREREVEmvNLKOqc7soJw8WZf3wkndkGteIhq4OnZiIiIiEglpkx4ZWVJL/h9ZopHpiHiFqeSjMf0ZM/OQ0REREQqPQXhlZXK0aWysOZC9mnj+Nz3vYiIiIiImykIr6yyzsmEKwgXb5U/8FYQLiIiIiIepiC8srIHI6a8t4C6o4u3yr/0QkG4iIiIiHiYgvDKypIXjITVNh6VCRdvlb/q49xeCJVUr169ePjhhx3fx8bGMmXKlCKfYzKZmDt3bpnv7axxRERERCoqBeGVlT0jGFHXeFQQLt6qQCa8YgfhAwcOpG/fvoX+7JdffsFkMrFhw4YSj7t69Wruvvvusk6vgGeeeYb4+Pjzzh8+fJh+/fo59V7nmjlzJpGRkS69h4iIiEhpKQivrM4Nwi3pkJvtufmIuEr+7fjO3ZqvgrnzzjtZvHgxBw4cOO9nM2bMoGPHjrRp06bE41avXp3g4GBnTPGiatasSUBAgFvuJSIiIlIeKQivrOwZwfDaZ8+dqdgBikihiluObrOBJcMzXzZbsV7K1VdfTfXq1Zk5c2aB8+np6Xz55ZfceeedHD9+nFtuuYU6deoQHBxM69at+fzzz4sc99xy9O3bt9OjRw8CAwOJi4tj8eLF5z1nzJgxNG3alODgYBo2bMjTTz9NdrbxQd7MmTN59tln+euvvzCZTJhMJseczy1H37hxI1dccQVBQUFUrVqVu+++m/T0s79PI0aMYNCgQbz88svUqlWLqlWrcv/99zvuVRr79u3j2muvJTQ0lPDwcG666SaSk89uX/fXX39x+eWXExYWRnh4OB06dGDNmjUA7N27l4EDB1KlShVCQkJo2bIl8+fPL/VcREREpPLx9fQExEPsmfCgSPAPM9aIn0mBkKqenJWI8xW3MVv2aXih9oV/7kpPHQL/kIte5uvry7Bhw5g5cybjxo3DZDIB8OWXX5Kbm8stt9xCeno6HTp0YMyYMYSHh/PDDz9w++2306hRIzp37nzRe1itVq677jqio6P5448/SE1NLbB+3C4sLIyZM2dSu3ZtNm7cyF133UVYWBhPPPEEQ4YM4e+//2bBggUsWbIEgIiIiPPGyMjIoE+fPnTt2pXVq1dz5MgRRo0axejRowt80LBs2TJq1arFsmXL2LFjB0OGDCE+Pp677rrroq+nsNdnD8B/+ukncnJyuP/++xkyZAjLly8HYOjQobRr14533nkHHx8f1q9fj5+fHwD3338/FouFn3/+mZCQEDZt2kRoaGiJ5yEiIiKVl4LwysremC0gHAIjzgbhIt4my3vWhAPccccdvPTSS/z000/06tULMErRr7/+eiIiIoiIiOCxxx5zXP/AAw+wcOFC/vvf/xYrCF+yZAlbtmxh4cKF1K5tfCjxwgsvnLeO+1//+pfjODY2lscee4wvvviCJ554gqCgIEJDQ/H19aVmzZoXvNesWbM4c+YMH3/8MSEhxocQb775JgMHDuQ///kP0dHRAFSpUoU333wTHx8fmjdvzoABA1i6dGmpgvClS5eyceNGdu/eTUxMDAAff/wxLVu2ZPXq1XTq1Il9+/bx+OOP07x5cwCaNGnieP6+ffu4/vrrad26NQANGzYs8RxERESkclMQXlnZM4L+oUY2PO2AmrOJdyqwJryITLhfsJGR9gS/4q/Hbt68Od26dWP69On06tWLHTt28MsvvzBx4kQAcnNzeeGFF/jvf//LwYMHsVgsZGVlFXvN9+bNm4mJiXEE4ABdu3Y977rZs2fzxhtvsHPnTtLT08nJySE8PLzYr8N+r7Zt2zoCcIBLL70Uq9XK1q1bHUF4y5Yt8fHxcVxTq1YtNm7cWKJ75b9nTEyMIwAHiIuLIzIyks2bN9OpUycSExMZNWoUn3zyCQkJCdx44400atQIgAcffJB7772XRYsWkZCQwPXXX1+qdfgiIiJSeWlNeGVlzwgGhBmZcFAQLt4pfzm6pYgg3GQySsI98ZVXVl5cd955J19//TWnTp1ixowZNGrUiJ49ewLw0ksv8frrrzNmzBiWLVvG+vXr6dOnDxaLpTS/eoVauXIlQ4cOpX///nz//ff8+eefjBs3zqn3yM9eCm5nMpmwWq0uuRcYnd3/+ecfBgwYwP/+9z/i4uL45ptvABg1ahS7du3i9ttvZ+PGjXTs2JGpU6e6bC4iIiLifRSEV1b2jGD+IDwzxWPTEXEZLytHB7jpppswm83MmjWLjz/+mDvuuMOxPnzFihVce+213HbbbbRt25aGDRuybdu2Yo/dokUL9u/fz+HDhx3nfv/99wLX/Pbbb9SvX59x48bRsWNHmjRpwt69ewtc4+/vT25u7kXv9ddff5GRkeE4t2LFCsxmM82aNSv2nEvC/vr279/vOLdp0yZSUlKIi4tznGvatCmPPPIIixYt4rrrrmPGjBmOn8XExHDPPfcwZ84cHn30Ud5//32XzFVERES8k8eD8LfeeovY2FgCAwPp0qULq1atuuC1c+bMoWPHjkRGRhISEkJ8fDyffPJJgWuSk5MZMWIEtWvXJjg4mL59+7J9+3ZXv4yKxxGEh0JgpHGsTLh4o+I2ZqtAQkNDGTJkCGPHjuXw4cOMGDHC8bMmTZqwePFifvvtNzZv3sz//d//Fej8fTEJCQk0bdqU4cOH89dff/HLL78wbty4Atc0adKEffv28cUXX7Bz507eeOMNR6bYLjY2lt27d7N+/XqOHTtGVlbWefcaOnQogYGBDB8+nL///ptly5bxwAMPcPvttztK0UsrNzeX9evXF/javHkzCQkJtG7dmqFDh7Ju3TpWrVrFsGHD6NmzJx07diQzM5PRo0ezfPly9u7dy4oVK1i9ejUtWrQA4OGHH2bhwoXs3r2bdevWsWzZMsfPRERERIrDo0H47NmzSUxMZMKECaxbt462bdvSp08fjhw5Uuj1UVFRjBs3jpUrV7JhwwZGjhzJyJEjWbhwIQA2m41Bgwaxa9cuvv32W/7880/q169PQkJCgUyLcH5jNlBjNvFO+QPvorYoq2DuvPNOTp48SZ8+fQqs3/7Xv/5F+/bt6dOnD7169aJmzZoMGjSo2OOazWa++eYbMjMz6dy5M6NGjeL5558vcM0111zDI488wujRo4mPj+e3337j6aefLnDN9ddfT9++fbn88supXr16odukBQcHs3DhQk6cOEGnTp244YYbuPLKK3nzzTdL9otRiPT0dNq1a1fga+DAgZhMJr799luqVKlCjx49SEhIoGHDhsyePRsAHx8fjh8/zrBhw2jatCk33XQT/fr149lnnwWM4P7++++nRYsW9O3bl6ZNm/L222+Xeb4iIiJSeZhstmJuUOsCXbp0oVOnTo7/cFmtVmJiYnjggQd48sknizVG+/btGTBgAM899xzbtm2jWbNm/P3337Rs2dIxZs2aNXnhhRcYNWpUscZMS0sjIiKC1NTUEjcaqhBsNpgYBTYrJG6BdR/B8snQ8Q64+jVPz07EuT66Bnb/dPb7p4+Bjx9nzpxh9+7dNGjQgMDAQM/NT7xWUe8xr/93xk306ygiIq7min9rPJYJt1gsrF27loSEhLOTMZtJSEhg5cqVF32+zWZj6dKlbN26lR49egA4yh3z/2fHbDYTEBDAr7/+esGxsrKySEtLK/Dl1bIzjQAc1JhNvN+52W8vKUkXERERkYrJY0H4sWPHyM3NPW/dX3R0NElJSRd8XmpqKqGhofj7+zNgwACmTp1K7969AWPrnnr16jF27FhOnjyJxWLhP//5DwcOHCjQZOhckydPduyvGxERUWDrGq/kCELyukGrMZt4s3ObsXlRSbqIiIiIVDweb8xWUmFhYaxfv57Vq1fz/PPPk5iYyPLlywFjG5s5c+awbds2oqKiCA4OZtmyZfTr1w+z+cIvdezYsaSmpjq+8nfN9UqWfNuTmUxqzCbe7dzMtzLhIiIiIuJBvp66cbVq1fDx8Tmva29ycjI1a9a84PPMZjONGzcGID4+ns2bNzN58mR69eoFQIcOHVi/fj2pqalYLBaqV69Oly5d6Nix4wXHDAgIICAgoOwvqqLIyiu3DwgzHlWOLt7Mkfk2ATav2aZMRERERComj2XC/f396dChA0uXLnWcs1qtLF26lK5duxZ7HKvVWujWNxEREVSvXp3t27ezZs0arr32WqfM2yvYM4H+ocajuqOLt7LZzgbhIdWNx3My4R7sTSleTu8tERERKYzHMuEAiYmJDB8+nI4dO9K5c2emTJlCRkYGI0eOBGDYsGHUqVOHyZMnA8ba7Y4dO9KoUSOysrKYP38+n3zyCe+8845jzC+//JLq1atTr149Nm7cyEMPPcSgQYO46qqrPPIay6WsfOXoAEGRxuOZVCNoMZk8Mi0Rp8s+fbYJYXgtyDji2J7Pz88PgNOnTxMUFOSpGYoXs1gsgLHtmYiIiIidR4PwIUOGcPToUcaPH09SUhLx8fEsWLDA0axt3759BdZyZ2RkcN9993HgwAGCgoJo3rw5n376KUOGDHFcc/jwYRITE0lOTqZWrVoMGzbsvP1rKz17JjDgnEx4rgVyzoCfAhLxEvb3uskMITUKnPPx8SEyMpIjR44Axp7VJn0AJU5itVo5evQowcHB+Pp69J9aERERKWc8/j+D0aNHM3r06EJ/Zm+4Zjdp0iQmTZpU5HgPPvggDz74oLOm550s9iA8LxPuHwomH7DlGh3SFYSLt7BXffiHQmB4wXPg6D9hD8RFnMlsNlOvXj19uCMiIiIFeDwIFw9wrAnPC8JNJiMbnnnCKEkPr+W5uYk4kyVf/wN7D4R8W5SZTCZq1apFjRo1yM7O9sAExZv5+/sXuTOHiIiIVE4Kwiujc9eEQ8EgXMRb5H+v29/v9t0B8vHx8dG6XRERERFxC31EXxllnVOODuqQLt4pf/8DRxCuLcpERERExHMUhFdG5zZmg4Id0kW8hSXfmnBHEH7qwteLiIiIiLiYgvDK6NzGbJAvE64gXLxI/qqPQtaEi4iIiIi4m4LwyujcxmxwNgjPTHH7dERcxpJ/TXheEK5ydBERERHxIAXhlVGhjdkijUetCRdvkpWvO3qAfYuy8xuziYiIiIi4i4LwyqiwNeEqRxdv5PjAqfAtykRERERE3E1BeGVkucAWZaBMuHiX/PuEqzGbiIiIiJQDCsIrI0cmPPzsuaAqxqMy4eJNHJnwcK0JFxEREZFyQUF4ZWOzFVwna6dydPFGBfYJz/vQKScTcnM8NycRERERqdQUhFc2lgzAZhwXVo6u7ujiTfLvE57/QyeLStJFRERExDMUhFc29sygyQx+QWfPO7qjKxMuXiR/YzZff/DxL3heRJzurbfeIjY2lsDAQLp06cKqVauKvH7KlCk0a9aMoKAgYmJieOSRRzhz5oybZisiIuJ+CsIrm/xN2Uyms+ftmfCsNLBa3T8vEVdwNGbLq/pQczYRl5o9ezaJiYlMmDCBdevW0bZtW/r06cORI0cKvX7WrFk8+eSTTJgwgc2bN/Phhx8ye/ZsnnrqKTfPXERExH0UhFc29j2S/cMKnrcH4TarSnXFezjWhOe937VNmYhLvfrqq9x1112MHDmSuLg4pk2bRnBwMNOnTy/0+t9++41LL72UW2+9ldjYWK666ipuueWWi2bPRUREKjIF4ZVNViHbkwH4BYJvoHGsknTxFvnL0eFsczb7h1Ei4jQWi4W1a9eSkJDgOGc2m0lISGDlypWFPqdbt26sXbvWEXTv2rWL+fPn079//0Kvz8rKIi0trcCXiIhIRePr6QmIm52bGcwvMALSzygIF++QkwXWbOPYngHXNmUiLnPs2DFyc3OJjo4ucD46OpotW7YU+pxbb72VY8eOcdlll2Gz2cjJyeGee+65YDn65MmTefbZZ50+dxEREXdSJtyFbDYbaWeyPT2NgiznZAbzU4d08Sb5A217EK5ydJFyZfny5bzwwgu8/fbbrFu3jjlz5vDDDz/w3HPPFXr92LFjSU1NdXzt37/fzTMWEREpO2XCXejvg2lcP+03ElrUYFB8HXo1q4G/r4c/9ygyEx5pPCoTLt7AXnLuFww+eX/VqTGbiMtUq1YNHx8fkpOTC5xPTk6mZs2ahT7n6aef5vbbb2fUqFEAtG7dmoyMDO6++27GjRuH2Vzw38yAgAACAgJc8wJERETcRJlwF/p5+1EsOVbmb0zi7k/W0uWFJTw992/W7TuJzWbzzKQu1JgNzmbCFYSLN8i/R7idytFFXMbf358OHTqwdOlSxzmr1crSpUvp2rVroc85ffr0eYG2j48PgOf+nRQREXExZcJd6L5ejejVrDrfrDvIt38d4uipLD75fS+f/L6XBtVCGBRfh8Ht6lCvarD7JnWhxmyQLwhPcdt0RFzm3KZsoMZsIi6WmJjI8OHD6dixI507d2bKlClkZGQwcuRIAIYNG0adOnWYPHkyAAMHDuTVV1+lXbt2dOnShR07dvD0008zcOBARzAuIiLibRSEu5DJZKJl7Qha1o5gbP8WrNhxjG/+PMiCv5PYfSyD15Zs47Ul2+hYvwqD29fh6ta1iQj2c+2kHOXohawJD4o0HpUJF29QWCZca8JFXGrIkCEcPXqU8ePHk5SURHx8PAsWLHA0a9u3b1+BzPe//vUvTCYT//rXvzh48CDVq1dn4MCBPP/88556CSIiIi6nINxNfMwmejStTo+m1Zk0KIeF/yTxzZ8HWbHjGGv2nmTN3pM8O28TVzSvweD2dbjcVevHLcXJhCsIFy9gz3bbs9+gNeEibjB69GhGjx5d6M+WL19e4HtfX18mTJjAhAkT3DAzERGR8kFBuAeEBPhyXfu6XNe+LslpZ/h2/UHmrDvIlqRTLPgniQX/JNGweghf/l9XqoY6uQHNxbYoA3VHF+9QaDm61oSLiIiIiGepMZuHRYcHcnePRix4uAc/PtSdu3s0pGqIP7uOZnDfZ+vIzrU694b2ILzQxmyRxqMy4eINVI4uIiIiIuWQgvBypEWtcJ7q34LZ/3cJoQG+/LH7BM9+949zb1KcTLgas4k3UGM2ERERESmHFISXQ41rhPH6zfGYTPDp7/v47I+9zhu8qMZsWhMu3sSxJjzfB04qRxcRERERD1MQXk5d2SKax65qBsCEb//hj13HnTNwUY3Z1B1dvImjHD1/EK7GbCIiIiLiWQrCy7H7ejViYNva5Fht3PvZOg6cPF32QR1rwovIhKsxm3iDwsrRtSZcRERERDxMQXg5ZjKZePH6NrSqE86JDAujPlrDaUtO6Qe0WvNlwsPP/7m9MVt2BuRml/4+IuVBYY3Z7Jnw7NOQW4Y/SyIiIiIipaQgvJwL8vfhvds7Ui3Uny1Jp3jsy7+w2WylGyx/9q+wcvT8gfkZNa6SCi6rkKUX+Y+VDRcRERERD1AQXgHUjgxi2m0d8PMxMX9jElP/t6N0A9mDDrMv+Bay/7iP79n1s+qQLhVdYY3ZfAPA7GccKwgXEREREQ9QEF5BdIyNYtKgVgC8ungbC/9JKvkg+bcnM5kKv0bblIm3KKwcHdScTUREREQ8SkF4BTKkUz1GdIsFIHH2erYmlTCIcDRlK6QU3U4d0sVbFNaYLf/32qZMRERERDxAQXgFM25AC7o1qkqGJZdRH6/mZIal+E/Onwm/EHVIF29xoe347L0PstT3QERERETcT0F4BePnY+atW9tTLyqY/Scyue+zdWTnWov3ZEcQXsj2ZHaOcnRlwqUCy80xOqDD+ZUf2qZMRERERDxIQXgFVCXEn/eHdSTE34eVu44z6ftNxXvihTKD+dm3KVMQLhVZgZ0AVI4uIiIiIuWHgvAKqlnNMF4bEg/ARyv38sWqfRd/UknK0dWYTSoyx04AfufvBKDGbCIiIiLiQQrCK7CrWtbk0d5NAXj6279ZvedE0U9wNGZTObp4ucL2CLdzlKMrCBcRERER91MQXsGNvqIxA1rXIjvXxr2frmXxpmRsNlvhFzsy4eEXHlDd0cUbFNX/wNGYTUG4iIiIiLifgvAKzmQy8dKNbYirFc6xdAt3fbyG/m/8yvyNh7FazwnGS9KYTd3RpSKzFLEdn9aEi4iIiIgHKQj3AsH+vnx+1yXc26sRIf4+bD6cxn2freOqKT8z98+D5Ni7pxerMZvK0cULXGiPcNCacBERERHxKAXhXiIi2I8xfZuz4skrePDKJoQF+rLjSDoPz15Pwqs/8d81+7GeydsXucg14ZHGo4JwqcjsHzgV9l7XFmUiIiIi4kEKwr1MZLA/ib2bsuLJK3i8TzOqBPux5/hpnvhqA3/u2A9Atl/IhQdQd3TxBkXtBKBMuIiIiIh4kIJwLxUe6Mf9lzfm1zFX8FT/5lQLDcAvJwOAJ77bzfRfd5NpyT3/ifnL0S/U4E2kvCuyMZuCcBERERHxHAXhXi4kwJe7ezTi1zGXUz/UWBt+IMOXid9vovuL/+Pdn3Zy2pJz9gn27ui5Fsg54/4JiziDoxy9qC3KVI4uIiIiIu6nILySCPTzIcJsBNUjrmhN3SpBHEu3MPnHLfR+9WeWbz1iXOgfCqa8t4U6pEtFpcZsIiIiIlJOKQivTPKCjgEdmrDssV68dEMb6kQGcTAlkxEzVvPQF39yPMOiDulS8RW5JlxblImIiIiI5ygIryysuZB92jgOCMfPx8yNHWNY9EgP7ri0AWYTfLv+EAmv/kS6KS9IURAuFVWR3dHzAvPsDOPPhYiIiIiIGykIryzyl97mK9ENCfBl/MA4vrnvUprXDOPk6Wx2pfsCcORIsrtnKeIcxemODuVrXbgaIYqIiIhUCgrCKwt7sOHjD74B5/24bUwk3z1wGU/0bUY6xhZmL877g/d+3klOrtWdMxUpu6Iy4b4BYDY+aCo3JelfjoC3usDpE56eiYiIiIi4mILwyqKozGAePx8z9/VqTNsmsQAE5abzwvwtDHp7BX8fVGm6VCBFvd9NpvLVnM2aC5u+hWNbYfUHnp6NiIiIiLiYgvDKIquIzOA5QiKiALipZRjhgb78fTCNa99aweT5mwvfW1ykvCmqOzqcXRdeHsrRM46BLa/a5I9pYDnt2fmIiIiIiEspCK8sstKMx4Dwi1+b1x29dVUbSx7tyYA2tci12nj35130mfIzv24/5sKJijhBUfuEQ75MeJp75lOU9KSzx6ePw/rPPDcXEREREXE5BeGVhaM89+KZcAIjjcczqdQIC+StW9vzwbCO1IoIZN+J09z24R889uVfpGZmu2y6IqVms138/V6etik7lVTw+9/egNwcz8xFRERERFxOQXhlYc8MFrEm3MGxT3iK41RCXDSLE3syvGt9TCb4au0B+rz2M8u2HnH+XEXKwpIB5HUav9D73b4sozyUo9uD8NjuEFwVUvbBprkenZKIiIiIuI6C8MrCnhksxprw/Jnw/EIDfHn22lZ8dU9XGlQLISntDCNnrGbMVxtIO6OsuJQT9sDaZAa/4MKvKU+N2dLztgKsEgtd7jGOf52iLctEREREvJTHg/C33nqL2NhYAgMD6dKlC6tWrbrgtXPmzKFjx45ERkYSEhJCfHw8n3zySYFr0tPTGT16NHXr1iUoKIi4uDimTZvm6pdR/mWVIBMeFGk8nim8I3qH+lHMf7A7d1zaAJMJZq/ZT9/XtFZcyon8TQhNpsKvcZSjl4Mg3J4JD6sFnUaBXwgkb4QdSz07LxERERFxCY8G4bNnzyYxMZEJEyawbt062rZtS58+fThypPAS56ioKMaNG8fKlSvZsGEDI0eOZOTIkSxcuNBxTWJiIgsWLODTTz9l8+bNPPzww4wePZp58+a562WVT47GbCUoR89MueAlQf4+jB8Yxxd3XUK9qGAOpZ7htg//YNw3G0nP0npW8SBLMao+7A0Ky0MQbs+Eh0VDcBR0GG58v2KKx6YkIiIiIq7j0SD81Vdf5a677mLkyJGOjHVwcDDTp08v9PpevXoxePBgWrRoQaNGjXjooYdo06YNv/76q+Oa3377jeHDh9OrVy9iY2O5++67adu2bZEZ9kqhVGvCL743eJeGVVnwcHeGda0PwGd/7KPvlJ/5baey4uIhRe0Rblce14SH1jQeu94PZl/Y8wscWOu5eYmIiIiIS3gsCLdYLKxdu5aEhISzkzGbSUhIYOXKlRd9vs1mY+nSpWzdupUePXo4znfr1o158+Zx8OBBbDYby5YtY9u2bVx11VUXHCsrK4u0tLQCX16nOIGJXf414VbrRS8P9vdl4rWtmDWqC3UigzhwMpNb3/+DZ+b9w2mLsuLiZhfbIzz/z8pVJjwvCI+oC61vNI5XvOaZOYmIiIiIy3gsCD927Bi5ublER0cXOB8dHU1SUtIFngWpqamEhobi7+/PgAEDmDp1Kr1793b8fOrUqcTFxVG3bl38/f3p27cvb731VoFA/VyTJ08mIiLC8RUTE1P2F1jelKgxW14mHNvZ0t5i6Na4Ggsf6cGtXeoBMPO3PfR7/RdW7T5RwsmKlIEl35rwC3E0ZvNwJtxmOxuEh+b7u/DSh4zHzd/Dse3un5eIiIiIuIzHG7OVVFhYGOvXr2f16tU8//zzJCYmsnz5csfPp06dyu+//868efNYu3Ytr7zyCvfffz9Lliy54Jhjx44lNTXV8bV//343vBI3K0ljNr9A8AkwjotRkp5faIAvLwxuzcd3dKZWRCB7j59myHsree77TZzJzi3hpEVKoVjl6Hk/K8GHTC6ReRJyLcZx/iC8Rgto2g+wGfuGi4iIiIjX8PXUjatVq4aPjw/JyckFzicnJ1OzZs0LPs9sNtO4cWMA4uPj2bx5M5MnT6ZXr15kZmby1FNP8c033zBgwAAA2rRpw/r163n55ZcLlL7nFxAQQEBAgJNeWTlVksZsYHRIT082mrNF1ivx7Xo0rc7CR3ow6ftN/HfNAT78dTfLthxh4rWtuKxJtRKPJ1JsxQnCy8sWZfb14EFR4Otf8GeXPQzbfoS/voBeT0F4LbdPT0REREScz2OZcH9/fzp06MDSpWe34bFarSxdupSuXbsWexyr1UpWVhYA2dnZZGdnYzYXfFk+Pj5Yi7G22auVpDEblKg524WEB/rx4g1tmTGiE9HhAew6lsFtH/7B/32yhv0nTpd6XJEiFasc3b4m3MPl6On27ckK+eCx3iUQc4mRKf/9bffOS0RERERcxqPl6ImJibz//vt89NFHbN68mXvvvZeMjAxGjhwJwLBhwxg7dqzj+smTJ7N48WJ27drF5s2beeWVV/jkk0+47bbbAAgPD6dnz548/vjjLF++nN27dzNz5kw+/vhjBg8e7JHXWG6UpDEbOCUIt7u8eQ0WPdKTEd1i8TGbWPhPMgmv/sSri7eRaVGJujhZsRqzlbNMeGh04T+/7GHjcc2MIrcMFBEREZGKw2Pl6ABDhgzh6NGjjB8/nqSkJOLj41mwYIGjWdu+ffsKZLUzMjK47777OHDgAEFBQTRv3pxPP/2UIUOGOK754osvGDt2LEOHDuXEiRPUr1+f559/nnvuucftr69cySpGdjA/R4f0FKfcPiLIj2euacktnevxzLx/WLnrOG8s3c5Xa/YzbkAc/VvXxGQyOeVeUskVZ5/w8rJF2akiMuEATfpA9eZwdAusmQ7dE903NxERERFxCY8G4QCjR49m9OjRhf4sf8M1gEmTJjFp0qQix6tZsyYzZsxw1vS8Q24O5GQaxx7IhOfXrGYYs+7qwo9/J/H8D5s5mJLJ/bPW0bVhVSZcE0fzmuFOvZ9UQo6qjyLeS/Y/B5Z0Yxs+s4eKggrrjJ6f2Wx0Sp97L/z+Dlxyn9E4UUREREQqrArXHV1KIX8HaA8H4QAmk4n+rWuxJLEnD13ZhABfMyt3HWfAG7/yzLx/SD2d7fR7SiVSknJ08Gw23JEJL6LpWqsbILwuZByBvz53z7xERERExGUUhFcG9sygbyD4+BXvOUGRxqML16EG+fvwSO+mLEnsSd+WNcm12pj52x56vbyMWX/sI9dqc9m9xYsVpzGbbyCYfApe7wn2THjYBTLhYHRN73q/cfzbG2BVHwURERGRikxBeGWQVYw1sudyYSb8XDFRwUy7vQOf3tmFJjVCOXk6m6e+2ci1b/3K2r0nXH5/8TLFyYSbTOWjOZujMduFt2UEoP0wo0/DiV2weZ7LpyUiIiIirqMgvDLIKuH2ZJCvMZvrg3C7y5pUY/5D3Rl/dRxhgb78fTCN699ZyV0fr2Ht3pNum4dUcI4PnS7yfncE4R7KhNtsxcuEg/GBQue7jeNfpxjPFREREZEKSUF4ZVDS7ckgXyY8xenTKYqfj5k7LmvAssd6MaRjDCYTLN6UzPXv/MZN01aydHMyVpWpS1EsxXy/2ytDstJcO58LyToF2aeN44tlwgG6/B/4BsHh9bD7J5dOTURERERcR0F4ZVDcoCQ/N5ajF6ZaaAD/uaENix/pwU0d6+LnY2LVnhPc+dEa+r7+M1+vPUB2rtUjc5Nyrjjl6FCwQ7on2LPgAeHgH3zx60OqQbvbjONfp7hsWiIiIiLiWgrCK4PSZMLtjdk8FITbNa4Rxos3tOWXJ67g7h4NCQ3wZVtyOo9++Rc9X1zGh7/uJiMrx6NzlHIkJwused31L9YDwR6ke6oc3bEe/CKl6Pl1G200lNu1DA6td8m0RERERMS1FIRXBlnF6BZ9Lnsm3IXd0UuiZkQgT/VvwYonr+CJvs2oFhrAodQzPPf9Jrr9+3+8smgrx9OzPD1N8bT8TdYuGoR7uDGbYz14MUrR7arEQqvrjOMVU5w9IxERERFxAwXhlUGp1oRHGo/ZGZBbfvbtjgjy475ejfl1zOW8MLg1sVWDSc3MZur/dtDt3//j6bl/s+/4aU9PUzzF/l73CwYf36KvtTdus3goCD912HgsSSYc4NKHjMdN3xrd0kVERESkQlEQXhnYG09dbI1sfgHhZ4/PeKhxVREC/Xy4tUs9lj7ai7eHtqdN3Qiycqx88vteer28jIe++JPdxzI8PU1xt+LsEW7n6Uy4vRy9JJlwgJqtoXEC2Kzw21Tnz0tEREREXEpBeGVgD0zyB9YX4+N7NlPo5g7pJeFjNtG/dS2+vf9SZt3VhR5Nq2O1wbfrD5Hw6k+M+WoDB04qM15pFLcpW/5rPLUm3F6OXtJMOMClDxuPf34G6UecNiURERERcT0F4ZVBacrRwWPblJWGyWSiW6NqfHxHZ75/4DKuaF6DXKuN2Wv2c8XLPzHh2785knbG09MUV3PsEV6MINx+jae6ozsy4bVK/tzYy6BOB8jNgjXTnTsvEREREXEpBeGVQWkas0G56ZBeUq3qRDB9RCe+vrcb3RpVxZJr5aOVe+nx0jImz9/MyQyLp6coruLYjq8YVR+eLkd3NGYrRSbcZIIu9xrH6z4Ba67z5iUiIiIiLqUgvDIoaya8nHRIL6kO9asw665LmDWqC+3qRXIm28q7P++i+4vLeHXxNtLOlJ+Gc+IkJSpH9/SacHs5egnXhNu1GGg0UEw7ADuXOW1aIiIiIuJaCsIrA0d2sISZcEc5esXKhJ+rW+NqzLm3G9NHdCSuVjjpWTm8sXQ73f+zjLeX7+C0RfuMe42K0pgtOxOy8v5clSYTDuAXCG1vNo7XzXTKtESc4a233iI2NpbAwEC6dOnCqlWrirw+JSWF+++/n1q1ahEQEEDTpk2ZP3++m2YrIiLifgrCK4OsEpTo5mffpqyCB+FgrBm/onk03z9wGW8PbU/jGqGkZmbz4oKt9HhxOTNW7OZMtkp6K7ysEnzg5Mk14fb14L5BJf9zmV+7243HrT+qQZuUC7NnzyYxMZEJEyawbt062rZtS58+fThypPD3p8VioXfv3uzZs4evvvqKrVu38v7771OnTh03z1xERMR9FIRXBiVpVpVfBWrMVlzmvG7qCx/uwas3taVeVDDH0rN49rtNXPnKT6zec8LTU5SyKMnSC09mwvOvBzeZSj9OzVZGgzZrDvz1uXPmJlIGr776KnfddRcjR44kLi6OadOmERwczPTphTcQnD59OidOnGDu3LlceumlxMbG0rNnT9q2bevmmYuIiLiPgvDKwLFOtrTd0St+JvxcPmYT17Wvy9JHe/LC4NbUigjkYEomt7z3O9N/3Y3NZvP0FKU0HOXoJQnCPZgJL+168PzaDzce130Met+KB1ksFtauXUtCQoLjnNlsJiEhgZUrVxb6nHnz5tG1a1fuv/9+oqOjadWqFS+88AK5uYVXJmVlZZGWllbgS0REpKJREO7tcizGNkZQ8iC8gnZHLwk/HzO3dqnH0kd7ck3b2uRYbUz8fhMPfP4nGVlaK17hlKQxW/5ydKvVdXMqjGN7slKuB8+v1XXgFwLHd8De38o+nkgpHTt2jNzcXKKjC76vo6OjSUpKKvQ5u3bt4quvviI3N5f58+fz9NNP88orrzBp0qRCr588eTIRERGOr5iYGKe/DhEREVdTEO7t8q93LW05egXtjl4Swf6+vH5zPBMGxuFrNvH9hsMMemsFO486N0tqybHy7fqDrNt30qnjSp7SNGbDBtkZLptSodKdmAkPCDMCcTCy4SIViNVqpUaNGrz33nt06NCBIUOGMG7cOKZNm1bo9WPHjiU1NdXxtX//fjfPWEREpOwUhHu7rLxSPb9g8PEt2XO9uBy9MCaTiZGXNuCLuy8hOjyA7UfSufbNFfy48XCZx87JtfLlmv1c/vJyHvpiPTe/9zubDqmM0ulKsibcLwhMeX8Fursk/VQZ9ggvTIcRxuOmuZCpD3jEM6pVq4aPjw/JyckFzicnJ1OzZuEfONWqVYumTZvi4+PjONeiRQuSkpKwWCznXR8QEEB4eHiBLxERkYpGQbi3yypBZvBcXtQdvSQ6xkbx/QPd6dIgivSsHO79bB0vzN9MTm7JS5atVhs/bDjMVVN+5vGvNnAwJRMfswlLjpX7Z60jXSXvzlWSINxk8lxzNmdmwsFozlYjDnLOwMavnDOmSAn5+/vToUMHli5d6jhntVpZunQpXbt2LfQ5l156KTt27MCab0nItm3bqFWrFv7+/i6fs4iIiCcoCPd2JQlKzuWF3dGLq3pYAJ+N6sL/9WgIwHs/7+K2D//g6KmsYj3fZrOxbMsRrp76K/fPWseuoxlEBvsxtl9zfnnicmpFBLL7WAZPzdmoJnDOVJJydDjbwM3i5iDckQl3UhBuMp1t0Lb2IzVoE49JTEzk/fff56OPPmLz5s3ce++9ZGRkMHLkSACGDRvG2LFjHdffe++9nDhxgoceeoht27bxww8/8MILL3D//fd76iWIiIi4XAnrk6XCKcm+yefKX45us5VtK6UKyNfHzNj+LYiPieTxrzbw+64TXD31F94e2p4O9aMu+Lzfdx3npYVbWbvXKAsODfDlzssaMKp7A8IC/QB489Z23PTu78z76xCXNKzKrV3queU1eb2SNGbLf527y9HtmXBnBeEAbW6CxeMheSMc+hPqtHfe2CLFNGTIEI4ePcr48eNJSkoiPj6eBQsWOJq17du3D7P57Of/MTExLFy4kEceeYQ2bdpQp04dHnroIcaMGeOplyAiIuJyCsK9nT3DF1CKdXP27ui5FqPM1S/IadOqSPq1rkXTmmHc88lath9JZ8i7vzNuQAtGdIvFlO+Dib/2p/Dyoq38sv0YAAG+ZkZ0i+X/ejYiKqRgWWWH+lE80acZk3/cwjPf/UN8TCRxtbW2scxKWvnhiXL0HAucPm4cO6scHSA4CloMhL+/Mhq0KQgXDxk9ejSjR48u9GfLly8/71zXrl35/fffXTwrERGR8kPl6N6uLOXo/qFnG1dVgg7pRWlUPZS591/K1W1qkWO18ex3m3joi/VkZOWwNekUd3+8hmvfWsEv24/hazZx+yX1+fmJyxnbv8V5AbjdXd0bckXzGlof7iy5OZCTaRwXZ59wKLhNmbtkHDEezX5G4OxMHfJK0jd+5Zn9z0VERETkohSEe7uyNGYzmSpdh/SihAT4MvWWdoy/2tjGbN5fh7jileX0ff1nFm1KxmyC69vXZdljvXhuUCuiwwOLHM9sNvHKjW21PtxZ8gfSxS5H90Am3L4ePDTa+Us86l8GVRoYFTCb5jp3bBERERFxCgXh3q4smXDI1yE9xRmzqfBMJhN3XNaAz+++hBphASSnZWGzQf/WNVn0SA9euaktMVHBxR6vSog/b97aDp+8oP7zVdrzttTsQbjZD3wDivccTwThjvXgTtqeLD+zGdoPM461Z7iIiIhIuaQg3NtZStio6lzKhBeqU2wU3z94GU/0bcZ3oy/j7aEdaFyjdB902NeHAzzz3T/aP7y0SvOBk0cy4U7enuxc8beCyQf2/wFHNrvmHiIiIiJSagrCvV1WXkBX6ky4gvALqREWyH29GtO6bkSZx9L6cCcoaWd08Mya8FMuzISD0XG9aV/jeN0nrrmHiIiIiJSagnBvZ8/wFbdR1bnsHdIreWM2V7OvD6+t9eGlZynFe90TW5SluzgTDmcbtP31OeQUb297EREREXEPBeHezpEdVCa8vKsS4s/UW9s7mr5pfXgJlSYT7ihHd+MSAHtjNldlwgEaXQlhtSHzBGz53nX3EREREZESUxDu7crcmM0ehKc4ZTpStA71q/BEX60PLxVH1UdJytHz/ly4sxzdHZlwH19od5txrAZtIiIiIuWKgnBvV+bGbJHGo4Jwtxl1WUOu1PrwkrOUourDk1uUhbkwCIe8INwEu5bDyT2uvZeIiIiIFJuCcG/naMwWXrrnqxzd7cxmEy9rfXjJOao+SlKO7uY14dZcyDhiHLs6CK9SHxr2Mo7VoE1ERESk3FAQ7u3swUVJSnTzc2TCFYS7k9aHl4I9E16Sxmz2PxfuyoRnHAObFUxmCKnu+vvZG7St/wxyVVEhIiIiUh74enoC4kI2W9nXhKs7usfY14e/MH8Lz3z3D/ExkcTVPlvRkJWTS2pmNmmZ2aScziY10/jKf5xjtXJd+7q0r1fFg6/ETUqVCc/79XTXmnD7evCQ6mD2cf39mvWH4Kpw6jDsWALN+rr+niIiIiJSJAXh3iwnC6zZxnGp14SrHN2TRl3WkD92nWDpliPc/uEfVAsNcATYmdm5xRrjsz/2MeyS+jzetzmhAV78R740OwEE5MuE22xgMjl/XvnZ14OHurAzen6+AdD2Flj5Jqz7SEG4iIiISDngxf8jlwLZvVKXoysI9yT7+vCrp/7KwZRMjmdYCvzcZILwQD8igvyIDDYew4P8iAwyjg+czGTeX4f4aOVeFm1K5rlrW5EQ56YA0N0spVh64QjYbWDJKP2HVcVlz4S7ej14fu2HGUH4toWQdhjCa7nv3iIiIiJyHgXh3szelM0/tPSlr/nXhFutYFYbAXerEuLP1/d2Y92+k4QF+hIZ5E9EXpAdFuiL2Vx09vamjjE89c1G9p04zaiP1zCgdS0mDIyjRnigm16Bm5Rm6YVfsLE+22Y1gnhXB+HuzoQDVG8GMZfA/t+NteE9HnPfvUVERETkPIqovFlZm7LB2Uw4NrC4cRsnKaBmRCD9W9eie5PqtK4bQb2qwUQE+100AAe4rEk1Fj7cg3t6NsLHbOKHjYe58tWf+HzVPqxWL+q6Xpp9wk2ms43c3NGc7dRh49GdmXA426Dtz0+MD9NERERExGNKFYTv37+fAwcOOL5ftWoVDz/8MO+9957TJiZOUNambAB+geATYByrJL3CCvL34cl+zZk3+lLa1I3g1Jkcxs7ZyM3v/87Oo2VrSnYiw8KCvw+zZFOyZ4P60uwTDgXXhbtaugcy4QBx1xpN6E7ugT2/uPfeIiIiIlJAqYLwW2+9lWXLlgGQlJRE7969WbVqFePGjWPixIlOnaCUgSMoKWOJrTqke42WtSOYc283/jWgBUF+PqzafYJ+r//C1KXbseQUL0N6LD2LHzYcZvy3f9PntZ9p/9xi7vl0HaM+XsOImas5np7l4ldxAVmlfL/bM+fu6JB+ygNrwgH8Q6D1Dcbxuo/ce2932Pw9/DXb07MQERERKZZSrQn/+++/6dy5MwD//e9/adWqFStWrGDRokXcc889jB8/3qmTlFJyRiYcjJL09GRlwr2Er4+ZUd0b0qdlTf41929+2naUVxZv47sNh5h8XRs61C+4ndmRtDP8vvsEf+w6zh+7T7DjyPnBapMaoew7cZqftx2l/xu/MPWW9nRuEOWul2QozT7hcPbPh1sz4W4OwgHaD4c102Hzd3D6BAS7+ffHVc6kwpfDwZoDIVWhcYKnZyQiIiJSpFIF4dnZ2QQEGCXKS5Ys4ZprrgGgefPmHD582Hmzk7JxNGZzQhAOCsK9TExUMDNHdmLeX4eY+N0mtiWnc8O037j9kvq0r1eFP3Yf549dJ9h1LOO85zavGcYlDatyScMoOsVGUTU0gC1Jadz/2Tp2Hs3g5vdW8uhVzbi3Z6NirVsvM5utdPuE578+y8WZcJvtbBDu7kw4QO14qNkGkjbAhtlwyb3un4MrHFxnBOAA8x+He1cay2hEREREyqlSBeEtW7Zk2rRpDBgwgMWLF/Pcc88BcOjQIapWrerUCUoZlGbf5MI4OqSnlG0cKXdMJhPXxtehR5PqPD9/M1+tPcDHK/fy8cq9+a6BuFrhdGlQlS4No+gcG0WVEP/zxmpeM5x5oy/jX3P/5ps/D/LSwq38vus4U4bEUzU0wLUvxJIB5K1HL/GacHsmPM2pUzpP5knIzdtizt1rwu3aD4P5j8HfX3tREL7m7PGJXbDideg1xnPzEREREbmIUgXh//nPfxg8eDAvvfQSw4cPp23btgDMmzfPUaYu5YAzy9FBmXAvViXEn5dvbMvgdnV4edFWcnJtXNIwii4NqtIpNoqIYL9ijRMS4MurN7Wla8OqjJ/3N79sP0b/N37hjZvb0aWhCz+gs5eim8zGtmMlYa8UcfWacPt68KAo8D3/Qwy3aNjLeEz+B6y5pd+6sDw5sNZ4rNcN9v0Gv7wCbW6EqIaenZeIiIjIBZQqCO/VqxfHjh0jLS2NKlXOrh+9++67CQ4u4X+AxXWc1ZhNQXilcWnjalzauFqZxjCZTNzUKYa2MZHc99ladh7N4Jb3fyexd1Pu69XYNeXp+bfjM5VwfHetCU/3UFO2/KIagm8QZJ+GE7uhWmPPzcUZbLazmfDez8L/JsHun+DHMXDrf0v+XhARERFxg1J1R8/MzCQrK8sRgO/du5cpU6awdetWatSo4dQJShnYy2vLmglXd3QphWY1w5g3+jKua18Hqw1eXrSN4TNWccwV3dMd/Q9K8YGTu9aEn/LQ9mT5mX2gRgvjOPlvz83DWVL2QsZRMPsZ690HvGIcb18EW37w9OxEREREClWqIPzaa6/l448/BiAlJYUuXbrwyiuvMGjQIN555x2nTlDKIKuU3aLPpUy4lJJRnh7PSze0IdDPbJSnv/4Lv+867twblXaPcHDfFmXlIRMOEN3SeEz+x7PzcIYDeVnwmq2NZmzVmsClDxrnfhyT1ytAREREpHwpVRC+bt06unfvDsBXX31FdHQ0e/fu5eOPP+aNN95w6gSlDLQmXMqJGzvGMG/0ZTSuEcqRU1nc+v7vvPm/7VitNufcoLR7hIP7GrPZ14R7MhMORsAK3pEJP5i3Hrxux7Pnuj8GEfUg7QD8/JJn5iUiIiJShFIF4adPnyYszPiP66JFi7juuuswm81ccskl7N279yLPFrdx2prwSONR3dGlDJpGhzFv9KVc375ugfL0ExmWsg9uybcmvKQcQbibGrOVm0y4FwTh9kx4nXxBuH8w9PuPcfzbVDi61f3zEhERESlCqYLwxo0bM3fuXPbv38/ChQu56qqrADhy5Ajh4eFOnaCUgTLhUs4E+/vyyk1tC5Snj5yxitOWnLINXJb+B0U0Zst1VqYezu4R7ulMuD0IT9lXsf9M51jg8F/Gcf5MOEDz/tC0r7F/+A+PGg3cRERERMqJUgXh48eP57HHHiM2NpbOnTvTtWtXwMiKt2vXzqkTlDJQEC7l1I0dY5h7/6VEBvvx14FUHvz8T3JyraUfMMv5a8LfWLqd+ImL+ObPA6WfV37lJRMeVAXC6xrHyZs8O5eySN4IuVnG6ylsO7J+/wHfQNjzC2z8yv3zExEREbmAUgXhN9xwA/v27WPNmjUsXLjQcf7KK6/ktddec9rkpIzsQXhZG7OpO7q4QPOa4Xw4vCMBvmaWbD7CM9/9g620GcsylaOf3x39vZ938uribZw6k8NTc/5m59EylqrbbOUnEw7eUZJu3x+8TsfCtyKrEmusDwdYNE4fIoqIiEi5UaogHKBmzZq0a9eOQ4cOceCAkSnq3LkzzZs3d9rkpAxsNidmwiONx+wMyM0u21gi+XSoH8XrN8djMsGnv+/jnZ92lm6gMjVmy1tCk/fnZfbqfbwwfwsAtSMCyczO5eEv1mPJKUum/pSxNzd4PhMO3tEh3b4/+Lml6Pld+iBENTI+AFn2gnvmJSIiInIRpQrCrVYrEydOJCIigvr161O/fn0iIyN57rnnsFrL8B9VcZ6cM2DLNY7L2pgtIN86/zMu7iAtlU7fVrWYcHUcAC8u2MrcPw+WfBBH1Ucp3uuOcvRTzN9wiLFzNgJwT89GzLnPKJnfeDCVVxdvK/nYdvYseEA4+IeUfhxn8YpMeCFN2c7lGwADXjaOV70Hhze4fl4iIiIiF1GqIHzcuHG8+eab/Pvf/+bPP//kzz//5IUXXmDq1Kk8/fTTzp6jlIajyZQJ/Mr4n34f37Ml7eqQLi4w4tIG3NW9AQCPf/UXv+04VrIBLPaqj1I0hrRXitisPDn7d6w2uKVzPcb0bUbNiED+fV0bAN79eSe/7SzhvOzKy/Zkdo5tyjZBRfzg9PQJOJFXNVGnfdHXNroCWg4GmxV+SKyYr1dERES8SqmC8I8++ogPPviAe++9lzZt2tCmTRvuu+8+3n//fWbOnFni8d566y1iY2MJDAykS5curFq16oLXzpkzh44dOxIZGUlISAjx8fF88sknBa4xmUyFfr30UiXaMzZ/ZtBc6lUHZzmas6WUfSyRQozt14IBbWqRnWvj/z5Zy5akElRdlKUc3T8EG8aa4oDcTAa0qcWkQa0w5a0z7tuqJrd0jsFmg8TZf5FyuhRbqtkz4eWhFB2MEm2fAGOJScoeT8+m5Oz7g0c1guCoi1/f5wXj78IDq2H9p2W796kkSHVSsz4RERGplEoVnZ04caLQtd/NmzfnxIkTJRpr9uzZJCYmMmHCBNatW0fbtm3p06cPR44cKfT6qKgoxo0bx8qVK9mwYQMjR45k5MiRBRrEHT58uMDX9OnTMZlMXH/99SV7oRWZs9aD26lDuriY2WzilRvb0rlBFKeychgxfTWHUzOL9+QyNGbbnHSKdAIBuLxBEK/dFI+PuWCjr6evjqNhtRCS0s7w1DcbS95Arrxlwn18oUbe3+FJFbAk3V6KXrdT8a4Prw29xhrHiycYmfSSsFph5zKYfTu81hJ+erFkzxcRERHJp1RBeNu2bXnzzTfPO//mm2/Spk2bEo316quvctdddzFy5Eji4uKYNm0awcHBTJ8+vdDre/XqxeDBg2nRogWNGjXioYceok2bNvz666+Oa2rWrFng69tvv+Xyyy+nYcNCtrHxVs4OwtUhXdwg0M+H92/vSOMaoSSlnWHkjNWknSlGM0DH+71kQfieYxnc/uEq0m1BAEzsWx9/3/P/Wgz292XKzfH4mk3M35jEV2tLmAlNLyfbk+UXbS9Jr4DN2YrTlO1cXf4PasRB5glY8kzxnpNxDFa8Dm92gE8GweZ5xt7jaQe197iIiIiUWqmC8BdffJHp06cTFxfHnXfeyZ133klcXBwzZ87k5ZdfLvY4FouFtWvXkpCQcHZCZjMJCQmsXLnyos+32WwsXbqUrVu30qNHj0KvSU5O5ocffuDOO++84DhZWVmkpaUV+KrwLGUozy2MMuHiJhHBfswc2YnqYQFsSTrFPZ+svXhncns5egm240tKPcNtH/7BsfQssn2CAQi0nr7g9W3qRpJ4VVMAnpn3D3uOZRT7XuUuEw4VtzmbzXa2HL1Oh+I/z8cPBrxqHK/7CPavvvD4e3+Dr0fBqy1g8Xg4scvoN9D5brh3Jdz2deHboomIiIgUQ6mC8J49e7Jt2zYGDx5MSkoKKSkpXHfddfzzzz/nrc8uyrFjx8jNzSU6uuB/TKOjo0lKSrrg81JTUwkNDcXf358BAwYwdepUevfuXei1H330EWFhYVx33XUXHG/y5MlEREQ4vmJiYor9GsotlaNLBVa3SjAzRnQixN+H33YeZ8zXG4ouAbeU7P1+MsPC7R/+wYGTmcRWDaZWjRrGDxwNDQv3fz0a0aVBFBmWXB6evZ7s3GI2+TpVHjPhFTQIP7ELMk8aa9qjW5XsufW7QttbjeMfEiE35+zPMlPgj3fh7UtgRj/Y+CXkWqB2O7hmKjy6Bfq/BNFxTnspIiIiUjn5lvaJtWvX5vnnny9w7q+//uLDDz/kvffeK/PEihIWFsb69etJT09n6dKlJCYm0rBhQ3r16nXetdOnT2fo0KEEBgZecLyxY8eSmJjo+D4tLa3iB+Jl2bKpMPa9wtWYTdykVZ0I3rmtA3fMXM03fx6kdmQgj/c5vxcFNluJGrOlZ+UwYsYqth9Jp2Z4IJ/c2QW/7/KCd3sFyQX4mE28NiSevlN+Zv3+FKYu3U7iVc0u/mLsjdnKVSY8L4A9ucf4+8JZH9i52oG8DHattuDrX/Ln954IW3+ApA2w5kOjpH3NdNj4NeTk9SDwC4bWN0CHkRfvvi4iIiJSQqUOwp2hWrVq+Pj4kJycXOB8cnIyNWteOGNkNptp3LgxAPHx8WzevJnJkyefF4T/8ssvbN26ldmzZxc5j4CAAAICAkr3IsqrrDJs2VQYZcLFA3o0rc7k61rz+FcbeGvZTmpFBHHbJfULXpSTBda8deMX+dDpTHYud320hr8OpFIl2I9PR3UmJir4bACadfGlKLUjg3jhutaMnvUnby7bQfem1ekUe5EO3afKWXd0gJCqEFYLTh2GI5shprOnZ1Q8JW3Kdq7Q6nDlBCMT/uMYIF+FRY046HgHtLnp7N95IiIiIk7mhL2rSs/f358OHTqwdOlSxzmr1crSpUvp2rVrscexWq1kZWWdd/7DDz+kQ4cOtG3b1inzrVBctSZcjdnEzW7sGMMjCcZa7PHf/s2STQU/tCuQvS4iCM/JtfLA53+yctdxQvx9+OiOzjSukRd8O4LwojPhdle3qc317etitcHDX6wvunlcdiZk5X14VZ4y4XC2JD1po2fnURKOpmwlWA9+rg4joHZ7wGaUtbcZAncshHt/g853KQAXERERl/JoJhwgMTGR4cOH07FjRzp37syUKVPIyMhg5MiRAAwbNow6deowefJkwFi/3bFjRxo1akRWVhbz58/nk08+4Z133ikwblpaGl9++SWvvPKK219TueCq7ujKhIsHPHhlYw6lZDJ7zX4e+PxPnrkmjuphAQT7+xJ55hDNAatvEKeybAT5W8/rcG612nji6w0s3pSMv6+Z94d3pE3dyLMX2IP3i6wJz++Za+JYvecE+06c5um5f/P6ze0Kv9C+Htw3sPwFd9GtYMeSitMhPfvM2S3V6pSgM/q5zD4w9EvYtRwaXm5UBYiIiIi4SYmC8KKamwGkpKSUeAJDhgzh6NGjjB8/nqSkJOLj41mwYIGjWdu+ffswm8/+hzojI4P77ruPAwcOEBQURPPmzfn0008ZMmRIgXG/+OILbDYbt9xyS4nn5BXUmE28iMlkYtLgViSlneGnbUcZ8/XZzG0L015+DIDj2f50mrgIAD8fE0F+PoQE+BLk7wPArqMZ+JhNvHVre7o1qlbwBgHFWxOeX1igH68Nieemd1fy7fpDXN6sBoPa1Tn/wvR8pejlraO2fV14RQnCkzYYSw9CqkNkvbKNFVLNWPctIiIi4mYlCsIjIorO4kRERDBs2LAST2L06NGMHj260J8tX768wPeTJk1i0qRJFx3z7rvv5u677y7xXLyG0xuz2YPwFOeMJ1JCfj5m3h7anhcXbGFr8ilOW3I5bcklNjMXsiGDIMe12bk2snNzSDuTU2CMl25oQ++4QkrC7cs2ilmObtehfhUevKIJry3ZxtNz/6ZD/SrGGvP8HNuTlaP14HaODun/gNUKZo+uULo4e1O2Oh3L3wcaIiIiIsVUoiB8xowZrpqHOJvTG7NFGo/KhIsHhQT48uy152xLtS0LZkFsrRpsG9WPTEsup7NzyMjK5bQlJy9Yz6FeVAiNa1zgQyn7n5NiNGY71/2XN+Ln7UdZu/ckj8xezxd3X4KvT75g1pEJL2frwQGqNQEff2OLt9R9UCXW0zMqmqMpWxlK0UVEREQ8rJynPaTUXNWY7UyqsSWUSHlhOfuBk7+vmYhgP2pFBNG4Riht6kZyScOqXNE8+sIBOJytGClBObqdr4+ZKUPiCQ3wZc3ek7y9fGfBCy6QCbfZbGRacklOO8O25FOkZhbR3M1VfPyget4WaxWhJP2ggnARERGp+DzemE1cxFVrwnMtRrdn/+CirxdxlxLsEX5Bju7oxW/Mll9MVDDPDWrJI7P/4vWl2wny88GGjdTMbK7cuoX2wJfbspm1ZwWpmdmkZeaQlpmNJdfqGCPQz8y02zrQq1mN0r+O0ohuZXRHT/obmg9w771LIv0opOwDTHmdzUVEREQqJgXh3soemDhrTXhAGJjMYLMa2XAF4VJeOKP/QSnXhOc3uF1dlm89yrfrD/H8/M2O81389oMP/HHUjz9zU857no/ZRKCvmQxLLnd/vJa3hrYvfN26qzias/3tvnuWhj0LXr0ZBDppmY2IiIiIBygI91bOXhNuMhnZ8MyTRhAeXss544qUlTOWXviXvDt6YZ4bZAS0p87kEBHkR3igLy22ZsJpGHhpe3rX75B33o+IYOPnoQG+ZOfaeHj2n8zfmMS9n67ljVva0b+1m/6M5W/OVp7lb8omIiIiUoEpCPdGNlu+dbJOKkeHfEF4ivPGFCkrZyy9cJSjl7wxW37hgX7n7xf+4kkAerZvBTUL75Du72vijZvb4efzF9+uP8ToWet4bUg818YXsuWZs9kz4Sd2gSUD/ENcf8/SUFM2ERER8RJqzOaNsk8bZePgvMZsoA7pUj7Zs9f+ZQnC85WjO7PxYI4FTh83jsOK3qLM18fMqzfFc0OHulht8PDs9fx3zX7nzeVCQqtDaDRggyObL3q5R1itcOhP41hBuIiIiFRwCsK9kT0zaDKDnxPXbufvkC5SXjizMZst12g86CwZR4xHsy8ERV30ch+ziRevb8OtXephs8ETX23gsz/2Om8+F+IoSS+n68KPbTOqFPyCoXoLT89GREREpEwUhHujrHyZQZPJeePag/DMFOeNKVJWzmjM5pevBLuM68ILOJW3R3hoNJiL99et2Wzi+UGtGHlpLADjvvmbGSt2O29OhbEH4UlODMLTDsOa6ZCTVfax7E3ZarcDH62iEhERkYpNQbg3sq9rdeZ6cICgSONRmXApTxyN2crwfjebz5azl3KbskKl5+0RfpFS9HOZTCbGXx3H//VsCMCz323i3Z92XuRZZRDd2nh0ZnO2Hx6F7x+BZc+XfSz7evA6Hco+loiIiIiHKQj3Rs7oFl0YRzl6inPHFSkLZzRmg3zrwp0YhJ/KC8JDSxaEgxGIP9m3OQ9e0RiAyT9uYerS7c6bW375O6Q7Y038mVTYsdg4XvUBZBwr23iOpmydyjaOiIiISDmgINwbOSsoOZejMVuKc8cVKQtHY7Yyfuhkf74zy9HT88rRw0q377fJZCLxqmY8dlVTAF5ZvI2XF27F5szmcQDVmhrr1rNSIdUJzeC2LYRci3GcnQG/TS39WJYMOJKXoVdTNhEREfECCsK9kcuCcDVmkwvY9zus+8S5ncWLy/F+L2MQHuCCcvQyZMLzG31FE8b1NxqSvblsB5N/3OLcQNzXH6o1M46dUZK+6Vvj0b6n96r3IeN46cY6tN7Y7SGsNoTXLvvcRERERDxMQbg3ckajqsJoizIpzJoZMKMfzBsNh9e7//5ZTlgTDgW3KXOWMmbC87urR0OevcYoG3/v5108+90m5wbiNfP2Cy9rh/SsdNixxDgeOAVqtTWy4StLmQ23N2Wrq/XgIiIi4h0UhHsjR2Yw3Lnj2huzqTu6gJH1/t/z8P3DZ/elP7rVvXPIzYGcvC3FyrJPOJz982JvbOgMpw4bj2XMhNsN7xbLC4NbYzLBzN/28NQ3f2O1OikQd1aH9O2LIOcMRDWE6FbQ80nj/B/vlS4b7mjKplJ0ERER8Q4Kwr2RyxuzKRNe6eVmw7ej4ecXje/DahmPJ3a5dx7512+X9f3uijXhp5yXCbe7tUs9XrqhLWYTfL5qH4/8dz2WHGvZB87fnK0s7KXocdcaWyQ26wc125Q+G66mbBXOW2+9RWxsLIGBgXTp0oVVq1YV63lffPEFJpOJQYMGuXaCIiIiHqYg3BtpTbi4UlY6fH4zrP8UTGYY+Dp0ucf4mbuDcPt73ewHvgFlG8vZ5ejWXMg4Yhw7KRNud0OHuky5uR2+ZhPfrj/EXR+v4bQlp2yD2rcpO7ETLKdLN4bltJEJByMIByMQ7zXWOC5pNjztEJw6BCYfqB1fujmJW82ePZvExEQmTJjAunXraNu2LX369OHIkSNFPm/Pnj089thjdO/e3U0zFRER8RwF4d4oy0ndos+Vf0241QmZN6l40o/AzAHGml/fILj5c+gwwig9Bs9lwp3xgZOzG7NlHMsr0zdBSHXnjJnPNW1r88HwjgT5+fDTtqPc+v4fnMywlH7A0BoQXM2Y89HNpRtjxxLIPg2R9aBW/NnzBbLhbxZ/PHsWvEYc+IeUbk7iVq+++ip33XUXI0eOJC4ujmnTphEcHMz06dMv+Jzc3FyGDh3Ks88+S8OGDd04WxEREc9QEO6N7GtaXZUJxwYWJ3aQlorh2A74IMFovhZcFUZ8D836Gj/zVBCe5cSlF45ydCe9t9PzOqOHVAcfX+eMeY5ezWow664uRAb7sX5/Cje+u5JDKZmlG8xkKntJ+rml6PnH7pW3NnxVCbLhaspWoVgsFtauXUtCQoLjnNlsJiEhgZUrV17weRMnTqRGjRrceeedF71HVlYWaWlpBb5EREQqGgXh3shVjdn8AsEnr+RXJemVy/7V8GFvSNkLVWLhzsUF92yOamA8Zp40vtzFHjCXtSkb5GvM5qQg3AXrwQvTrl4VvrqnK7UiAtlxJJ3r3/mNHUdK+Rpq5pWklyYIzz5j7A8OEDfo/J8362+Mb0kvfjb8wFrjUU3ZKoRjx46Rm5tLdHTB93x0dDRJSUmFPufXX3/lww8/5P333y/WPSZPnkxERITjKyYmpszzFhERcTcF4d7IVY3ZQB3SK6Mt8+GjgZB5Amq3MwLwqo0KXuMfcnbd84nd7pubs/YIzz+Gs9aE2zPh9qZ1LtS4Rhhf3duNRtVDOJx6hhumreTPfaX4MKQsHdJ3LTM+FAmvC3UKyVznXxu+6j04faLo8XJz4NA641hN2bzSqVOnuP3223n//fepVq1asZ4zduxYUlNTHV/79+938SxFREScT0G4N3JVYzZQc7bKZs10mD3U2AascW8Y/r2xdrgwnihJd2b/A2evCbdnwkNdmwm3qxMZxJf3dKNtTCQpp7O59f0/+Gnb0ZIN4ihH/9vYgq4kHKXo1xQsRc+vJNnwo5uN9eUB4VCtacnmIh5RrVo1fHx8SE5OLnA+OTmZmjXPb064c+dO9uzZw8CBA/H19cXX15ePP/6YefPm4evry86dO897TkBAAOHh4QW+REREKhoF4d7IVY3ZQEF4ZWGzwf8mwfePGI262t0Gt3xedMbZEYS7MRPuzMZszt6izJEJd25n9KJEhfgza1QXejStTmZ2LqM+Ws236w8Wf4DqzY1O5GdSjM7keY6eyip6rXmOxaiYAGhxzYWvK9Ap/d2is+H2pmy124FZ/1RVBP7+/nTo0IGlS5c6zlmtVpYuXUrXrl3Pu7558+Zs3LiR9evXO76uueYaLr/8ctavX69ScxER8Vqu6RYknuXSTHik8XgmxfljS/mQmw3fPQTrPzO+7znGCJwulN20i4o1Ht2aCXdmObo9E+6kIPxUXhDupky4XUiALx8M68hjX/7FvL8O8fDs9ZzMsDDi0gYXf7JvgJF1PrqZg1tXMzcjk8Wbklm/PwWARtVDuLxZDS5vXoNOsVH4++YFx7t/gqxUY0lCTJei72HPhidtNLLhV44v/DpHUzatB69IEhMTGT58OB07dqRz585MmTKFjIwMRo4cCcCwYcOoU6cOkydPJjAwkFatWhV4fmRkJMB550VERLyJgnBvY7U6Nzt4LmXCvVtuNnx+C+xYbGREr37V2IKsODxSju7Mxmz2INxJ3ZZPuT8Tbufva2bKkHiiQvyZ+dsenvluEycyLDzSuymmC3yYkmu1sW7fSYJzY2jJZj77dj5v5/o5fu5jNrHzaAY7j+7mg193E+Lvw6WNq3F58xpcu/drggFaDLx41tpkgp5PGssc/ngPuo6G4Kjzr1NTtgppyJAhHD16lPHjx5OUlER8fDwLFixwNGvbt28fZlU2iIhIJacg3NtkZwB5azkVhEtJ/TbVCMD9guHGmdC0T/Gf64kg3JlNCPOXo9tsF8/8X0y6fU24+4NwALPZxISBcVQL9eflRdt44387OJpuYdKgVviYjdd2JjuXX7YfY/GmJJZuPsLxDAv3+ETR0g/ifPbTq3F1roqrSUKLGgT6+/Dr9mMs23KE5duOcvRUFos2JfO/TQfpG/AdwSb4PL0djfecoF1MJL4+RQRazQfky4a/BVc+XfDnZ9Lg6BbjWJnwCmf06NGMHj260J8tX768yOfOnDnT+RMSEREpZxSEext7ZtDsC76Bzh9f3dG918k98NOLxvGAV0sWgANUySt3zjhivA9d8SHQubKcWPVhH8OaAzlnwC+o9GPZbGeDcBdvUVYUk8nE6CuaEBUSwL/mbuTzVfs4mWHhyhY1WLwpmZ+3H+VMttVxfXigL1XqtoMDX9C/+jGuHtm5wHj9W9eif+taWK02Nh1OY9mWIxzfuJAqKekcs4Uz7s9wrH+uJDzQlx5Nq3NVy5oMbFPr/Ox7gWz4u9D1/oLZ8EPrABtE1rtwI0ARERGRCkpBuLfJ35StrJm8wigT7p1sNvjhMaMLemx3aHtzyccIioTgqnD6uNGcrVYbp0/zPBYnNiHMP0ZWetmC8MyTkGsxjt28Jrwwt3apR5VgPx76Yj0L/kliwT9n92yuExlE77horoqLplODKPwykuDVMZhP7DD2/vY7/8M8s9lEqzoRtKoTAaffgrVwqkFfBgbW5adtR0k5nc33Gw7z/YbD7Duewegrmpw/qeYDILo1JBeSDbc3ZVMpuoiIiHghBeHextGoykXbtigI906b5hpl6D7+cPVrpf8AJ6phXhC+yz1BuH39tjMy4WYz+IUYSzqy0iC0eunHsq8HD6piNDsrB/q1rkVEsB+PzF5P1ZAArmoZTe+4aOJqhRfMVIfVgqAoY1/4o1ugdvyFB7XmwubvAGjQ/VZeb9SOXKuN9ftTmLf+IB+t3MvU/+3g2vg6xEQFF3yuyQS9xsDs287Phh/MWw+uUnQRERHxQuqO4m0sTuwWXRh1R/c+Z1LhxyeN48segWqFZC2Ly74u/KSbtilz9nZ89mC+rNuU2bcn89B68Avp1qgafzyVwPyHuvNwQlNa1o4ovFQ8/37hRdn7G5w+ZnzYEHsZYDRw61C/Cs9c05KuDauSlWPlue83Ff78ZnnZcMsp+P1t45zNpky4iIiIeDUF4d7GlduTgTLh3uh/k4ygMaoRXJZYtrHc3ZzN2TsB2D+8Kus2Zac8vx68TKLztodK/qfo6zZ9azw2HwA+fgV+ZDKZePbalviaTSzalMzyrUfOf77ZbGTDAX6fZuwbnrLP6Ctg9nVPNYWIiIiImykI9zbOzgyeyx6EqzGbdzi4Fla9bxwPeKXQ9b8lYm/OdsLNmXBnVX44tik7VbZx7JnwsFplG8dTatqD8CIy4VaroxSduEGFXtI0OowR3WIBeGbeP2Tl5J5/0bnZcPv+4DVbl21dvoiIiEg5pSDc27g6E27vjq5MeMWXmwPfPQzYoPVN0Ojyso/p7ky4M/cJh4LblJWFPRNeDpqylYq9HD3pb6M8vDAHVhkfNgREQIOeFxzqoYQmVA8LYM/x03zwSyEfzpjN0PMJ4/iPd2HHUuNYpegiIiLipRSEexuLi4Pw4KrGY3ZG2bOF4lmr3oOkDUZ1Q5/nnTOmPQhPOwjZmc4Z80JsNufuEw5nGxraG76VliMTXr7WhBdb9eZgMhvN2U4lFX6NoxS9P/j6X3CosEA/xvVvAcDU/23nYEoh74vmVxsl8FlpsP4z45yasomIiIiXUhDubdyxJjwkr2v0se2uuYe4XupBWJYXeCc867y9mIOjjMwoGPuOu5IlA8jL0pbXNeEVNRPuFwRVGxvHha0Lt1rPBuFx1150uGvja9O5QRRnsq1MKqxJm9kMPccUPKdMuIiIiHgpBeHextVBOEC1psajgvCK68cnjCxyTBdoP9x545pMEGVfF+7iknR7FtxkBr/goq8tLqeVox82HitqJhzyNWfbeP7PDq0zqh38w6DhxZcxmEwmJl7bEh+ziR//TuLnbUfPv8ieDQdjF4aqjUo/dxEREZFyTEG4t3F1YzbIF4Rvdd09xHW2/ghbvje6T1/9mpGFdCZ3rQt3rAcPLf2+5udyRmM2mw3SK3gmHPJtU1ZIJnzTXOOxaZ9iN/NrXjOcYV3rAxdo0mY2wxVPAyZo0tt5v6ciIiIi5YyCcG/jjkx49WbG41EF4RWOJQPmP24cd73/bKDlTI4g3MUd0vMH4c7iKEcvQxCedQqyTxvHXpEJPycIt9lKVIqe3yO9m1ItNIBdxzL48NdC3h/N+sLoNTDw9VJMWERERKRiUBDubVzdmA2gWhPjUeXoFc/yf0Pqfoiod/4aXGdxVybc2XuEQ77GbGUIwu1ZcP8w8A8p+5w8xb5N2bFtkJN19vzh9cZe3n7B0DihREOGB/oxtl9zAKYu3cGhwpq0VWtcsX/dRERERC5CQbi3ccua8LxM+ImdkJvtuvuIcyX9DSvfMo4HvOy6QMdda8KdvUc4OGdNuL2beFgFLkUHCK9jNGK05hSsetk0z3hschX4l3wt/nXt69CxfhUys3N5/ofNTpqsiIiISMWhINzbZLkgO3iu8DrgF2L859zVJcfiHFYrfP8w2HKhxTXGWl5XsWfCU/dDjsV193FJOboT1oQ71oNX4FJ0MNZkn1uSbrOdXQ9ewlL0s8OamHhtK8wm+GHjYX7dfqzscxURERGpQBSEextXBCbnMpuNklEwSlWl/Fs3Ew6sNt4X/f7j2nuFRhulyjarUbbsKq5YeuGMLcq8JRMO+YLwv/Me/zEqHHwDjUx4KcXVDuf2S4wmbRPm/Y0lx1rWmYqIiIhUGArCvY07ytHhbEm6OqSXf+lHYMkzxvEV/4Lw2q69n8nknnXhrqj68M8by1KWTLg9CK9V9vl4mqNDel4Qbm/I1jihzMsAEq9qRtUQf3YezWDGClXUiIiISOWhINybWHMhO8M4dnUQXl17hVcYC5+CM6lQqy10vts993THunCLC7bjc0Y5+ikv2J7M7txy9FJ2RS9MRJAfY/KatL2+dDtJqWfKPKaIiIhIRaAg3Jvkbybl8kx4XhCubcrKt53/g41fgskMV08Bs4977uuWTLi96sMVW5SlG+ufS8ORCa/ga8IBarQATJBxFHb9ZFS++Pg7rafADe3r0q5eJKctuTw/X03aREREpHJQEO5N7OW5Zj/wDXDtvRzl6NtLH6yIa2WfgR8eNY473QV12rvv3u4sR3dFJtyaXXBbrpLwpky4fzBUbWQcL3vBeGx0hdE13QnMZhPPXdsKkwm+++sQv+1UkzYRERHxfgrCvYm71oODEWSZfIy1s6cOu/5+UnJrPjSC4LBaxlpwd7IH4SdduNbX0Zgt3Hlj5g/oS7tN2SkvyoTD2XXh+383Hp1Qip5fqzoRDO1SD4AJ3/5Ddq6atImIiIh3UxDuTSxu2J7Mztf/7LpflaSXT5u/Mx4vS4RAJwaqxVEl771xci/k5rjmHq7YJ9zsY3R2h9KtC8/OhKxU49gbMuEA0a3PHpt9oVk/p9/isauaUSXYj+1H0vnotz1OH19ERESkPFEQ7k2y0oxHdwThkK8kXduUlTunT8D+P4xjFwRNFxVeB3wCjLLutAOuuYertuMrS3M2exbcN9BpJdseZ8+EAzTsBUFVnH6LyGB/xvQ1mrRNWbKdI2lq0iYiIiLeS0G4N3FnOTpAtSbGo4Lw8mfHEmOf7hotITLG/fc3m6FKrHHsqnXhFhdkwuFsUF+acnT70ozQaGOrNm+QPwh3cil6fjd1jKFtTCTpWTlc+9YKnv3uH1buPE6OytNFRETEyygI9yauaFRVlOp5mXCVo5c/2xYYj07qYl0qrm7O5ni/O/lDp7Jkwnf/bDzat/byBpH1jN0QgqtC86tddhuz2cQLg1tRJdiPw6lnmLFiD7e8/zudnl/CY1/+xaJ/ksi05Lrs/iIiIiLu4uvpCYgTuT0TrnL0cik328iEAzTt67l5OIJwFzVns7jo/V6WIHzL98Zj8wHOm4+nmUxw52LjfRUc5dJbtawdwW9PXsmvO46x8J8klm5O5uTpbL5ae4Cv1h4g0M9Mz6bVuSquJle2qEFksL9L5yMiIiLiCgrCvYnFBfsmF6VaY+MxPRkyUyAo0j33laLt/wPOpEJQFNTt6Ll52Bv3uSITbrO5Zp9wKH0QfnIvJG009mT35IcfruDGP9tB/j70joumd1w0OblW1uw9ycJ/klj0TzIHUzJZ+E8yC/9JxsdsonNsFH1aRtO7ZU3qRAa5bY4iIiIiZaEg3JtkuWDLpqIERhjbX506bOwXHtPJPfeVom1baDw2ucro9u0prixHz8kCa17XdWcvvyjtmvCtPxqP9bpCSFXnzqmS8vUxc0nDqlzSsCrjr45j0+E0Fv6TzKJ/ktiSdIqVu46zctdxnvluE81rhtExtgod60fRMbYKdSKDMHnLunwRERHxKgrCvUmWG7cos6vWNC8I36YgvLywB+GeXA8O+fYK3wNWq9GszVnyB8hO746eN15WCYNwbyxFL0dMJhMta0fQsnYEib2bsu/4aRZtMjLkq/eeYEvSKbYkneLT3/cBUDM8MC8or0LH2Cia1wzD10dtUERERMTzFIR7E1dt2VSUak1h909wTM3ZyoUTu4zfC7MvNLrCs3OJiDHmkXPG+KAmoo7zxra/1/2CwcfJf42Vphz99AnY+5tx3Ky/c+cjhapXNZhR3RsyqntDjqdnsWr3CVbvOcnavSf451AaSWln+H7DYb7fYHSsD/H3oV29KnSoX4VOsVHE14skNED/BIqIiIj76X8g3sTdjdkgX4d0NWcrF7YtMh7rdfX8Gn0fX6Oz9oldxpcrgnBXfOBk77ZuKUEQvm0h2HKNruj2tfDiNlVDA+jXuhb9WtcC4LQlh/X7U1i75yRr9p5k3d6TnMrK4dcdx/h1xzEAzCaIj4nkP9e3oUm0G//OFBERkUpPQbg3cdW+yUWp1tR4VIf08sGxNVk5aQwW1fBsEN6gu/PGdeV7vTSZcHspurLg5UKwvy/dGlWjW6NqAORabWxLPsWaPSdYs/cka/ac5GBKJuv2pTD0gz/46p5u1Ksa7OFZi4iISGXh8QVyb731FrGxsQQGBtKlSxdWrVp1wWvnzJlDx44diYyMJCQkhPj4eD755JPzrtu8eTPXXHMNERERhISE0KlTJ/bt2+fKl1E+ZKUZj+5qzAZng/CTu41mWeI5Wadgz6/GcXkKwsH5zdkce4S7Iggv4Zrw7EzY+T/jWOvByyUfs4kWtcK5vWssr9/cjhVPXsEvT1xOs+gwjpzKYuiHv5OcdsbT0xQREZFKwqNB+OzZs0lMTGTChAmsW7eOtm3b0qdPH44cOVLo9VFRUYwbN46VK1eyYcMGRo4cyciRI1m4cKHjmp07d3LZZZfRvHlzli9fzoYNG3j66acJDAx018vyHFcGJhcSVtMI+m1WOL7TffeV8+1cBtZsiGp0dvs4T3NVEG5x4U4AJe2Ovms5ZJ+G8LpQq63z5yMuERMVzCd3dqZ+1WD2n8jktg/+4ESGxdPTEhERkUrAo0H4q6++yl133cXIkSOJi4tj2rRpBAcHM3369EKv79WrF4MHD6ZFixY0atSIhx56iDZt2vDrr786rhk3bhz9+/fnxRdfpF27djRq1IhrrrmGGjVqXHAeWVlZpKWlFfiqkDyxJtxkgmpNjGOVpHtWeemKnp8jCN/t3HFdtUc4lLwcPX9XdG2JVaHUCA/k0zu7UDM8kO1H0hkxYxWnzmR7eloiIiLi5TwWhFssFtauXUtCQsLZyZjNJCQksHLlyos+32azsXTpUrZu3UqPHj0AsFqt/PDDDzRt2pQ+ffpQo0YNunTpwty5c4sca/LkyURERDi+YmJiyvTaPMbigS3KAKrlNWdTEO45VitsL89B+C6w2Zw3rkvL0UsQhFtzYWveOnyVoldIMVHBfDqqM1Eh/mw4kMqdH63hTHaup6clIiIiXsxjQfixY8fIzc0lOjq6wPno6GiSkpIu+LzU1FRCQ0Px9/dnwIABTJ06ld69ewNw5MgR0tPT+fe//03fvn1ZtGgRgwcP5rrrruOnn3664Jhjx44lNTXV8bV//37nvEh3ys0xSmLB/UF49bx14Ue1TZnHHPoTMo4anb3rdfP0bM6KrAcmM2RnGPNzlvLSmG3/Kjh9DAIjoH45+nWXEmlcI4yP7+hMWIAvq3af4N5P12LJsXp6WiIiIuKlKlx39LCwMNavX096ejpLly4lMTGRhg0b0qtXL6xW4z9N1157LY888ggA8fHx/Pbbb0ybNo2ePXsWOmZAQAABAQFuew0ukX87JXeuCQd1SC8P7F3RG18Bvv6enUt+vgHGWunUfUY2PPTCy0JKxJVLL0qyJtxeit60L/j4OX8u4jat6kTw4YhODJv+B8u2HiXxv+t5/eZ2+Ji1xEBEREScy2OZ8GrVquHj40NycnKB88nJydSsWfOCzzObzTRu3Jj4+HgeffRRbrjhBiZPnuwY09fXl7i4uALPadGihfd3R7eX5/oEuD8Ic5SjbzfKosX9ytvWZPnZ9812ZnM2e4Ds74Ig3B7Y51qK7vhvs8GWH4xjlaJ7hc4Noph2Wwf8fEx8v+Ew/5q7EZszl1GIiIiI4MEg3N/fnw4dOrB06VLHOavVytKlS+natWuxx7FarWRlZTnG7NSpE1u3FiyL3rZtG/Xr13fOxMsrTzRls6sSC2Y/yMmEtAPuv39ll3YIkjYAJmjc29OzOZ8rOqS7sjFb/kqSorYpO7LZ2JrPJwAaXen8eYhH9GpWgylD2mE2weer9jP5xy0KxEVERMSpPFqOnpiYyPDhw+nYsSOdO3dmypQpZGRkMHLkSACGDRtGnTp1HJnuyZMn07FjRxo1akRWVhbz58/nk08+4Z133nGM+fjjjzNkyBB69OjB5ZdfzoIFC/juu+9Yvny5J16i+7hyjezF+PhC1UZwdAsc3WasAxb32b7IeKzbEUKre3YuhXFJEO7Cxmw+vuAbZHyoZDkFIVULv86eBW/YyzN/7sRlBrSpRUZWG574egPv/byL8EBfRl/RxNPTEhERES/h0SB8yJAhHD16lPHjx5OUlER8fDwLFixwNGvbt28fZvPZZH1GRgb33XcfBw4cICgoiObNm/Ppp58yZMgQxzWDBw9m2rRpTJ48mQcffJBmzZrx9ddfc9lll7n99ZXKoT9h/SzwDYRuDxR/DW1W3rZqnsiEg7Eu/OgWOLYVmiRc/HpxnvK4NVl+rgjCXb0TQECYEYQX1Zxtq0rRvdlNnWI4lZXDc99v4uVF2wgN8GXEpQ08PS0RERHxAh5vzDZ69GhGjx5d6M/OzV5PmjSJSZMmXXTMO+64gzvuuMMZ03OP7Ez4ew6s/gAOrTt7fs0M6PEYXHKv0eCqKPbMYEC46+ZZlOrNYDNqzuZu2Zmwa7lxXB7Xg8PZIPx43jZlzthL29XLLwJCIePIhcvRUw8YH5hhgmb9XDMH8bg7L2tAWmY2ry/dzjPfbSI00I8bOtT19LRERESkgvN4EF6pHd8Ja6bDn5/CmRTjnI8/tLgGTuw0/pO/ZAKsnQlXTTIybhcKYOxBibs7o9vZO6QfVRDuVnt+NbamC68D0a08PZvCVYk1HrNSIfMkBEeVfUxXv98vtk3Z1h+Nx5guzuv4LuXSwwlNOHUmh+krdvPEV38RGuBD31a1PD0tERERqcAUhLtbbg5s+xFWfwi7lp09H1kPOoyEdrcb63qtVtjwBSx51mj+NHsoNOgBfSZDzUKCLU82ZoN825Rpr3C3cnRF7+OcDLMr+AdDWG04dcgoSXdGEO7qHgj2ruuWCwTh9q3JVIru9UwmE/8a0IJTZ7L5cu0BHvx8PR+O8KV7k3LYf0FEREQqBI91R690TiXB8v/AlNYw+7a8ANwETfrArf+FB9dD98SzjbXMZoi/FR5YC90fNTow7/4Z3u0O3z0MGccKju/JxmwA1fKaFp0+DhnHPTOHysZmO7sevEk5XQ9u59imbLdzxstyw5pwKDwTnpliVCCAgvBKwmw28e/r29C/dU0suVbGztmIJUfbMYqIiEjpKBPuSjYb7PnFWOu95Qew5hjng6tC+2HQYcTZUt0LCQiFK8dD++GweDxsmgtrZ8DfX0PPJ6Dz/xn7gnu6MZt/CETEQOp+Y114SPG3mZNSOrLJ+PX2DTSqJMqzqAawd4VzmrPl5hhN08A1+4TD2Q+zClsTvn2x8We5enNjVwCpFHzMJl4bEk9owN/8X89G+PvqM2wREREpHQXhrrT83/DTv89+H3MJdBoFcddcvNHauarUh5s+gj0rYMGTxr7Qi/5lNG/r83y+NbIeCsLBKElP3W+UpNdXEO5y9lL0Bj2Nku/yzJkd0vOXiLusHD1vXEshQbhK0SutAF8fXryhraenISIiIhWcgnBXajkIVr4JbW6CjncWvpa7pGIvhbuXG9uYLZ1oNHD7/GYjGwqey4SDEYTvXArHtntuDpVJed+aLD9nBuH27LTZr+QfZhXXhcrRc7JgxxLjWEG4iIiIiJSCgnBXqtECHtvu/Cyl2Qfa3w5x18Ivr8Dvb0POGeNnnloTDlDd3iFdzdlcLuM47F9lHFe2INzVe4TnH/vcIHz3z8b9w2pDrXauu7+IiIiIeC0tanM1V5YJB4ZD72fh/lVGQB4RA/W6ue5+F1OtmfGovcJdb8diwAbRrSGiAuxbXCWvMdvpY3AmtWxjZbmhCeGFgnB7KXqzfkbzRBERERGRElIm3BtENYCbPvb0LM5uU5ayD7IzwS/Is/PxZvm3JqsIAsMhpDpkHDU6pNeOL/1Y9iaErux/UNiacKsVtsw3jlWKLiIiIiKlpFSOOE9INQiqAti0LtyVcrNhx1LjuGlfz86lJJxVku6O7fgK645+cA1kHIGAcIjt7rp7i4iIiIhXUxAuzmMyqSTdHfatNLLBwdWgTntPz6b47CXpJ8u4V7g9MPZ3czm6vRS9yVXGtoAiIiIiIqWgIFycq1oT41FBuOvYu6I3ucpo0ldROD0T7spy9Lyx82+HplJ0EREREXECBeHiXNXzMuHqkO46FWlrsvwcQXhZM+F5a8Ld2Zjt6DY4vt3YFq1xguvuKyIiIiJeT0G4OJe9OZvWhLvG8Z15waAvNLrC07MpGWdlwh3l6K7couycNeH2UvSGPY0mcyIiIiIipaQgXJzLHoQf3wHWXM/OxRvZs+D1u1W8YDAqb034qcNgySj9OG5pzJYX4OdmQY4FtvxgfK9SdBEREREpIwXh4lyR9cA30AheUvZ6ejbex7E1WQXqim4XHAWBkcbxyT2lHyfLjWvCwfhA6eAa47hZf9fdU0REREQqBQXh4lxmH6ja2Dg+quZsTnUmDfauMI4rYhAOzilJt6/TdmV3dB9f48MkgI3/NR7rdISwmq67p4iXeOutt4iNjSUwMJAuXbqwatWqC177/vvv0717d6pUqUKVKlVISEgo8noRERFvoCBcnM+xLlzN2Zxq5//AmmN8yFG1kadnUzrOCMLtHctdmQnPP/6GvCBcpegiFzV79mwSExOZMGEC69ato23btvTp04cjR44Uev3y5cu55ZZbWLZsGStXriQmJoarrrqKgwcPunnmIiIi7qMgXJyvuvYKdwlHV/QKmgWHs+vCy9Ih3R37hOcfPy0vGGh+tWvvJ+IFXn31Ve666y5GjhxJXFwc06ZNIzg4mOnTpxd6/WeffcZ9991HfHw8zZs354MPPsBqtbJ06VI3z1xERMR9FISL89n3Clc5uvNYc2H7IuO4om1Nlp9TMuFuWBN+7vhVm0D1pq69n0gFZ7FYWLt2LQkJZ7fxM5vNJCQksHLlymKNcfr0abKzs4mKiir051lZWaSlpRX4EhERqWgUhIvzVbNnwreCzebZuXiLg+vg9DEICId6XT09m9Jzxl7h9jXhruyODgWDcJWii1zUsWPHyM3NJTo6usD56OhokpKSijXGmDFjqF27doFAPr/JkycTERHh+IqJiSnzvEVERNxNQbg4X9XGgAnOpELGUU/PxjvYu6I3vhJ8/Dw7l7KwB+Gp+yEnq3RjuGOfcChY7q4gXMTl/v3vf/PFF1/wzTffEBgYWOg1Y8eOJTU11fG1f/9+N89SRESk7BSEi/P5BUKV+sbxUTVnKzObDTbPM44r8npwgJDqecGtDU6WYgs7m809+4TD2Ux4SA2jM7qIFKlatWr4+PiQnJxc4HxycjI1axa9s8DLL7/Mv//9bxYtWkSbNm0ueF1AQADh4eEFvkRERCoaBeHiGvlL0qVsdv7PaHLnF1Lxg3CTKV9ztlKsC7dkAHlLHFy9Jjw4b01qs35g1l+VIhfj7+9Phw4dCjRVszdZ69r1wstoXnzxRZ577jkWLFhAx476wEtERLyfr6cnIF6qelPYvhCObff0TCq+398xHtvdBkGRHp2KU0Q1hKSNpQvC7evBTWbwC3buvM7V5R6wWaHHE669j4gXSUxMZPjw4XTs2JHOnTszZcoUMjIyGDlyJADDhg2jTp06TJ48GYD//Oc/jB8/nlmzZhEbG+tYOx4aGkpoqIurXeT/27v7uCjKtQ/gvwXZBRQQQt4UUUDxFXkUxdVMExTIY2J2JDNDM00Bj0V1UkvR7KSnzDyV4qNZebLE9Ekz8yWlsKPiO4YekcSX0BRUTEBQ3vZ+/phYW0UF3J1Zdn/fz2c+Oztz7+y11w67XDv33ENERAphEU6mUXOtcHZHfzCXc4Dc7QBUQO9JSkdjHA8yQnrFny5PplIZL6baPBQADHnPtM9BZGFiY2Nx+fJlzJo1C/n5+QgJCcHWrVv1g7Xl5eXB5k89S1JSUlBRUYEnn3zSYDvJycmYPXu2nKETERHJhkU4mYa+OzqPhD+QmqPgQY/dKl4bO9cH6I5emCvdmvoa4UTUYImJiUhMTKx1XXp6usH9s2fPmj4gIiIiM8MTHck0aq4VXnz+1mjWVD9lV4GfU6V5bbyysRhTzY8Jv9fzMmWndwLrxkvzfo34Mm1EREREZNVYhJNpOLpJI2ED0qBiVH+HPgWqbgBeXQG/vkpHYzw1Rfi1PKC6sm6PObEZ+OKvQGUp4D8AGPqBycIjIiIiIjIlFuFkOuyS3nBVFcD+5dJ87wTTn/8sJydvoIk9oKuSrhd+P1lrgTXPANXlQIe/AKPWmP7yZEREREREJsIinEynpks6L1NWf8c3ACUXgWaeQJcnlI7GuGxs6n5e+IEVwNcTAFENBD8F/HWldB16IiIiIqJGikU4mU6LP46Ec4T0+hEC2LtEmu/5PNBEo2w8pqAfIf0e54Xveh/4LgmAkPIQkwLYcixJIiIiImrc+B8tmU7NZcrYHb1+8vYCFzIBWw0Q+pzS0ZiG2z2OhAsBpL0J7Foo3X84CQifZVld8omIiIjIarEIJ9OpKcKvnpIG4LK1UzaexmLvYum2WyzQ1F3ZWEzlbtcK1+mALX8HDvxxPnzEbODhl2QNjYiIiIjIlNgdnUzHpRVg11QagOte3Y7plt/PAie+k+Z7W9BlyW5X25Hw6ipgw+Q/CnAVMOQ9FuBEREREZHFYhJPpqFR/GpyNlymrk33LAKED/B8FPDoqHY3p6K8VfhbQVQNV5cDaOCArFVDZAk8sk84DJyIiIiKyMCzCybT054VzcLb7ulkMHP63NK9NUDYWU3NuBdjYAdUVQGEu8OVI4MQm6Tz42FVA8EilIyQiIiIiMgmeE06m1YKDs9VZ5iqgokT64SIgXOloTMu2CeDqJxXg/x4mXY7Nrikw6kvAf4DS0RERERERmQyPhJNp1RwJ52XK7k1XDexbKs2HTZKupW3parqkl1wE7F2AZ79hAU5EREREFs8K/tMnRbn/ca3wKyelS09R7XI2A9d+BRxcgW6jlI5GHjU/0DT1AMZuBnx7KhsPEREREZEM2B2dTMvNXxpoq6JEOuLp7KN0ROYpY4l022McoHZUNha5aBMAOwcg5OlbR8WJiIiIiCwcj4STaTVR37ocFbuk1+5CJpC3B7BpAvSaoHQ08nH2AQa+wQKciIiIiKwKi3AyPX2XdF6mrFZ7U6TbzsPZU4CIiIiIyMKxCCfT04+QbmFFePl1YM+HQMF/G76N4ovAsf+T5nvHGycuIiIiIiIyWzwnnEzPUkdI35EMHPhY6kbe529A/79L5zjXx4HlgK4KaK0FWnY3TZxERERERGQ2eCScTM8Su6OXFgKZX0jzuipg10IgpS9w5j9130ZFGXDwU2m+92Tjx0hERERERGaHRTiZnns76fZ6AXDjmqKhGM2Bj4GqG4B3CBC7CmjmBVw9Baz8C/BNInDj9/tvI2sNcOMq0Lw10OEvJg+ZiIiIiIiUxyKcTM/eGXDylubT5wPnDwE6nbIxPYjKG8D+ZdJ8378BHYcCifuB0OekZZmfAx/1Av67/u7XRhfi1oBsYZMAG1vTx01ERERERIpjEU7yaBUq3e5LAT4eCCwIBP5vApD1ldS1uzH5eTVQdgVwaQ10HCYts3cB/vI+MG6LdA586SVg7Vhg9Sig6Pyd2ziVBlzJAdROwP+MkTV8IiIiIiJSDgdmI3nEpACBg4Dc7cCpdKCsEDj6lTRBJQ1KFjgICIyQ5s31yLBOB+z5SJrXxgO2t/0J+fUBJu0C/vMe8J+FwC9bgLP/ASJmA6HjAZs/fvfKWCLd/s8zUk8BIiIiIiKyCioh7tZf1noVFxfDxcUFRUVFcHZmgWR01ZXAuX3Aye1AbhpQcNRwvYMbEDAQaDcICAgHmrVQJs7anPgOSH1aOvL90nFA0+zubS9lAxv/BpzfL91v1Qt4/AMAKmBJmHT7t0zAra0ckRORGeH3jHEwj0REZGqm+K7hkXCSn60d0OZhaRo0R7pWdu6OW0fJb1wFjq2TJkAaXd23J9Cqp1TItghS7kj5ng+l29Dx9y7AAcCjI/DcNuDgCmDHbKkYX9rv1kB1HYawACciIiIisjIswkl5zt5A9zHSVF0FnD8gFeQntwP5WdK501dygMxVUnu1k9Rl3beXVJi3DAWaPmT6OM8dAPIyAFs1EPZC3R5jYwP0mgAERQPfvSJ1T790XFrXO950sRIRERERkVliEU7mxbYJ4KeVpvBZQOkVqSivmX47DFSUAGd2SlMNt4A/jpSHSsW5ZxfjHy3f84F0GzwScPKq32NdWgGjVgPHNwA75gBeXaXzx4mIiIiIyKqwCCfz1tRdOoocFC3d11VL51qf3w+cPwic2w8UnpSu0X31FJCVKrVrGQrEfQuoHY0Tx9XTQPa30rw2sWHbUKmAzsOliYiIiIiIrBKLcGpcbGwBry7SVHNd7rKr0hHy8/ulo+V5e4HfDgLbZwFDFhjneTOWABBAu8HSud5EREREREQNwCKcGj9HN6BdhDQB0iBvq0YAB5ZLRXP7wQ+2/dLCW+ej95nyYNsiIiIiIiKrZqN0AACwePFitGnTBvb29ggLC8P+/fvv2vbrr79GaGgomjdvjqZNmyIkJASff/65QZuxY8dCpVIZTFFRUaZ+GWQuAiOAsEnS/DfxwPXLD7a9gyuAqhuAdwjQpt8Dh0dERERERNZL8SJ8zZo1SEpKQnJyMg4fPoxu3bohMjISly5dqrW9m5sbXn/9dWRkZCArKwvjxo3DuHHjsG3bNoN2UVFRuHjxon5avXq1HC+HzEXEbKBFR6D0MrAxERCiYdupvAns+19pvs8U6bxuIiIiIiKiBlK8CF+4cCEmTJiAcePGoVOnTli6dCkcHR3xySef1Np+wIABGD58ODp27IiAgABMnToVwcHB2LVrl0E7jUYDLy8v/eTq6irHyyFzYecAjPhYupzYL1uBg7XvT/f182qg7Arg4gt0ijFqiEREREREZH0ULcIrKipw6NAhRERE6JfZ2NggIiICGRkZ9328EAJpaWnIycnBI488YrAuPT0dHh4eCAoKwuTJk1FYWHjX7ZSXl6O4uNhgIgvg1QUIT5bmt70OXP6lfo/X6YCMj6T53vHS5dOIiIiIiIgegKJF+JUrV1BdXQ1PT0+D5Z6ensjPz7/r44qKitCsWTOo1WoMGTIEH374IQYNGqRfHxUVhX//+99IS0vDP//5T+zcuRPR0dGorq6udXvz5s2Di4uLfvL19TXOCyTl9Y4H/AdI53R//TxQVVH3x/6yFSjMBexdgO5jTBYiERERERFZj0Z5aM/JyQlHjhzB9evXkZaWhqSkJPj7+2PAgAEAgKeeekrftmvXrggODkZAQADS09MRHh5+x/amT5+OpKQk/f3i4mIW4pbCxgaISQFS+gAXfwbS35bOF6+LPR9Kt6HPARonk4VIRERERETWQ9Ej4e7u7rC1tUVBQYHB8oKCAnh5ed31cTY2NggMDERISAhefvllPPnkk5g3b95d2/v7+8Pd3R25ubm1rtdoNHB2djaYyII4+wBD/yXN71oEnN11z+YAgPMHgbw9gI0d0OsFk4ZHRERERETWQ9EiXK1Wo0ePHkhLS9Mv0+l0SEtLg1arrfN2dDodysvL77r+/PnzKCwshLe39wPFS41Yp2FAyDMABPD1C8CNa/duv+cD6TY4FnDmfkNERERERMah+OjoSUlJWL58OVauXIns7GxMnjwZpaWlGDduHADg2WefxfTp0/Xt582bh+3bt+P06dPIzs7Ge++9h88//xzPPPMMAOD69et49dVXsXfvXpw9exZpaWkYNmwYAgMDERkZqchrJDMRPR9wbQsUnwe+e/nu7a6eBrK/leb7JMoTGxERERERWQXFzwmPjY3F5cuXMWvWLOTn5yMkJARbt27VD9aWl5cHG5tbvxWUlpYiPj4e58+fh4ODAzp06IBVq1YhNjYWAGBra4usrCysXLkS165dg4+PDwYPHoy5c+dCo9Eo8hrJTGicgCeWA59EAsfWAe2jgOC/3tlubwogdEDgIMCjo/xxEhERERGRxVIJIYTSQZib4uJiuLi4oKioiOeHW6L0+UD6PEDjDEzeDTRvfWtd2VXg/c5AZRnw7EbAv79ycRKRxeL3jHEwj0REZGqm+K5RvDs6kez6vQK06gWUF0vnh+v+dOm6AyukAty7G9D2kbtvg4iIiIiIqAFYhJP1sW0CPLEMUDeTRkDfvUhaXnkT2P+/0nyfvwEqlWIhEhERERGRZWIRTtbJrS0Q/Y40/+PbwG+HgaxUoPQy4OIrjaZORERERERkZIoPzEakmJCngZPfA8c3AF9PuLW8dzxga6dYWEREREREZLlYhJP1UqmAv7wPnNsPFOZKyzQuQPcxysZFREREREQWi93Rybo5ugHDlwL44/zv0HHSpcyIiIiIiIhMgEU4kX9/IPJtwH8A0GeK0tEQEREREZEFY3d0IgDQxksTERERERGRCfFIOBEREREREZFMWIQTERERERERyYRFOBEREREREZFMWIQTERERERERyYRFOBEREREREZFMWIQTERERERERyYRFOBEREREREZFMWIQTERERERERyYRFOBEREREREZFMWIQTERERERERyYRFOBERERnN4sWL0aZNG9jb2yMsLAz79++/Z/u1a9eiQ4cOsLe3R9euXbF582aZIiUiIlIGi3AiIiIyijVr1iApKQnJyck4fPgwunXrhsjISFy6dKnW9nv27MGoUaMwfvx4ZGZmIiYmBjExMTh27JjMkRMREclHJYQQSgdhboqLi+Hi4oKioiI4OzsrHQ4REVkYS/2eCQsLQ8+ePfHRRx8BAHQ6HXx9fTFlyhRMmzbtjvaxsbEoLS3Fpk2b9Mt69+6NkJAQLF269L7PZ6l5JCIi82GK75omRtmKhan5XaK4uFjhSIiIyBLVfL9Y0u/gFRUVOHToEKZPn65fZmNjg4iICGRkZNT6mIyMDCQlJRksi4yMxIYNG2ptX15ejvLycv39oqIiAPy+JiIi0zHFdzaL8FqUlJQAAHx9fRWOhIiILFlJSQlcXFyUDsMorly5gurqanh6ehos9/T0xIkTJ2p9TH5+fq3t8/Pza20/b948zJkz547l/L4mIiJTKywsNNp3NovwWvj4+ODcuXNwcnKCSqVSOpw6KS4uhq+vL86dO2f1XfKYi1uYCwnzcAtzIVE6D0IIlJSUwMfHR/bnbsymT59ucOT82rVr8PPzQ15ensX8mKEEpf8eLAXzaDzMpXEwj8ZRVFSE1q1bw83NzWjbZBFeCxsbG7Rq1UrpMBrE2dmZf2R/YC5uYS4kzMMtzIVEyTxYWtHo7u4OW1tbFBQUGCwvKCiAl5dXrY/x8vKqV3uNRgONRnPHchcXF+7PRsDPBeNgHo2HuTQO5tE4bGyMN6Y5R0cnIiKiB6ZWq9GjRw+kpaXpl+l0OqSlpUGr1db6GK1Wa9AeALZv337X9kRERJaAR8KJiIjIKJKSkhAXF4fQ0FD06tULixYtQmlpKcaNGwcAePbZZ9GyZUvMmzcPADB16lT0798f7733HoYMGYLU1FQcPHgQy5YtU/JlEBERmRSLcAuh0WiQnJxcazc9a8Nc3MJcSJiHW5gLCfNgGrGxsbh8+TJmzZqF/Px8hISEYOvWrfrB1/Ly8gy68/Xp0wdffvkl3njjDcyYMQPt2rXDhg0b0KVLlzo9H99H42AejYN5NB7m0jiYR+MwRR55nXAiIiIiIiIimfCccCIiIiIiIiKZsAgnIiIiIiIikgmLcCIiIiIiIiKZsAgnIiIiIiIikgmL8EZu9uzZUKlUBlOHDh2UDksWP/30E4YOHQofHx+oVCps2LDBYL0QArNmzYK3tzccHBwQERGBkydPKhOsCd0vD2PHjr1jH4mKilImWBOaN28eevbsCScnJ3h4eCAmJgY5OTkGbW7evImEhAQ89NBDaNasGUaMGIGCggKFIjaduuRiwIABd+wXkyZNUihi00lJSUFwcDCcnZ3h7OwMrVaLLVu26Ndbyz7RmC1evBht2rSBvb09wsLCsH///nu2X7t2LTp06AB7e3t07doVmzdvlilS81afPC5fvhz9+vWDq6srXF1dERERcd+8W4v67o81UlNToVKpEBMTY9oAG4n65vHatWtISEiAt7c3NBoN2rdvz79t1D+PixYtQlBQEBwcHODr64uXXnoJN2/elCla83S//6Nrk56eju7du0Oj0SAwMBCfffZZvZ+XRbgF6Ny5My5evKifdu3apXRIsigtLUW3bt2wePHiWte/8847+OCDD7B06VLs27cPTZs2RWRkpMV92NwvDwAQFRVlsI+sXr1axgjlsXPnTiQkJGDv3r3Yvn07KisrMXjwYJSWlurbvPTSS/j222+xdu1a7Ny5ExcuXMATTzyhYNSmUZdcAMCECRMM9ot33nlHoYhNp1WrVpg/fz4OHTqEgwcPYuDAgRg2bBj++9//ArCefaKxWrNmDZKSkpCcnIzDhw+jW7duiIyMxKVLl2ptv2fPHowaNQrjx49HZmYmYmJiEBMTg2PHjskcuXmpbx7T09MxatQo/Pjjj8jIyICvry8GDx6M3377TebIzUt981jj7NmzeOWVV9CvXz+ZIjVv9c1jRUUFBg0ahLNnz2LdunXIycnB8uXL0bJlS5kjNy/1zeOXX36JadOmITk5GdnZ2VixYgXWrFmDGTNmyBy5eanL/9F/dubMGQwZMgSPPvoojhw5ghdffBHPP/88tm3bVr8nFtSoJScni27duikdhuIAiPXr1+vv63Q64eXlJd599139smvXrgmNRiNWr16tQITyuD0PQggRFxcnhg0bpkg8Srp06ZIAIHbu3CmEkN5/Ozs7sXbtWn2b7OxsAUBkZGQoFaYsbs+FEEL0799fTJ06VbmgFOTq6io+/vhjq94nGotevXqJhIQE/f3q6mrh4+Mj5s2bV2v7kSNHiiFDhhgsCwsLEy+88IJJ4zR39c3j7aqqqoSTk5NYuXKlqUJsFBqSx6qqKtGnTx/x8ccfW+338e3qm8eUlBTh7+8vKioq5AqxUahvHhMSEsTAgQMNliUlJYm+ffuaNM7GpLb/o2/397//XXTu3NlgWWxsrIiMjKzXc/FIuAU4efIkfHx84O/vj9GjRyMvL0/pkBR35swZ5OfnIyIiQr/MxcUFYWFhyMjIUDAyZaSnp8PDwwNBQUGYPHkyCgsLlQ7J5IqKigAAbm5uAIBDhw6hsrLSYJ/o0KEDWrdubfH7xO25qPHFF1/A3d0dXbp0wfTp01FWVqZEeLKprq5GamoqSktLodVqrXqfaAwqKipw6NAhg/fHxsYGERERd31/MjIyDNoDQGRkpFW/nw3J4+3KyspQWVl5x2eINWloHt988014eHhg/PjxcoRp9hqSx40bN0Kr1SIhIQGenp7o0qUL3n77bVRXV8sVttlpSB779OmDQ4cO6busnz59Gps3b8Zjjz0mS8yWwljfM02MGRTJLywsDJ999hmCgoJw8eJFzJkzB/369cOxY8fg5OSkdHiKyc/PBwB4enoaLPf09NSvsxZRUVF44okn0LZtW5w6dQozZsxAdHQ0MjIyYGtrq3R4JqHT6fDiiy+ib9++6NKlCwBpn1Cr1WjevLlBW0vfJ2rLBQA8/fTT8PPzg4+PD7KysvDaa68hJycHX3/9tYLRmsbRo0eh1Wpx8+ZNNGvWDOvXr0enTp1w5MgRq9wnGosrV66gurq61s/xEydO1PqY/Px8fu7fpiF5vN1rr70GHx+fO/7xtCYNyeOuXbuwYsUKHDlyRIYIG4eG5PH06dP44YcfMHr0aGzevBm5ubmIj49HZWUlkpOT5Qjb7DQkj08//TSuXLmChx9+GEIIVFVVYdKkSVbfHb2+7vY9U1xcjBs3bsDBwaFO22ER3shFR0fr54ODgxEWFgY/Pz989dVX/NWVAABPPfWUfr5r164IDg5GQEAA0tPTER4ermBkppOQkIBjx45ZzfgI93K3XEycOFE/37VrV3h7eyM8PBynTp1CQECA3GGaVFBQEI4cOYKioiKsW7cOcXFx2Llzp9JhETUK8+fPR2pqKtLT02Fvb690OI1GSUkJxowZg+XLl8Pd3V3pcBo1nU4HDw8PLFu2DLa2tujRowd+++03vPvuu1ZbhDdEeno63n77bSxZsgRhYWHIzc3F1KlTMXfuXMycOVPp8KwOi3AL07x5c7Rv3x65ublKh6IoLy8vAEBBQQG8vb31ywsKChASEqJQVObB398f7u7uyM3NtcgiPDExEZs2bcJPP/2EVq1a6Zd7eXmhoqIC165dMzjyWVBQoN9fLM3dclGbsLAwAEBubq7FFeFqtRqBgYEAgB49euDAgQP417/+hdjYWKvbJxoTd3d32Nra3jFa/b3eHy8vr3q1twYNyWONBQsWYP78+dixYweCg4NNGabZq28eT506hbNnz2Lo0KH6ZTqdDgDQpEkT5OTkWNxnbV00ZH/09vaGnZ2dQe+9jh07Ij8/HxUVFVCr1SaN2Rw1JI8zZ87EmDFj8PzzzwOQfoAvLS3FxIkT8frrr8PGhmcp18XdvmecnZ3rfBQc4OjoFuf69es4deqUQeFpjdq2bQsvLy+kpaXplxUXF2Pfvn3QarUKRqa88+fPo7Cw0OL2ESEEEhMTsX79evzwww9o27atwfoePXrAzs7OYJ/IyclBXl6exe0T98tFbWq6S1raflEbnU6H8vJyq9onGiO1Wo0ePXoYvD86nQ5paWl3fX+0Wq1BewDYvn27Vb+fDckjIF1hZO7cudi6dStCQ0PlCNWs1TePHTp0wNGjR3HkyBH99Pjjj+tHVPb19ZUzfLPRkP2xb9++yM3N1f+IAQC//PILvL29rbIABxqWx7KysjsK7ZofNqQxyagujPY9U69h3MjsvPzyyyI9PV2cOXNG7N69W0RERAh3d3dx6dIlpUMzuZKSEpGZmSkyMzMFALFw4UKRmZkpfv31VyGEEPPnzxfNmzcX33zzjcjKyhLDhg0Tbdu2FTdu3FA4cuO6Vx5KSkrEK6+8IjIyMsSZM2fEjh07RPfu3UW7du3EzZs3lQ7dqCZPnixcXFxEenq6uHjxon4qKyvTt5k0aZJo3bq1+OGHH8TBgweFVqsVWq1WwahN4365yM3NFW+++aY4ePCgOHPmjPjmm2+Ev7+/eOSRRxSO3PimTZsmdu7cKc6cOSOysrLEtGnThEqlEt9//70Qwnr2icYqNTVVaDQa8dlnn4njx4+LiRMniubNm4v8/HwhhBBjxowR06ZN07ffvXu3aNKkiViwYIHIzs4WycnJws7OThw9elSpl2AW6pvH+fPnC7VaLdatW2fwGVJSUqLUSzAL9c3j7Tg6uqS+eczLyxNOTk4iMTFR5OTkiE2bNgkPDw/x1ltvKfUSzEJ985icnCycnJzE6tWrxenTp8X3338vAgICxMiRI5V6CWbhfvXEtGnTxJgxY/TtT58+LRwdHcWrr74qsrOzxeLFi4Wtra3YunVrvZ6XRXgjFxsbK7y9vYVarRYtW7YUsbGxIjc3V+mwZPHjjz8KAHdMcXFxQgjpMmUzZ84Unp6eQqPRiPDwcJGTk6Ns0CZwrzyUlZWJwYMHixYtWgg7Ozvh5+cnJkyYoP+AtiS15QCA+PTTT/Vtbty4IeLj44Wrq6twdHQUw4cPFxcvXlQuaBO5Xy7y8vLEI488Itzc3IRGoxGBgYHi1VdfFUVFRcoGbgLPPfec8PPzE2q1WrRo0UKEh4frC3AhrGefaMw+/PBD0bp1a6FWq0WvXr3E3r179ev69++v/8yv8dVXX4n27dsLtVotOnfuLL777juZIzZP9cmjn59frZ8hycnJ8gduZuq7P/4Zi/Bb6pvHPXv2iLCwMKHRaIS/v7/4xz/+IaqqqmSO2vzUJ4+VlZVi9uzZIiAgQNjb2wtfX18RHx8vfv/9d/kDNyP3qyfi4uJE//7973hMSEiIUKvVwt/f3+B/zbpSCcH+B0RERERERERy4DnhRERERERERDJhEU5EREREREQkExbhRERERERERDJhEU5EREREREQkExbhRERERERERDJhEU5EREREREQkExbhRERERERERDJhEU5EREREREQkExbhRCQrlUqFDRs2KB0GEREREZEiWIQTWZGxY8dCpVLdMUVFRSkdGhERERGRVWiidABEJK+oqCh8+umnBss0Go1C0RARERERWRceCSeyMhqNBl5eXgaTq6srAKmreEpKCqKjo+Hg4AB/f3+sW7fO4PFHjx7FwIED4eDggIceeggTJ07E9evXDdp88skn6Ny5MzQaDby9vZGYmGiw/sqVKxg+fDgcHR3Rrl07bNy4Ub/u999/x+jRo9GiRQs4ODigXbt2d/xoQERERETUWLEIJyIDM2fOxIgRI/Dzzz9j9OjReOqpp5CdnQ0AKC0tRWRkJFxdXXHgwAGsXbsWO3bsMCiyU1JSkJCQgIkTJ+Lo0aPYuHEjAgMDDZ5jzpw5GDlyJLKysvDYY49h9OjRuHr1qv75jx8/ji1btiA7OxspKSlwd3eXLwFERERERCakEkIIpYMgInmMHTsWq1atgr29vcHyGTNmYMaMGVCpVJg0aRJSUlL063r37o3u3btjyZIlWL58OV577TWcO3cOTZs2BQBs3rwZQ4cOxYULF+Dp6YmWLVti3LhxeOutt2qNQaVS4Y033sDcuXMBSIV9s2bNsGXLFkRFReHxxx+Hu7s7PvnkExNlgYiIiIhIOTwnnMjKPProowZFNgC4ubnp57VarcE6rVaLI0eOAACys7PRrVs3fQEOAH379oVOp0NOTg5UKhUuXLiA8PDwe8YQHBysn2/atCmcnZ1x6dIlAMDkyZMxYsQIHD58GIMHD0ZMTAz69OnToNdKRERERGRuWIQTWZmmTZve0T3cWBwcHOrUzs7OzuC+SqWCTqcDAERHR+PXX3/F5s2bsX37doSHhyMhIQELFiwwerxERERERHLjOeFEZGDv3r133O/YsSMAoGPHjvj5559RWlqqX797927Y2NggKCgITk5OaNOmDdLS0h4ohhYtWiAuLg6rVq3CokWLsGzZsgfaHhERERGRueCRcCIrU15ejvz8fINlTZo00Q9+tnbtWoSGhuLhhx/GF198gf3792PFihUAgNGjRyM5ORlxcXGYPXs2Ll++jClTpmDMmDHw9PQEAMyePRuTJk2Ch4cHoqOjUVJSgt27d2PKlCl1im/WrFno0aMHOnfujPLycmzatEn/IwARERERUWPHIpzIymzduhXe3t4Gy4KCgnDixAkA0sjlqampiI+Ph7e3N1avXo1OnToBABwdHbFt2zZMnToVPXv2hKOjI0aMGIGFCxfqtxUXF4ebN2/i/fffxyuvvAJ3d3c8+eSTdY5PrVZj+vTpOHv2LBwcHNCvXz+kpqYa4ZUTERERESmPo6MTkZ5KpcL69esRExOjdChERERERBaJ54QTERERERERyYRFOBEREREREZFMeE44Eenx7BQiIiIiItPikXAiIiIiIiIimbAIJyIiIiIiIpIJi3AiIiIiIiIimbAIJyIiIiIiIpIJi3AiIiIiIiIimbAIJyIiIiIiIpIJi3AiIiIiIiIimbAIJyIiIiIiIpLJ/wPso23YwlPf/QAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1800x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = history.history\n",
        "\n",
        "# Adjust epochs range to start from the 6th epoch\n",
        "start_epoch = 3\n",
        "epochs = range(start_epoch, len(metrics['loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Loss\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(epochs, metrics['loss'][start_epoch - 1:], label='Training Loss')\n",
        "plt.plot(epochs, metrics['val_loss'][start_epoch - 1:], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Directional Accuracy\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(epochs, metrics['directional_accuracy'][start_epoch - 1:], label='Training Directional Accuracy')\n",
        "plt.plot(epochs, metrics['val_directional_accuracy'][start_epoch - 1:], label='Validation Directional Accuracy')\n",
        "plt.title('Training and Validation Directional Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pMxOyOVkA0Tu"
      },
      "outputs": [],
      "source": [
        "model.save_weights('model_weights_binary.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnSg9Zh3Z0G7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "lWWaTyYkyvVX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
